<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Markov Chain Monte Carlo</title>

<script src="site_libs/header-attrs-2.5/header-attrs.js"></script>
<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/paper.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="site_libs/anchor-sections-1.0/anchor-sections.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="styles.css" type="text/css" />
<link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 64px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h2 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h3 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h4 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h5 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h6 {
  padding-top: 69px;
  margin-top: -69px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Jose Storopoli</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://scholar.google.com/citations?user=xGU7H1QAAAAJ&amp;hl=en">
    <span class="ai ai-google-scholar fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="https://orcid.org/0000-0002-0559-5176">
    <span class="ai ai-orcid fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="http://github.com/storopoli">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="https://twitter.com/JoseStoropoli">
    <span class="fa fa-twitter fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="https://www.linkedin.com/in/storopoli/">
    <span class="fa fa-linkedin fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Markov Chain Monte Carlo</h1>

</div>


<p>A principal barreira computacional para estatística bayesiana é o denominador <span class="math inline">\(P(\text{data})\)</span> da fórmula de Bayes:</p>
<p><span class="math display">\[P(\theta | \text{data})=\frac{P(\theta) \cdot P(\text{data} | \theta)}{P(\text{data})}\]</span></p>
<p>Em casos discretos podemos fazer o denominador virar a soma de todos os paramêtros usando a regra da cadeia de probabilidade:</p>
<p><span class="math display">\[P(A,B|C)=P(A|B,C) \times P(B|C)\]</span></p>
<p>Isto também é chamado de marginalização:</p>
<p><span class="math display">\[P(\text{data})=\sum_{\theta} P(\text{data} | \theta) \times P(\theta)\]</span></p>
<p>Porém no caso de valores contínuos o denominador <span class="math inline">\(P(\text{data})\)</span> vira uma integral bem grande e complicada de calcular:</p>
<p><span class="math display">\[P(\text{data})=\int_{\theta} P(\text{data} | \theta) \times P(\theta)d \theta\]</span></p>
<p>Em muitos casos essa integral vira <em>intrátavel</em> (incalculável) e portanto devemos achar outras maneiras de cálcular a probabilidade posterior <span class="math inline">\(P(\theta | \text{data})\)</span> de Bayes sem usar o denominador <span class="math inline">\(P(\text{data})\)</span>.</p>
<div id="para-quê-serve-o-denominador-ptextdata" class="section level2">
<h2>Para quê serve o denominador <span class="math inline">\(P(\text{data})\)</span>?</h2>
<p>Para normalizar a posterior com o intuito de torná-la uma distribuição probabilística válida. Isto quer dizer que a soma de todas as probabilidades dos eventos possíveis da distribuição probabilística devem ser iguais a 1:</p>
<ul>
<li>no caso de distribuição probabilística discreta: <span class="math inline">\(\sum_{\theta} P(\theta | \text{data}) = 1\)</span></li>
<li>no caso de distribuição probabilística contínua: <span class="math inline">\(\int_{\theta} P(\theta | \text{data})d \theta = 1\)</span></li>
</ul>
</div>
<div id="se-removermos-o-denominador-de-bayes-o-que-temos" class="section level2">
<h2>Se removermos o denominador de Bayes o que temos?</h2>
<p>Ao removermos o denominador <span class="math inline">\((\text{data})\)</span> temos que a posterior <span class="math inline">\(P(\theta | \text{data})\)</span> é <strong>proporcional</strong> à prior vezes a verossimilhança <span class="math inline">\(P(\theta) \cdot P(\text{data} | \theta)\)</span></p>
<p><span class="math display">\[P(\theta | \text{data}) \propto P(\theta) \cdot P(\text{data} | \theta)\]</span></p>
<p>Este <a href="https://youtu.be/8FbqSVFzmoY">vídeo do YouTube</a> explica muito bem o problema do denominador.</p>
</div>
<div id="simulação-montecarlo" class="section level2">
<h2>Simulação Montecarlo</h2>
<p>Aí que entra simulação Montecarlo. Simulação Montecarlo é usada quando não é possível coletar amostras de <span class="math inline">\(\theta\)</span> direto da distribuição probabilística posterior <span class="math inline">\(P(\theta | \text{data})\)</span>. Ao invés disso, nos coletamos amostras de maneira iterativa que a cada passo do processo nós esperamos que a distribuição da qual amostramos se torna cada vez mais similar à posterior <span class="math inline">\(P(\theta | \text{data})\)</span>.</p>
<blockquote>
<p>Não vamos cobrir a parte computacional ou a base matemática por trás de Markov Chain Monte Carlo (MCMC). Quem quiser, pode ler os capítulos 11 e 12 do livro Bayesian Data Analysis (3rd edition) de Gelman et al. (2014)</p>
</blockquote>
</div>
<div id="implementação-com-o-rstanarm" class="section level2">
<h2>Implementação com o <code>rstanarm</code></h2>
<p>Como configuração padrão, o pacote <code>rstanarm</code> utiliza uma modalidade de MCMC que usa dinâmicas Hamiltoneanas chamada <strong>Hamiltonian Monte Carlo</strong> (HMC). HMC é a modalidade de MCMC mais eficiente para gerar inferências Bayesianas. Em especial, <code>rstanarm</code> e a linguagem <code>Stan</code> usam HMC com uma técnica chamada <strong>No-U-Turn Sampling</strong> (NUTS), que faz HMC ser bem eficiente e não desperdiça amostragens.</p>
<p>Além disso, os argumentos padrões do HMC no <code>rstanarm</code> são o 4 correntes Markov de amostragem (<code>chains = 4</code>) e o 2.000 iterações de cada corrente (<code>iter = 2000</code>). Sendo que, por padrão, HMC descarta a primeira metade (1.000) das iterações como aquecimento (<code>warmup = floor(iter/2)</code>).</p>
<p>Relembrando o exemplo da aula de regressão linear, vamos usar o mesmo <em>dataset</em> <code>kidiq</code>. São dados de uma <em>survey</em> de mulheres adultas norte-americanas e seus respectivos filhos. Datado de 2007 possui 434 observações e 4 variáveis:</p>
<ul>
<li><code>kid_score</code>: QI da criança;</li>
<li><code>mom_hs</code>: binária (0 ou 1) se a mãe possui diploma de ensino médio;</li>
<li><code>mom_iq</code>: QI da mãe; e</li>
<li><code>mom_age</code>: idade da mãe.</li>
</ul>
<p>Vamos estimar um modelo de regressão linear Bayesiano na qual a variável dependente é <code>kid_score</code> e as independentes são <code>mom_hs</code> e <code>mom_iq</code>.</p>
<pre class="r"><code>options(mc.cores = parallel::detectCores())
options(Ncpus = parallel::detectCores())

library(rstanarm)
model &lt;- stan_glm(
  kid_score ~ mom_hs + mom_iq,
  data = kidiq
  )</code></pre>
<div id="métricas-da-simulação-mcmc" class="section level3">
<h3>Métricas da simulação MCMC</h3>
<p>Um modelo estimado pelo <code>rstanarm</code> pode ser inspecionado em relação ao desempenho da amostragem MCMC. Ao chamarmos a função <code>summary()</code> no modelo estimado há uma parte chamada <code>MCMC diagnostics</code>.</p>
<pre class="r"><code>summary(model)</code></pre>
<pre><code>## 
## Model Info:
##  function:     stan_glm
##  family:       gaussian [identity]
##  formula:      kid_score ~ mom_hs + mom_iq
##  algorithm:    sampling
##  sample:       4000 (posterior sample size)
##  priors:       see help(&#39;prior_summary&#39;)
##  observations: 434
##  predictors:   3
## 
## Estimates:
##               mean   sd   10%   50%   90%
## (Intercept) 25.9    5.8 18.5  25.8  33.5 
## mom_hs       6.0    2.2  3.2   6.0   8.8 
## mom_iq       0.6    0.1  0.5   0.6   0.6 
## sigma       18.2    0.6 17.4  18.1  19.0 
## 
## Fit Diagnostics:
##            mean   sd   10%   50%   90%
## mean_PPD 86.8    1.2 85.2  86.8  88.4 
## 
## The mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help(&#39;summary.stanreg&#39;)).
## 
## MCMC diagnostics
##               mcse Rhat n_eff
## (Intercept)   0.1  1.0  4999 
## mom_hs        0.0  1.0  4617 
## mom_iq        0.0  1.0  4494 
## sigma         0.0  1.0  5301 
## mean_PPD      0.0  1.0  4201 
## log-posterior 0.0  1.0  1823 
## 
## For each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).</code></pre>
<p>A seção <code>MCMC diagnostics</code> possui três colunas de valores para cada parâmetro estimado do modelo.</p>
<p>No nosso caso, temos três parâmetros importantes:</p>
<ol style="list-style-type: decimal">
<li>valor do coeficiente da variável <code>mom_hs</code></li>
<li>valor do coeficiente da variável <code>mom_iq</code></li>
<li>valor do erro residual do modelo linear <code>sigma</code></li>
</ol>
<p>As três métricas são:</p>
<ul>
<li><code>mcse</code>: <em>Monte Carlo Standard Error</em>, o erro de mensuração da amostragem Monte Carlo do parâmetro</li>
<li><code>n_eff</code>: uma aproximação crua do número de amostras efetivas amostradas pelo MCMC</li>
<li><code>Rhat</code>: uma métrica de convergência e estabilidade da corrente Markov</li>
</ul>
<p>A métrica mais importante para levarmos em consideração é a <code>Rhat</code> que é uma métrica que mensura se as correntes Markov são estáveis e convergiram para um valor durante o progresso total das simulações. Ela é basicamente a proporção de variação ao compararmos duas metades das correntes. Valor de <span class="math inline">\(1\)</span> implica em convergência e estabilidade. Como padrão o <code>Rhat</code> deve ser menor que <span class="math inline">\(1.05\)</span> para que a estimação Bayesiana seja válida.</p>
</div>
<div id="o-que-fazer-se-não-obtermos-convergência" class="section level3">
<h3>O que fazer se não obtermos convergência?</h3>
<p>Dependendo do modelo e dos dados é possível que HMC (mesmo com NUTS) não atinja convergência. Nesse caso, ao rodar o modelo <code>rstanarm</code> dará diversos avisos de divergências.</p>
<pre class="r"><code>bad_model &lt;- stan_glm(
  kid_score ~ mom_hs + mom_iq,
  data = kidiq,
  chains = 2,
  iter = 200
  )</code></pre>
<pre><code>## Warning: There were 1 chains where the estimated Bayesian Fraction of Missing Information was low. See
## http://mc-stan.org/misc/warnings.html#bfmi-low</code></pre>
<pre><code>## Warning: Examine the pairs() plot to diagnose sampling problems</code></pre>
<pre><code>## Warning: The largest R-hat is 2.45, indicating chains have not mixed.
## Running the chains for more iterations may help. See
## http://mc-stan.org/misc/warnings.html#r-hat</code></pre>
<pre><code>## Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.
## Running the chains for more iterations may help. See
## http://mc-stan.org/misc/warnings.html#bulk-ess</code></pre>
<pre><code>## Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.
## Running the chains for more iterations may help. See
## http://mc-stan.org/misc/warnings.html#tail-ess</code></pre>
<pre><code>## Warning: Markov chains did not converge! Do not analyze results!</code></pre>
<p>E vemos que o <code>Rhat</code> dos parâmetros estimados do modelo estão bem acima do limiar de <span class="math inline">\(1.05\)</span>.</p>
<pre class="r"><code>summary(bad_model)</code></pre>
<pre><code>## 
## Model Info:
##  function:     stan_glm
##  family:       gaussian [identity]
##  formula:      kid_score ~ mom_hs + mom_iq
##  algorithm:    sampling
##  sample:       200 (posterior sample size)
##  priors:       see help(&#39;prior_summary&#39;)
##  observations: 434
##  predictors:   3
## 
## Estimates:
##               mean   sd    10%   50%   90%
## (Intercept)  11.8   17.3 -13.2  17.1  30.9
## mom_hs        6.0    3.8   1.7   6.1  10.1
## mom_iq        0.6    0.1   0.5   0.6   0.7
## sigma        26.3    9.6  17.8  19.0  41.5
## 
## Fit Diagnostics:
##            mean   sd   10%   50%   90%
## mean_PPD 72.9   15.9 50.2  84.5  88.1 
## 
## The mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help(&#39;summary.stanreg&#39;)).
## 
## MCMC diagnostics
##               mcse  Rhat  n_eff
## (Intercept)    13.9   1.9   2  
## mom_hs          0.2   1.0 362  
## mom_iq          0.0   1.0 280  
## sigma           8.2   4.0   1  
## mean_PPD       13.9   3.1   1  
## log-posterior 134.8   4.2   1  
## 
## For each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).</code></pre>
</div>
</div>
<div id="gráficos-de-diagnósticos-do-mcmc" class="section level2">
<h2>Gráficos de Diagnósticos do MCMC</h2>
<p>O pacote <code>rstanarm</code> tem diversos gráficos interessantes de diagnósticos de convergência das simulações MCMC.</p>
<div id="traceplot" class="section level3">
<h3>Traceplot</h3>
<p>O <em>traceplot</em> é a sobreposição das amostragens MCMC das correntes para cada parâmetro estimado. A ideia é que as correntes se misturam e que não haja nenhuma inclinação ao longo das iterações.</p>
<p>Detalhe: aqui o <em>traceplot</em> usa somente as iterações válidas, após a remoção das iterações de <code>warmup</code>.</p>
<pre class="r"><code>plot(model, &quot;trace&quot;)</code></pre>
<p><img src="5-MCMC_files/figure-html/plot-diagnostics-1.png" width="672" /></p>
<pre class="r"><code>plot(bad_model, &quot;trace&quot;)</code></pre>
<p><img src="5-MCMC_files/figure-html/plot-diagnostics-2.png" width="672" /> ### <em>Posterior Predictive Check</em></p>
<p>Um bom gráfico de diagnóstico é o <em>posterior predictive check</em> que compara o histograma da variável dependente <span class="math inline">\(y\)</span> contra o histograma variáveis dependentes simuladas pelo modelo <span class="math inline">\(y_{\text{rep}}\)</span>. A ideia é que os histogramas reais e simulados se misturem e não haja divergências.</p>
<pre class="r"><code>pp_check(model)</code></pre>
<p><img src="5-MCMC_files/figure-html/pp-checks-1.png" width="672" /></p>
<pre class="r"><code>pp_check(bad_model)</code></pre>
<p><img src="5-MCMC_files/figure-html/pp-checks-2.png" width="672" /></p>
</div>
</div>
<div id="o-quê-fazer-para-que-as-métricas-sejam-convergentes" class="section level2">
<h2>O quê fazer para que as métricas sejam convergentes</h2>
<p>Se o seu modelo Bayesiano está com problemas de convergência há alguns passos que podem ser tentados. Aqui listados do mais simples para o mais complexo:</p>
<ol style="list-style-type: decimal">
<li><strong>Aumentar o número de iterações e correntes</strong>: primeira opção é aumentar o número de iterações do MCMC com o argumento <code>iter = XXX</code> e também é possível aumentar o número de correntes com o argumento <code>chains = X</code>. Lembrando que o padrão é <code>iter = 2000</code> e <code>chains = 4</code>.</li>
<li><strong>Alterar a rotina de adaptação do HMC</strong>: a segunda opção é fazer com que o algoritmo de amostragem HMC fique mais conservador (com proposições de pulos menores). Isto pode ser alterado com o argumento <code>adapt_delta</code> da lista de opções <code>control</code>. <code>control=list(adapt_delta=0.9)</code>. O padrão do <code>adapt_delta</code> é <code>control=list(adapt_delta=0.8)</code>. Então quaquer valor entre <span class="math inline">\(0.8\)</span> e <span class="math inline">\(1.0\)</span> o torna mais conservador.</li>
<li><strong>Reparametrização do Modelo</strong>: a terceira opção é reparametrizar o modelo. Há duas maneiras de parametrizar o modelo: a primeira com parametrização centrada (<em>centered parameterization</em>) e a segunda com parametrização não-centrada (<em>non-centered parameterization</em>). Não são assuntos que vamos cobrir aqui no curso. Recomendo o <a href="https://mc-stan.org/users/documentation/case-studies/divergences_and_bias.html">material de um dos desenvolvedores da linguagem <code>Stan</code>, Michael Betancourt</a>.</li>
<li><strong>Coletar mais dados</strong>: às vezes o modelo é complexo demais e precisamos de uma amostragem maior para conseguirmos estimativas estáveis.</li>
<li><strong>Repensar o modelo</strong>: falha de convergência quando temos uma amostragem adequada geralmente é por conta de uma especificação de priors e verossimilhança que não são compatíveis com os dados. Nesse caso, é preciso repensar o processo generativo de dados no qual os pressupostos do modelo estão ancorados.</li>
</ol>
</div>
<div id="ambiente" class="section level2">
<h2>Ambiente</h2>
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>## R version 4.0.3 (2020-10-10)
## Platform: x86_64-apple-darwin17.0 (64-bit)
## Running under: macOS Big Sur 10.16
## 
## Matrix products: default
## LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
## [1] carData_3.0-4   gapminder_0.3.0 skimr_2.1.2     rstanarm_2.21.1 Rcpp_1.0.5      readxl_1.3.1   
## 
## loaded via a namespace (and not attached):
##   [1] nlme_3.1-150         matrixStats_0.57.0   xts_0.12.1           threejs_0.3.3        rstan_2.21.2         repr_1.1.0          
##   [7] tools_4.0.3          utf8_1.1.4           R6_2.5.0             DT_0.16              colorspace_2.0-0     withr_2.3.0         
##  [13] tidyselect_1.1.0     gridExtra_2.3        prettyunits_1.1.1    processx_3.4.5       curl_4.3             compiler_4.0.3      
##  [19] cli_2.2.0            shinyjs_2.0.0        labeling_0.4.2       colourpicker_1.1.0   scales_1.1.1         dygraphs_1.1.1.6    
##  [25] ggridges_0.5.2       callr_3.5.1          stringr_1.4.0        digest_0.6.27        StanHeaders_2.21.0-6 minqa_1.2.4         
##  [31] rmarkdown_2.5        base64enc_0.1-3      pkgconfig_2.0.3      htmltools_0.5.0      lme4_1.1-26          highr_0.8           
##  [37] fastmap_1.0.1        htmlwidgets_1.5.2    rlang_0.4.9          shiny_1.5.0          farver_2.0.3         generics_0.1.0      
##  [43] zoo_1.8-8            jsonlite_1.7.1       crosstalk_1.1.0.1    gtools_3.8.2         dplyr_1.0.2          inline_0.3.17       
##  [49] magrittr_2.0.1       loo_2.3.1            bayesplot_1.7.2      Matrix_1.2-18        munsell_0.5.0        fansi_0.4.1         
##  [55] lifecycle_0.2.0      stringi_1.5.3        yaml_2.2.1           MASS_7.3-53          pkgbuild_1.1.0       plyr_1.8.6          
##  [61] grid_4.0.3           parallel_4.0.3       promises_1.1.1       crayon_1.3.4         miniUI_0.1.1.1       lattice_0.20-41     
##  [67] splines_4.0.3        knitr_1.30           ps_1.4.0             pillar_1.4.7         igraph_1.2.6         boot_1.3-25         
##  [73] markdown_1.1         shinystan_2.5.0      reshape2_1.4.4       codetools_0.2-18     stats4_4.0.3         rstantools_2.1.1    
##  [79] glue_1.4.2           evaluate_0.14        V8_3.4.0             RcppParallel_5.0.2   nloptr_1.2.2.2       vctrs_0.3.5         
##  [85] httpuv_1.5.4         cellranger_1.1.0     tidyr_1.1.2          gtable_0.3.0         purrr_0.3.4          assertthat_0.2.1    
##  [91] ggplot2_3.3.2        xfun_0.19            mime_0.9             xtable_1.8-4         later_1.1.0.1        survival_3.2-7      
##  [97] rsconnect_0.8.16     tibble_3.0.4         shinythemes_1.1.2    statmod_1.4.35       ellipsis_0.3.1</code></pre>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>

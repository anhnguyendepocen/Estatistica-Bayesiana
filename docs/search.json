{
  "articles": [
    {
      "path": "1-Comandos_Basicos.html",
      "title": "Comandos Básicos de R",
      "description": "Introdução ao R e aos comandos básicos do R.\n",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nLendo Arquivos de Dados\nCSV\nExcel\n\nGráficos\nAmbiente\n\nEste arquivo é um documento R Markdown. Ele é uma proposta de prosa com código em R, além de ser o formato preferido nosso de comunicar nossas análises. Quando renderizamos o documento no formato desejado. Todo código que é inserido nele é executado e as saídas são incorporadas no documento final. Isto vale para tabelas e gráficos. Por exemplo, podemos pedir para o R imprimir algo com a função print() e o resultado será o código que foi executado e o seu resultado.\n\n\nprint(\"Você executou um código\")\n\n\n[1] \"Você executou um código\"\n\nO formato R Markdown é muito flexível. Podemos fazer relatórios (em PDF, Word e HTML), apresentações (em PDF, PowerPoint e HTML), artigos acadêmicos, livros, websites1, blogs, CVs, etc.\n\nO site do primeiro autor foi feito usando a biblioteca {postcars} de R. O CV também foi feito em R usando a biblioteca {vitae}.\nLendo Arquivos de Dados\nCom o R conseguimos ler diversos tipo de arquivos de dados: CSV, texto, HTML, Excel, Stata, SPSS, Planilhas Google, Banco de Dados Relacionais, entre outros… Vamos demonstrar como ler arquivso de dados dos dois formatos mais comuns: CSV e Excel.\nCSV\nPara ler um arquivo CSV (.csv) no R execute a função read.csv() para arquivos CSV formato americano (vírgula como separador e decimais como ponto) ou a função read.csv2() para arquivos CSV formato europeu/brasileiro (ponto-e-vírgula como separador e decimais como vírgula). Não esqueça de designar a leitura para uma variável com o designador <-.\n\n\ndf <- read.csv2(\"datasets/mtcars.csv\", row.names = 1)\nhead(df)\n\n\n                  mpg cyl disp  hp drat  wt qsec vs am gear carb\nMazda RX4          21   6  160 110  3.9 2.6   16  0  1    4    4\nMazda RX4 Wag      21   6  160 110  3.9 2.9   17  0  1    4    4\nDatsun 710         23   4  108  93  3.9 2.3   19  1  1    4    1\nHornet 4 Drive     21   6  258 110  3.1 3.2   19  1  0    3    1\nHornet Sportabout  19   8  360 175  3.1 3.4   17  0  0    3    2\nValiant            18   6  225 105  2.8 3.5   20  1  0    3    1\n\nExcel\nPara ler um arquivo Excel (.xls ou .xlsx) no R é necessário importar um pacote chamado readxl que contem a função read_excel. Para importar um pacote no R executamos o comando library() com um argumento único sendo o nome do pacote. Caso não tenha o pacote instalado, deve instalar ele com o comando install.packages(). Não esqueça de colocar o nome do pacote entre aspas \"nome_do_pacote\" dentro do parênteses da função.\n\n\n# install.packages(\"readxl\")\nlibrary(readxl)\ndf <- read_excel(\"datasets/mtcars.xlsx\")\nhead(df)\n\n\n# A tibble: 6 x 12\n  ...1       mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear\n  <chr>    <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n1 Mazda R…  21       6   160   110  3.9   2.62  16.5     0     1     4\n2 Mazda R…  21       6   160   110  3.9   2.88  17.0     0     1     4\n3 Datsun …  22.8     4   108    93  3.85  2.32  18.6     1     1     4\n4 Hornet …  21.4     6   258   110  3.08  3.22  19.4     1     0     3\n5 Hornet …  18.7     8   360   175  3.15  3.44  17.0     0     0     3\n6 Valiant   18.1     6   225   105  2.76  3.46  20.2     1     0     3\n# … with 1 more variable: carb <dbl>\n\nGráficos\nGeralmente no R você pode plotar mostrar graficamente diversos objetos com o comando plot(). Quando você plota um dataset (conjunto de dados lido de um aquivo), o R retorna um gráfico chamado Pair Plot:\nNa diagonal: nome da variável (coluna do dataset)\nFora da diagonal: um gráfico de dispersão entre a variável no eixo horizontal e a variável no eixo vertical\nExemplo: na figura 1 veja a relação entre disp (cilindrada) e hp (cavalos de potência). Ela é uma relação positiva. Quanto maior disp maior hp.\n\n\nplot(mtcars)\n\n\n\n\nFigure 1: Pair Plot do dataset mtcars\n\n\n\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.3 (2020-10-10)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n[1] readxl_1.3.1\n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.5       knitr_1.30       magrittr_2.0.1  \n [4] downlit_0.2.1    rlang_0.4.10     fansi_0.4.1     \n [7] highr_0.8        stringr_1.4.0    tools_4.0.3     \n[10] parallel_4.0.3   xfun_0.19        utf8_1.1.4      \n[13] cli_2.2.0        htmltools_0.5.0  ellipsis_0.3.1  \n[16] yaml_2.2.1       digest_0.6.27    assertthat_0.2.1\n[19] tibble_3.0.4     lifecycle_0.2.0  crayon_1.3.4    \n[22] vctrs_0.3.6      distill_1.1      glue_1.4.2      \n[25] evaluate_0.14    rmarkdown_2.6    stringi_1.5.3   \n[28] compiler_4.0.3   pillar_1.4.7     cellranger_1.1.0\n[31] pkgconfig_2.0.3 \n\n\nesse website foi todo feito com R↩︎\n",
      "last_modified": "2020-12-31T05:43:55-03:00"
    },
    {
      "path": "2-Regressao_Linear.html",
      "title": "Regressão Linear Bayesiana",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nrstanarm\nRegressão Linear\nExemplo - Score de QI de crianças\nDescritivo das variáveis\nModelo 1 - mom_hs\nModelo 2 - mom_iq\nModelo 3 - mom_hs + mom_iq\nModelo 4 - mom_hs * mom_iq\n\nVariáveis qualitativas\nAtividade Prática\nWHO Life Expectancy\nWine Quality Kaggle Dataset\n\nReferências\nAmbiente\n\n\nA principal ferramenta para computação Bayesiana é a linguagem probabilística Stan. O nome homenageia Stanislaw Ulam: um matemático polonês membro do projeto Manhattan (bomba atômica americana) e um dos principais criadores do método de Monte Carlo de simulação. Stan foi lançado em 2012 e é a principal ferramenta utilizada hoje para inferência estatística Bayesiana. O programa roda em linguagem C++, mas possui interfaces para R, Python, MATLAB, Julia, Stata, Mathematica, Scala e Shell.\nO problema do Stan é que ele é uma linguagem de programação e, portanto, possui um acesso dificultado a não-programadores. Abaixo um código que mostra como é um programa escrito em Stan:\n\ndata {\n  int<lower=0> N;\n  vector<lower=0, upper=200>[N] kid_score;\n  vector<lower=0, upper=200>[N] mom_iq;\n}\nparameters {\n  vector[2] beta;\n  real<lower=0> sigma;\n}\nmodel {\n  sigma ~ cauchy(0, 2.5);\n  kid_score ~ normal(beta[1] + beta[2] * mom_iq, sigma);\n}\n\nrstanarm\nPara remediar isso, temos interfaces abstratas que interpretam a intenção do usuário e lidam com a parte mais obral de codificação. A principal delas é o pacote rstanarm, que a etmologia pode ser quebrada em:\nr: pacote para R\nstan: usa a linguagem probabilística Stan\narm: acrônimo para Applied Regression Modeling\nO código anterior de Stan ficaria assim no rstanarm:\n\n\nstan_glm(kid_score ~ mom_iq, data = dataset)\n\n\n\nRegressão Linear\nA ideia aqui é modelar uma variável dependente sendo a combinação linear de variáveis independentes.\n\\[y = \\alpha + \\boldsymbol{\\beta} \\textbf{X} + \\epsilon\\]\nAonde \\(y\\) é a variável dependente, \\(\\alpha\\) um constante, \\(\\boldsymbol{\\beta}\\) um vetor de coeficientes, \\(\\textbf{X}\\) uma matriz de dados e \\(\\epsilon\\) o erro do modelo.\nExemplo - Score de QI de crianças\nVamos aplicar modelagem estatística Bayesiana em um dataset famoso chamado kidiq. São dados de uma survey de mulheres adultas norte-americanas e seus respectivos filhos. Datado de 2007 possui 434 observações e 4 variáveis:\nkid_score: QI da criança;\nmom_hs: binária (0 ou 1) se a mãe possui diploma de ensino médio;\nmom_iq: QI da mãe; e\nmom_age: idade da mãe.\nVamos usar 4 modelos para modelar QI da criança (kid_score). Os primeiros dois modelos terão apenas um único preditor (mom_hs ou mom_iq), o terceiro usará dois preditores (mom_hs + mom_iq) e o quarto incluirá uma interação entre esses dois preditores (mom_hs * mom_iq),\nDescritivo das variáveis\nAntes de tudo, analise SEMPRE os dados em mãos. Graficamente e com tabelas.\nGráficos\n\n\n# Detectar quantos cores/processadores\noptions(mc.cores = parallel::detectCores())\noptions(Ncpus = parallel::detectCores())\n\nlibrary(rstanarm)\ndata(kidiq)\n\nboxplot(kidiq)\n\n\n\n\nTabelas\nPessoalmente uso o pacote skimr com a função skim():\n\n\nlibrary(skimr)\n\nskim(kidiq)\n\n\nTable 1: Data summary\nName\nkidiq\nNumber of rows\n434\nNumber of columns\n4\n_______________________\n\nColumn type frequency:\n\nnumeric\n4\n________________________\n\nGroup variables\nNone\nVariable type: numeric\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\nkid_score\n0\n1\n86.80\n20.41\n20\n74\n90\n102\n144\n▁▃▇▇▁\nmom_hs\n0\n1\n0.79\n0.41\n0\n1\n1\n1\n1\n▂▁▁▁▇\nmom_iq\n0\n1\n100.00\n15.00\n71\n89\n98\n110\n139\n▃▇▆▃▂\nmom_age\n0\n1\n22.79\n2.70\n17\n21\n23\n25\n29\n▂▅▇▃▂\n\nModelo 1 - mom_hs\nPrimeiro modelo é apenas a variável mom_hs como preditora:\n\n\nmodel_1 <- stan_glm(\n  kid_score ~ mom_hs,\n  data = kidiq\n  )\n\n\n\nPara ver os valores estimados pelo modelo usamos a função print:\n\n\nprint(model_1)\n\n\nstan_glm\n family:       gaussian [identity]\n formula:      kid_score ~ mom_hs\n observations: 434\n predictors:   2\n------\n            Median MAD_SD\n(Intercept) 77.6    2.1  \nmom_hs      11.7    2.4  \n\nAuxiliary parameter(s):\n      Median MAD_SD\nsigma 19.9    0.7  \n\n------\n* For help interpreting the printed output see ?print.stanreg\n* For info on the priors used see ?prior_summary.stanreg\n\nAlém disso, temos a função summary que traz tudo que queremos:\n\n\nsummary(model_1)\n\n\n\nModel Info:\n function:     stan_glm\n family:       gaussian [identity]\n formula:      kid_score ~ mom_hs\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 434\n predictors:   2\n\nEstimates:\n              mean   sd   10%   50%   90%\n(Intercept) 77.6    2.1 74.9  77.6  80.3 \nmom_hs      11.7    2.4  8.6  11.7  14.7 \nsigma       19.9    0.7 19.0  19.9  20.7 \n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 86.8    1.3 85.1  86.8  88.5 \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n              mcse Rhat n_eff\n(Intercept)   0.0  1.0  4102 \nmom_hs        0.0  1.0  4199 \nsigma         0.0  1.0  3693 \nmean_PPD      0.0  1.0  3920 \nlog-posterior 0.0  1.0  1460 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nModelo 2 - mom_iq\nSegundo modelo é apenas a variável mom_iq como preditora:\n\n\nmodel_2 <- stan_glm(\n  kid_score ~ mom_iq,\n  data = kidiq\n  )\n\n\n\nPodemos também especificar os percentis desejados no sumário:\n\n\nsummary(model_2, probs = c(0.025, 0.975))\n\n\n\nModel Info:\n function:     stan_glm\n family:       gaussian [identity]\n formula:      kid_score ~ mom_iq\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 434\n predictors:   2\n\nEstimates:\n              mean   sd   2.5%   98%\n(Intercept) 25.8    5.8 14.7   37.1 \nmom_iq       0.6    0.1  0.5    0.7 \nsigma       18.3    0.6 17.0   19.6 \n\nFit Diagnostics:\n           mean   sd   2.5%   98%\nmean_PPD 86.8    1.2 84.4   89.2 \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n              mcse Rhat n_eff\n(Intercept)   0.1  1.0  3789 \nmom_iq        0.0  1.0  3781 \nsigma         0.0  1.0  3917 \nmean_PPD      0.0  1.0  4000 \nlog-posterior 0.0  1.0  1929 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nModelo 3 - mom_hs + mom_iq\nTerceiro modelo usa as duas variáveis mom_hs e mom_iq como preditoras:\n\n\nmodel_3 <- stan_glm(\n  kid_score ~ mom_hs + mom_iq,\n  data = kidiq\n  )\n\n\n\n\n\nprint(model_3)\n\n\nstan_glm\n family:       gaussian [identity]\n formula:      kid_score ~ mom_hs + mom_iq\n observations: 434\n predictors:   3\n------\n            Median MAD_SD\n(Intercept) 25.7    5.6  \nmom_hs       6.0    2.2  \nmom_iq       0.6    0.1  \n\nAuxiliary parameter(s):\n      Median MAD_SD\nsigma 18.1    0.6  \n\n------\n* For help interpreting the printed output see ?print.stanreg\n* For info on the priors used see ?prior_summary.stanreg\n\nModelo 4 - mom_hs * mom_iq\nQuarto modelo usa as duas variáveis mom_hs e mom_iq como preditoras por meio de uma interação entre as duas:\n\n\nmodel_4 <- stan_glm(\n  kid_score ~ mom_hs * mom_iq,\n  data = kidiq\n  )\n\n\n\n\n\nprint(model_4)\n\n\nstan_glm\n family:       gaussian [identity]\n formula:      kid_score ~ mom_hs * mom_iq\n observations: 434\n predictors:   4\n------\n              Median MAD_SD\n(Intercept)   -9.4   13.0  \nmom_hs        48.8   14.6  \nmom_iq         0.9    0.1  \nmom_hs:mom_iq -0.5    0.2  \n\nAuxiliary parameter(s):\n      Median MAD_SD\nsigma 18.0    0.6  \n\n------\n* For help interpreting the printed output see ?print.stanreg\n* For info on the priors used see ?prior_summary.stanreg\n\nVariáveis qualitativas\nPara as variáveis qualitativas, o R usa um tipo especial de variável chamado factor. A codificação é em números inteiros \\(1,2,\\dots,K\\) mas a relação é distinta/nominal. Ou seja 1 é distinto de 2 e não 1 é 2x menor que 2. Não há relação quantitativa entre os valores das variáveis factor.\nIsso resolve o problema de termos variáveis qualitativas (também chamadas de dummy) em modelos de regressão. Para um factor com \\(K\\) quantidade de classes distintas, temos a possibilidade de criar \\(K-1\\) coeficientes de regressão. Um para cada classe e usando uma como basal (baseline).\n\n\nlibrary(gapminder)\nlevels(gapminder$continent)\n\n\n[1] \"Africa\"   \"Americas\" \"Asia\"     \"Europe\"   \"Oceania\" \n\nmodel_5 <- stan_glm(lifeExp ~ gdpPercap + factor(continent), data = gapminder)\n\n\n\n\n\nprint(model_5)\n\n\nstan_glm\n family:       gaussian [identity]\n formula:      lifeExp ~ gdpPercap + factor(continent)\n observations: 1704\n predictors:   6\n------\n                          Median MAD_SD\n(Intercept)               47.9    0.3  \ngdpPercap                  0.0    0.0  \nfactor(continent)Americas 13.6    0.6  \nfactor(continent)Asia      8.7    0.6  \nfactor(continent)Europe   17.6    0.6  \nfactor(continent)Oceania  18.2    1.8  \n\nAuxiliary parameter(s):\n      Median MAD_SD\nsigma 8.4    0.1   \n\n------\n* For help interpreting the printed output see ?print.stanreg\n* For info on the priors used see ?prior_summary.stanreg\n\nObs: para mudar o basal de referência de um factor use a função relevel() do R.\nAtividade Prática\nDois datasets estão disponíveis na pasta datasets/:\nWHO Life Expectancy Kaggle Dataset: datasets/WHO_Life_Exp.csv\nWine Quality Kaggle Dataset: datasets/Wine_Quality.csv\nWHO Life Expectancy\nEsse dataset possui 193 países nos últimos 15 anos.\nVariáveis\ncountry\nyear\nstatus\nlife_expectancy\nadult_mortality\ninfant_deaths\nalcohol\npercentage_expenditure\nhepatitis_b\nmeasles\nbmi\nunder_five_deaths\npolio\ntotal_expenditure\ndiphtheria\nhiv_aids\ngdp\npopulation\nthinness_1_19_years\nthinness_5_9_years\nincome_composition_of_resources\nschooling\nWine Quality Kaggle Dataset\nEsse dataset possui 1599 vinhos e estão relacionados com variantes tintas do vinho “Vinho Verde” português. Para mais detalhes, consulte a referência [Cortez et al., 2009]. Devido a questões de privacidade e logística, apenas variáveis físico-químicas (entradas) e sensoriais (a saída) estão disponíveis (por exemplo, não há dados sobre os tipos de uva, marca de vinho, preço de venda do vinho, etc.).\nfixed_acidity\nvolatile_acidity\ncitric_acid\nresidual_sugar\nchlorides\nfree_sulfur_dioxide\ntotal_sulfur_dioxide\ndensity\np_h\nsulphates\nalcohol\nquality\n\n\n###\n\n\n\nReferências\nP. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009.\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.3 (2020-10-10)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n[1] gapminder_0.3.0 skimr_2.1.2     rstanarm_2.21.1 Rcpp_1.0.5     \n[5] readxl_1.3.1   \n\nloaded via a namespace (and not attached):\n  [1] nlme_3.1-151         matrixStats_0.57.0   xts_0.12.1          \n  [4] lubridate_1.7.9.2    threejs_0.3.3        rprojroot_2.0.2     \n  [7] rstan_2.21.2         repr_1.1.0           tools_4.0.3         \n [10] utf8_1.1.4           R6_2.5.0             DT_0.16             \n [13] colorspace_2.0-0     withr_2.3.0          tidyselect_1.1.0    \n [16] gridExtra_2.3        prettyunits_1.1.1    processx_3.4.5      \n [19] downlit_0.2.1        curl_4.3             compiler_4.0.3      \n [22] cli_2.2.0            shinyjs_2.0.0        colourpicker_1.1.0  \n [25] bookdown_0.21        scales_1.1.1         dygraphs_1.1.1.6    \n [28] ggridges_0.5.2       callr_3.5.1          stringr_1.4.0       \n [31] digest_0.6.27        StanHeaders_2.21.0-7 minqa_1.2.4         \n [34] rmarkdown_2.6        base64enc_0.1-3      pkgconfig_2.0.3     \n [37] htmltools_0.5.0      lme4_1.1-26          fastmap_1.0.1       \n [40] highr_0.8            htmlwidgets_1.5.3    rlang_0.4.10        \n [43] rstudioapi_0.13      shiny_1.5.0          generics_0.1.0      \n [46] zoo_1.8-8            jsonlite_1.7.2       crosstalk_1.1.0.1   \n [49] gtools_3.8.2         dplyr_1.0.2          distill_1.1         \n [52] inline_0.3.17        magrittr_2.0.1       loo_2.4.1           \n [55] bayesplot_1.7.2      Matrix_1.3-0         munsell_0.5.0       \n [58] fansi_0.4.1          lifecycle_0.2.0      stringi_1.5.3       \n [61] yaml_2.2.1           MASS_7.3-53          pkgbuild_1.2.0      \n [64] plyr_1.8.6           grid_4.0.3           parallel_4.0.3      \n [67] promises_1.1.1       crayon_1.3.4         miniUI_0.1.1.1      \n [70] lattice_0.20-41      splines_4.0.3        knitr_1.30          \n [73] ps_1.5.0             pillar_1.4.7         igraph_1.2.6        \n [76] boot_1.3-25          markdown_1.1         shinystan_2.5.0     \n [79] reshape2_1.4.4       codetools_0.2-18     stats4_4.0.3        \n [82] rstantools_2.1.1     glue_1.4.2           evaluate_0.14       \n [85] V8_3.4.0             RcppParallel_5.0.2   nloptr_1.2.2.2      \n [88] vctrs_0.3.6          httpuv_1.5.4         cellranger_1.1.0    \n [91] tidyr_1.1.2          gtable_0.3.0         purrr_0.3.4         \n [94] assertthat_0.2.1     ggplot2_3.3.3        xfun_0.19           \n [97] mime_0.9             xtable_1.8-4         later_1.1.0.1       \n[100] survival_3.2-7       rsconnect_0.8.16     tibble_3.0.4        \n[103] shinythemes_1.1.2    statmod_1.4.35       ellipsis_0.3.1      \n\n\n\n\n",
      "last_modified": "2020-12-31T05:44:07-03:00"
    },
    {
      "path": "3-Distribuicoes_Estatisticas.html",
      "title": "Distribuições Estatísticas",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nDiscretas\nUniforme Discreta\nBinomial\nPoisson\n\nContínuas\nNormal / Gaussiana\nLog-normal\nExponencial\nDistribuição t de Student\n\nDashboard de Distribuições\nAmbiente\n\nA estatística usa distribuições probabilísticas como o motor de sua inferência na elaboração dos valores dos parâmetros estimados e suas incertezas.\nUma distribuição de probabilidade é a função matemática que fornece as probabilidades de ocorrência de diferentes resultados possíveis para um experimento. É uma descrição matemática de um fenômeno aleatório em termos de seu espaço amostral e as probabilidades de eventos (subconjuntos do espaço amostral)\nGeralmente usamos a notação X ~ Dist(par1, par2, ...). Onde X é a variável Dist é a distribuição e par os parâmetros que definem como a distribuição se comporta.\nDiscretas\nDistribuições de probabilidade discretas são aquelas que os resultados são números discretos (também chamados de números inteiros): \\(\\dots, -2, 1, 0,1,2,\\dots, N\\) e \\(N \\in \\mathbb{Z}\\).\nUniforme Discreta\nA distribuição uniforme discreta é uma distribuição de probabilidade simétrica em que um número finito de valores são igualmente prováveis de serem observados. Cada um dos \\(n\\) valores tem probabilidade igual \\(\\frac{1}{n}\\). Outra maneira de dizer “distribuição uniforme discreta” seria “um número conhecido e finito de resultados igualmente prováveis de acontecer”.\nA distribuição uniforme discreta possui dois parâmetros e sua notação é \\(U(a, b)\\):\nLimite Inferior (\\(a\\))\nLimite Superior (\\(b\\))\nExemplo: Um dado.\n\n\nx <- seq(1, 6)\ny <- dunif(x, min = 1, max = 6)\n\nplot(x, y, xlab=\"valor de x\",\n  ylab=\"Densidade\",\n  main=\"Distribuição Uniforme Discreta\",\n  lwd=2, col=\"red\"\n)\n\n\n\n\nBinomial\nA distribuição binomial descreve um evento do número de sucessos em uma sequência de \\(n\\) experimentos independentes, cada um fazendo uma pergunta sim-não.\nA distribuição binomial é freqüentemente usada para modelar o número de sucessos em uma amostra de tamanho \\(n\\) desenhada com substituição de uma população de tamanho \\(N\\).\nA distribuição binomial possui dois parâmetros e sua notação é \\(Bin(n, p)\\):\nNúmero de Experimentos (\\(n\\))\nProbabiliade de Sucessos (\\(p\\))\nExemplo: quantidade de caras em 5 lançamentos de uma moeda.\n\n\nx <- seq(0, 5)\n\nprobs <- c(0.1, 0.2, 0.5)\ncolors <- c(\"red\", \"blue\", \"darkgreen\")\nlabels <- c(\"p=0.1\", \"p=0.2\", \"p=0.5\")\n\nplot(NA, xlab=\"valor de x\",\n  ylab=\"Densidade\",\n  main=\"Comparativo de Distribuições Binomiais\",\n  xlim = c(0, 5),\n  ylim = c(0, 1))\n\nfor (i in 1:4){\n  lines(x, dbinom(x, 5, prob = probs[i]), lwd=2, col=colors[i])\n}\n\nlegend(\"topright\", inset=.05, title=\"Desvio Padrões\",\n  labels, lwd=2, lty=c(1, 1, 1, 1, 2), col=colors)\n\n\n\n\nPoisson\nA distribuição Poisson expressa a probabilidade de um determinado número de eventos ocorrerem em um intervalo fixo de tempo ou espaço se esses eventos ocorrerem com uma taxa média constante conhecida e independentemente do tempo desde o último evento. A distribuição de Poisson também pode ser usada para o número de eventos em outros intervalos especificados, como distância, área ou volume.\nA distribuição Poisson possui um parâmetro e sua notação é \\(pois(\\lambda)\\):\nTaxa (\\(\\lambda\\))\nExemplo: Quantidade de e-mails que você recebe diariamente. Quantidade de buracos que você encontra na rua.\n\n\nx <- seq(0, 20)\n\nrates <- c(1, 4, 10)\ncolors <- c(\"red\", \"blue\", \"darkgreen\")\nlabels <- c(\"taxa=1\", \"taxa=4\", \"taxa=10\")\n\nplot(NA, xlab=\"valor de x\",\n  ylab=\"Densidade\",\n  main=\"Comparativo de Distribuições Poisson\",\n  xlim = c(0, 20),\n  ylim = c(0, 0.5))\n\nfor (i in 1:4){\n  lines(x, dpois(x, lambda = rates[i]), lwd=2, col=colors[i])\n}\n\nlegend(\"topright\", inset=.05, title=\"Taxas\",\n  labels, lwd=2, lty=c(1, 1, 1, 1, 2), col=colors)\n\n\n\n\nContínuas\nDistribuições de probabilidade contínuas são aquelas que os resultados são valores em uma faixa contínua (também chamados de número reais): \\([-\\infty, \\infty] \\in \\mathbb{R}\\).\nNormal / Gaussiana\nEssa distribuição geralmente é usada nas ciências sociais e naturais para representar variáveis contínuas na qual as suas distribuições não são conhecidas. Esse pressuposto é por conta do teorema do limite central. O teorema do limite central afirma que, em algumas condições, a média de muitas amostras (observações) de uma variável aleatória com média e variância finitas é ela própria uma variável aleatória cuja distribuição converge para uma distribuição normal à medida que o número de amostras aumenta. Portanto, as quantidades físicas que se espera sejam a soma de muitos processos independentes (como erros de medição) muitas vezes têm distribuições que são quase normais.\nA distribuição normal possui dois parâmetros e sua notação é \\(N(\\mu, \\sigma^2)\\):\nMédia (\\(\\mu\\)): média da distribuição e também a moda e a mediana\nDesvio Padrão (\\(\\sigma\\)): a variância da distribuição (\\(\\sigma^2\\)) é uma média de dispersão das observações em relação à média\nExemplo: Altura, Peso etc.\n\n\nx <- seq(-4, 4, length = 100)\n\ndps <- c(0.5, 1, 2, 5)\ncolors <- c(\"red\", \"blue\", \"darkgreen\", \"gold\")\nlabels <- c(\"dp=0.5\", \"dp=1\", \"dp=2\", \"dp=5\")\n\nplot(NA, xlab=\"valor de x\",\n  ylab=\"Densidade\",\n  main=\"Comparativo de Distribuições Normais\",\n  xlim = c(-4, 4),\n  ylim = c(0, 1))\n\nfor (i in 1:4){\n  lines(x, dnorm(x, mean = 0, sd = dps[i]), lwd=2, col=colors[i])\n}\n\nlegend(\"topright\", inset=.05, title=\"Desvio Padrões\",\n  labels, lwd=2, lty=c(1, 1, 1, 1, 2), col=colors)\n\n\n\n\nLog-normal\nA distribuição Log-normal é uma distribuição de probabilidade contínua de uma variável aleatória cujo logaritmo é normalmente distribuído. Assim, se a variável aleatória \\(X\\) for distribuída normalmente por log, então \\(Y = \\ln (X)\\) terá uma distribuição normal.\nUma variável aleatória com distribuição logarítmica aceita apenas valores reais positivos. É um modelo conveniente e útil para medições em ciências exatas e de engenharia, bem como medicina, economia e outros campos, por ex. para energias, concentrações, comprimentos, retornos financeiros e outros valores.\nUm processo log-normal é a realização estatística do produto multiplicativo de muitas variáveis aleatórias independentes, cada uma das quais positiva.\nA distribuição log-normal possui dois parâmetros e sua notação é \\(Lognormal(\\mu, \\sigma^2)\\):\nMédia (\\(\\mu\\)): média do logaritmo natural da distribuição\nDesvio Padrão (\\(\\sigma\\)): a variância do logaritmo natural da distribuição (\\(\\sigma^2\\)) é uma média de dispersão das observações em relação à média\n\n\nx <- seq(0, 3, length = 100)\n\ndps <- c(0.25, 0.5, 1, 1.5)\ncolors <- c(\"red\", \"blue\", \"darkgreen\", \"gold\")\nlabels <- c(\"dp=0.25\", \"dp=0.5\", \"dp=1\", \"dp=1.5\")\n\nplot(NA, xlab=\"valor de x\",\n  ylab=\"Densidade\",\n  main=\"Comparativo de Distribuições Log-Normais\",\n  xlim = c(0, 3),\n  ylim = c(0, 2))\n\nfor (i in 1:4){\n  lines(x, dlnorm(x, mean = 0, sd = dps[i]), lwd=2, col=colors[i])\n}\n\nlegend(\"topright\", inset=.05, title=\"Desvio Padrões\",\n  labels, lwd=2, lty=c(1, 1, 1, 1, 2), col=colors)\n\n\n\n\nExponencial\nA distribuição exponencial é a distribuição de probabilidade do tempo entre eventos que ocorrem de forma contínua e independente a uma taxa média constante.\nA distribuição exponencial possui um parâmetro e sua notação é \\(Exp (\\lambda)\\):\nTaxa (\\(\\lambda\\))\nExemplo: Quanto tempo até o próximo terremoto. Quanto tempo até o próximo ônibus.\n\n\nx <- seq(0, 5, length = 100)\n\nrates <- c(0.5, 1, 1.5, 2)\ncolors <- c(\"red\", \"blue\", \"darkgreen\", \"gold\")\nlabels <- c(\"taxa=0.5\", \"taxa=1.0\", \"taxa=1.5\", \"taxa=2.0\")\n\nplot(NA, xlab=\"valor de x\",\n  ylab=\"Densidade\",\n  main=\"Comparativo de Distribuições Exponenciais\",\n  xlim = c(0, 5),\n  ylim = c(0, 1.5))\n\nfor (i in 1:4){\n  lines(x, dexp(x,rate = rates[i]), lwd=2, col=colors[i])\n}\n\nlegend(\"topright\", inset=.05, title=\"Taxas\",\n  labels, lwd=2, lty=c(1, 1, 1, 1, 2), col=colors)\n\n\n\n\nDistribuição t de Student\nA distribuição t de Student surge ao estimar a média de uma população normalmente distribuída em situações onde o tamanho da amostra é pequeno e o desvio padrão da população é desconhecido.\nSe tomarmos uma amostra de \\(n\\) observações de uma distribuição normal, então a distribuição t com \\(\\nu = n-1\\) graus de liberdade pode ser definida como a distribuição da localização da média da amostra em relação à média verdadeira, dividida pela desvio padrão da amostra, após multiplicar pelo termo padronizador \\(\\sqrt{n}\\).\nA distribuição t é simétrica e em forma de sino, como a distribuição normal, mas tem caudas mais pesadas, o que significa que é mais propensa a produzir valores que estão longe de sua média.\nA distribuição t de Student possui um parâmetro e sua notação é \\(Student (\\nu)\\):\nGraus de Liberdade (\\(\\nu\\)): controla o quanto ela se assemelha com uma distribuição normal\nExemplo: Uma base de dados cheia de outliers.\n\n\nx <- seq(-4, 4, length = 100)\n\ndegfs <- c(1, 3, 8, 30)\ncolors <- c(\"red\", \"blue\", \"darkgreen\", \"gold\")\nlabels <- c(\"df=1\", \"df=3\", \"df=8\", \"df=30\")\n\nplot(NA, xlab=\"valor de x\",\n  ylab=\"Densidade\",\n  main=\"Comparativo de Distribuições t de Student\",\n  xlim = c(-4, 4),\n  ylim = c(0, 0.5))\n\nfor (i in 1:4){\n  lines(x, dt(x,df = degfs[i]), lwd=2, col=colors[i])\n}\n\nlegend(\"topright\", inset=.05, title=\"Graus de Liberdade\",\n  labels, lwd=2, lty=c(1, 1, 1, 1, 2), col=colors)\n\n\n\n\nDashboard de Distribuições\nPara acessar todo o zoológico de distribuições use essa ferramenta do Ben Lambert (estatístico do Imperial College of London): https://ben18785.shinyapps.io/distribution-zoo/\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.3 (2020-10-10)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n[1] gapminder_0.3.0 skimr_2.1.2     rstanarm_2.21.1 Rcpp_1.0.5     \n[5] readxl_1.3.1   \n\nloaded via a namespace (and not attached):\n  [1] nlme_3.1-151         matrixStats_0.57.0   xts_0.12.1          \n  [4] lubridate_1.7.9.2    threejs_0.3.3        rprojroot_2.0.2     \n  [7] rstan_2.21.2         repr_1.1.0           tools_4.0.3         \n [10] utf8_1.1.4           R6_2.5.0             DT_0.16             \n [13] colorspace_2.0-0     withr_2.3.0          tidyselect_1.1.0    \n [16] gridExtra_2.3        prettyunits_1.1.1    processx_3.4.5      \n [19] downlit_0.2.1        curl_4.3             compiler_4.0.3      \n [22] cli_2.2.0            shinyjs_2.0.0        colourpicker_1.1.0  \n [25] bookdown_0.21        scales_1.1.1         dygraphs_1.1.1.6    \n [28] ggridges_0.5.2       callr_3.5.1          stringr_1.4.0       \n [31] digest_0.6.27        StanHeaders_2.21.0-7 minqa_1.2.4         \n [34] rmarkdown_2.6        base64enc_0.1-3      pkgconfig_2.0.3     \n [37] htmltools_0.5.0      lme4_1.1-26          fastmap_1.0.1       \n [40] highr_0.8            htmlwidgets_1.5.3    rlang_0.4.10        \n [43] rstudioapi_0.13      shiny_1.5.0          generics_0.1.0      \n [46] zoo_1.8-8            jsonlite_1.7.2       crosstalk_1.1.0.1   \n [49] gtools_3.8.2         dplyr_1.0.2          distill_1.1         \n [52] inline_0.3.17        magrittr_2.0.1       loo_2.4.1           \n [55] bayesplot_1.7.2      Matrix_1.3-0         munsell_0.5.0       \n [58] fansi_0.4.1          lifecycle_0.2.0      stringi_1.5.3       \n [61] yaml_2.2.1           MASS_7.3-53          pkgbuild_1.2.0      \n [64] plyr_1.8.6           grid_4.0.3           parallel_4.0.3      \n [67] promises_1.1.1       crayon_1.3.4         miniUI_0.1.1.1      \n [70] lattice_0.20-41      splines_4.0.3        knitr_1.30          \n [73] ps_1.5.0             pillar_1.4.7         igraph_1.2.6        \n [76] boot_1.3-25          markdown_1.1         shinystan_2.5.0     \n [79] reshape2_1.4.4       codetools_0.2-18     stats4_4.0.3        \n [82] rstantools_2.1.1     glue_1.4.2           evaluate_0.14       \n [85] V8_3.4.0             RcppParallel_5.0.2   nloptr_1.2.2.2      \n [88] vctrs_0.3.6          httpuv_1.5.4         cellranger_1.1.0    \n [91] tidyr_1.1.2          gtable_0.3.0         purrr_0.3.4         \n [94] assertthat_0.2.1     ggplot2_3.3.3        xfun_0.19           \n [97] mime_0.9             xtable_1.8-4         later_1.1.0.1       \n[100] survival_3.2-7       rsconnect_0.8.16     tibble_3.0.4        \n[103] shinythemes_1.1.2    statmod_1.4.35       ellipsis_0.3.1      \n\n\n\n\n",
      "last_modified": "2020-12-31T05:44:09-03:00"
    },
    {
      "path": "4-Priors.html",
      "title": "As famosas e controversas Priors",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nTipos de Priors\nPriors para os Modelos\nUniforme (Flat Prior)\nInformativas\nPadrões do rstanarm\nExemplo usando o mtcars\n\nPor quê não é interessante usar priors uniformes (flat priors)\nAtividade\n\nAmbiente\n\nA estatística bayesiana é caracterizada pelo uso de informação prévia embutida como probabilidade prévia \\(P(H)\\)\n\\[P(H | D)=\\frac{P(H) \\cdot P(D | H)}{P(D)}\\]\nTipos de Priors\nDe maneira geral, podemos ter 3 tipos de priors em uma abordagem Bayesiana:\nuniforme (Flat Prior): não recomendada\nfracamente informativa (weakly informative): pequena restrição com um pouco de senso comum e baixo conhecimento de domínio incorporado\ninformativa (informative): conhecimento de domínio incorporado\nPara se aprofundar mais recomendo a vignette do rstanarm sobre priors\nPriors para os Modelos\nArgumento\nUsado em\nAplica-se à\nprior_intercept\nTodas funções de modelagem exceto stan_polr and stan_nlmer\nConstante (intercept) do modelo, após centralização dos preditores\nprior\nTodas funções de modelagem\nCoeficientes de Regressão, não inclui coeficientes que variam por grupo em modelos multiníveis (veja prior_covariance)\nprior_aux\nstan_glm, stan_glmer, stan_gamm4, stan_nlmer\nParâmetro auxilizar (ex: desvio padrão (standard error - DP), interpretação depende do modelo\nprior_covariance\nstan_glmer, stan_gamm4, stan_nlmer\nMatrizes de covariância em modelos multiníveis\nUniforme (Flat Prior)\nEspecifica-se colocando o valor NULL (nulo em R) no. Exemplo:\nprior_intercept = NULL\nprior = NULL\nprior_aux = NULL\nColocando na função de modelo ficaria stan_glm(y ~ x1 + x2, data = df, prior = NULL, prior_intercept = NULL, prior_aux = NULL)\nInformativas\nColoca-se qualquer distribuição nos argumentos. Exemplo:\nprior = normal(0, 5)\nprior_intercept = student_t(4, 0, 10)\nprior_aux = cauchy(0, 3)\nColocando na função de modelo ficaria stan_glm(y ~ x1 + x2, data = df, prior = normal(0, 5), prior_intercept = student_t(4, 0, 10), prior_aux = cauchy(0, 3))\nPadrões do rstanarm\nAcontece se você não especifica nada nos argumentos de priors. O comportamento difere conforme o modelo. Aqui divido em modelos gaussianos (segue uma likelihood gaussiana ou normal) e outros (binomial, poisson etc)\nModelos Gaussianos\nConstante(Intercept): centralizada com média \\(\\mu_y\\) e desvio padrão de \\(2.5 \\sigma_y\\) - prior_intercept = normal(mean_y, 2.5 * sd_y)\nCoeficientes: para cada coeficiente média \\(\\mu = 0\\) e desvio padrão de \\(2.5\\times\\frac{\\sigma_y}{\\sigma_{x_k}}\\) - prior = normal(0, 2.5 * sd_y/sd_xk)\nOutros Modelos (Binomial, Poisson etc.)\nConstante(Intercept): centralizada com média \\(\\mu = 0\\) e desvio padrão de \\(2.5 \\sigma_y\\) - prior_intercept = normal(0, 2.5 * sd_y)\nCoeficientes: para cada coeficiente média \\(\\mu = 0\\) e desvio padrão de \\(2.5\\times\\frac{1}{\\sigma_{x_k}}\\) - prior = normal(0, 2.5 * 1/sd_xk)\n\nOBS: em todos os modelos prior_aux, o desvio padrão do erro do modelo, a prior padrão é uma distribuição exponencial com taxa \\(\\frac{1}{\\sigma_y}\\): prior_aux = exponential(1/sd_y)\n\nExemplo usando o mtcars\nVamos estimar modelos Bayesianos usando o dataset já conhecido mtcars. Para constar, calcularemos alguns valores antes de ver o sumário das priors:\n\\(\\mu_y\\): média do mpg - 20.09\n\\(2.5 \\sigma_y\\): 2.5 * sd(mtcars$mpg) - 15.07\n\\(2.5\\times\\frac{\\sigma_y}{\\sigma_{x_{\\text{wt}}}}\\): 2.5 * (sd(mtcars$mpg)/sd(mtcars$wt)) - 15.4\n\\(2.5\\times\\frac{\\sigma_y}{\\sigma_{x_{\\text{am}}}}\\): 2.5 * (sd(mtcars$mpg)/sd(mtcars$am)) - 30.2\n\\(\\frac{1}{\\sigma_y}\\): 1/sd(mtcars$mpg) - 0.17\nA função prior_summary resulta um sumário conciso das priors utilizadas em um modelo. Coloque como argumento o modelo estimado:\n\n\nlibrary(rstanarm)\ndefault_prior_test <- stan_glm(mpg ~ wt + am, data = mtcars, chains = 1)\n\n\n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 6.6e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.66 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.049999 seconds (Warm-up)\nChain 1:                0.044845 seconds (Sampling)\nChain 1:                0.094844 seconds (Total)\nChain 1: \n\nprior_summary(default_prior_test)\n\n\nPriors for model 'default_prior_test' \n------\nIntercept (after predictors centered)\n  Specified prior:\n    ~ normal(location = 20, scale = 2.5)\n  Adjusted prior:\n    ~ normal(location = 20, scale = 15)\n\nCoefficients\n  Specified prior:\n    ~ normal(location = [0,0], scale = [2.5,2.5])\n  Adjusted prior:\n    ~ normal(location = [0,0], scale = [15.40,30.20])\n\nAuxiliary (sigma)\n  Specified prior:\n    ~ exponential(rate = 1)\n  Adjusted prior:\n    ~ exponential(rate = 0.17)\n------\nSee help('prior_summary.stanreg') for more details\n\nAgora com priors especificadas:\nComo há dois coeficientes eu especifico médias iguais (\\(0\\)), porém desvios padrões diferentes (\\(5\\) para wt e \\(6\\) para am) usando a função de combinar do R (combine) - c()\n\n\ncustom_prior_test <- stan_glm(mpg ~ wt + am, data = mtcars, chains = 1,\n         prior = normal(c(0,0), c(5,6)),\n         prior_intercept = student_t(4, 0, 10),\n         prior_aux = cauchy(0, 3))\n\n\n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 6.8e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.68 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.050753 seconds (Warm-up)\nChain 1:                0.056209 seconds (Sampling)\nChain 1:                0.106962 seconds (Total)\nChain 1: \n\nprior_summary(custom_prior_test)\n\n\nPriors for model 'custom_prior_test' \n------\nIntercept (after predictors centered)\n ~ student_t(df = 4, location = 0, scale = 10)\n\nCoefficients\n ~ normal(location = [0,0], scale = [5,6])\n\nAuxiliary (sigma)\n ~ half-cauchy(location = 0, scale = 3)\n------\nSee help('prior_summary.stanreg') for more details\n\nPor quê não é interessante usar priors uniformes (flat priors)\nUma prior totalmente uniforme ou chapada (flat) é algo que devemos evitar pelo simples motivo que ela encompassa a premissa de que “tudo é possível”. Não há limites na crença de que tamanho o valor deve ser.\nPriors chapadas e super-vagas geralmente não são recomendadas e algum esforço deve ser incluído para ter, pelo menos, priors um pouco informativa. Por exemplo, é comum esperar que os tamanhos de efeito realistas sejam da ordem de magnitude \\(0.1\\) em uma escala padronizada (por exemplo, uma inovação educacional que pode melhorar as pontuações dos testes em \\(0.1\\) desvios padrão). Nesse caso, um prior de \\(N \\sim (0,1)\\) poderia ser considerado muito informativo, de uma maneira ruim, pois coloca a maior parte de sua massa em valores de parâmetro que são irrealisticamente grandes em valor absoluto. O ponto geral aqui é que se considerarmos uma prior como “fraca” ou “forte”, isso é uma propriedade não apenas da prior, mas também da pergunta que está sendo feita.\nQuando dizemos que a prior é “pouco informativa”, o que queremos dizer é que, se houver uma quantidade razoavelmente grande de dados, a likelihood dominará e a prior não será importante. Se os dados forem fracos, porém, esta “prior fracamente informativo” influenciará fortemente a inferência posterior.\nNão se esqueça que distribuição normal tem suporte \\(\\mathbb{R}\\), ou seja pode acontecer qualquer número entre \\(-\\infty\\) até \\(\\infty\\) independente da média \\(\\mu\\) ou desvio padrão \\(\\sigma\\).\nAtividade\nRegressão linear pensando nas priors. Usar o dataset do pacote carData chamado Salaries\n\n\nlibrary(carData)\ndata(\"Salaries\")\n?Salaries\n\n\n\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.3 (2020-10-10)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n[1] carData_3.0-4   gapminder_0.3.0 skimr_2.1.2     rstanarm_2.21.1\n[5] Rcpp_1.0.5      readxl_1.3.1   \n\nloaded via a namespace (and not attached):\n  [1] nlme_3.1-151         matrixStats_0.57.0   xts_0.12.1          \n  [4] lubridate_1.7.9.2    threejs_0.3.3        rprojroot_2.0.2     \n  [7] rstan_2.21.2         repr_1.1.0           tools_4.0.3         \n [10] utf8_1.1.4           R6_2.5.0             DT_0.16             \n [13] colorspace_2.0-0     withr_2.3.0          tidyselect_1.1.0    \n [16] gridExtra_2.3        prettyunits_1.1.1    processx_3.4.5      \n [19] downlit_0.2.1        curl_4.3             compiler_4.0.3      \n [22] cli_2.2.0            shinyjs_2.0.0        colourpicker_1.1.0  \n [25] bookdown_0.21        scales_1.1.1         dygraphs_1.1.1.6    \n [28] ggridges_0.5.2       callr_3.5.1          stringr_1.4.0       \n [31] digest_0.6.27        StanHeaders_2.21.0-7 minqa_1.2.4         \n [34] rmarkdown_2.6        base64enc_0.1-3      pkgconfig_2.0.3     \n [37] htmltools_0.5.0      lme4_1.1-26          fastmap_1.0.1       \n [40] highr_0.8            htmlwidgets_1.5.3    rlang_0.4.10        \n [43] rstudioapi_0.13      shiny_1.5.0          generics_0.1.0      \n [46] zoo_1.8-8            jsonlite_1.7.2       crosstalk_1.1.0.1   \n [49] gtools_3.8.2         dplyr_1.0.2          distill_1.1         \n [52] inline_0.3.17        magrittr_2.0.1       loo_2.4.1           \n [55] bayesplot_1.7.2      Matrix_1.3-0         munsell_0.5.0       \n [58] fansi_0.4.1          lifecycle_0.2.0      stringi_1.5.3       \n [61] yaml_2.2.1           MASS_7.3-53          pkgbuild_1.2.0      \n [64] plyr_1.8.6           grid_4.0.3           parallel_4.0.3      \n [67] promises_1.1.1       crayon_1.3.4         miniUI_0.1.1.1      \n [70] lattice_0.20-41      splines_4.0.3        knitr_1.30          \n [73] ps_1.5.0             pillar_1.4.7         igraph_1.2.6        \n [76] boot_1.3-25          markdown_1.1         shinystan_2.5.0     \n [79] reshape2_1.4.4       codetools_0.2-18     stats4_4.0.3        \n [82] rstantools_2.1.1     glue_1.4.2           evaluate_0.14       \n [85] V8_3.4.0             RcppParallel_5.0.2   nloptr_1.2.2.2      \n [88] vctrs_0.3.6          httpuv_1.5.4         cellranger_1.1.0    \n [91] tidyr_1.1.2          gtable_0.3.0         purrr_0.3.4         \n [94] assertthat_0.2.1     ggplot2_3.3.3        xfun_0.19           \n [97] mime_0.9             xtable_1.8-4         later_1.1.0.1       \n[100] survival_3.2-7       rsconnect_0.8.16     tibble_3.0.4        \n[103] shinythemes_1.1.2    statmod_1.4.35       ellipsis_0.3.1      \n\n\n\n\n",
      "last_modified": "2020-12-31T05:44:10-03:00"
    },
    {
      "path": "5-MCMC.html",
      "title": "Markov Chain Monte Carlo",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nPara quê serve o denominador \\(P(\\text{data})\\)?\nSe removermos o denominador de Bayes o que temos?\nSimulação Montecarlo\nImplementação com o rstanarm\nMétricas da simulação MCMC\nO que fazer se não obtermos convergência?\n\nGráficos de Diagnósticos do MCMC\nTraceplot\nPosterior Predictive Check\n\nO quê fazer para que as métricas sejam convergentes\nAmbiente\n\nA principal barreira computacional para estatística bayesiana é o denominador \\(P(\\text{data})\\) da fórmula de Bayes:\n\\[P(\\theta | \\text{data})=\\frac{P(\\theta) \\cdot P(\\text{data} | \\theta)}{P(\\text{data})}\\]\nEm casos discretos podemos fazer o denominador virar a soma de todos os paramêtros usando a regra da cadeia de probabilidade:\n\\[P(A,B|C)=P(A|B,C) \\times P(B|C)\\]\nIsto também é chamado de marginalização:\n\\[P(\\text{data})=\\sum_{\\theta} P(\\text{data} | \\theta) \\times P(\\theta)\\]\nPorém no caso de valores contínuos o denominador \\(P(\\text{data})\\) vira uma integral bem grande e complicada de calcular:\n\\[P(\\text{data})=\\int_{\\theta} P(\\text{data} | \\theta) \\times P(\\theta)d \\theta\\]\nEm muitos casos essa integral vira intrátavel (incalculável) e portanto devemos achar outras maneiras de cálcular a probabilidade posterior \\(P(\\theta | \\text{data})\\) de Bayes sem usar o denominador \\(P(\\text{data})\\).\nPara quê serve o denominador \\(P(\\text{data})\\)?\nPara normalizar a posterior com o intuito de torná-la uma distribuição probabilística válida. Isto quer dizer que a soma de todas as probabilidades dos eventos possíveis da distribuição probabilística devem ser iguais a 1:\nno caso de distribuição probabilística discreta: \\(\\sum_{\\theta} P(\\theta | \\text{data}) = 1\\)\nno caso de distribuição probabilística contínua: \\(\\int_{\\theta} P(\\theta | \\text{data})d \\theta = 1\\)\nSe removermos o denominador de Bayes o que temos?\nAo removermos o denominador \\((\\text{data})\\) temos que a posterior \\(P(\\theta | \\text{data})\\) é proporcional à prior vezes a verossimilhança \\(P(\\theta) \\cdot P(\\text{data} | \\theta)\\)\n\\[P(\\theta | \\text{data}) \\propto P(\\theta) \\cdot P(\\text{data} | \\theta)\\]\nEste vídeo do YouTube explica muito bem o problema do denominador.\nSimulação Montecarlo\nAí que entra simulação Montecarlo. Simulação Montecarlo é usada quando não é possível coletar amostras de \\(\\theta\\) direto da distribuição probabilística posterior \\(P(\\theta | \\text{data})\\). Ao invés disso, nos coletamos amostras de maneira iterativa que a cada passo do processo nós esperamos que a distribuição da qual amostramos se torna cada vez mais similar à posterior \\(P(\\theta | \\text{data})\\).\n\nNão vamos cobrir a parte computacional ou a base matemática por trás de Markov Chain Monte Carlo (MCMC). Quem quiser, pode ler os capítulos 11 e 12 do livro Bayesian Data Analysis (3rd edition) de Gelman et al. (2014)\n\nImplementação com o rstanarm\nComo configuração padrão, o pacote rstanarm utiliza uma modalidade de MCMC que usa dinâmicas Hamiltoneanas chamada Hamiltonian Monte Carlo (HMC). HMC é a modalidade de MCMC mais eficiente para gerar inferências Bayesianas. Em especial, rstanarm e a linguagem Stan usam HMC com uma técnica chamada No-U-Turn Sampling (NUTS), que faz HMC ser bem eficiente e não desperdiça amostragens.\nAlém disso, os argumentos padrões do HMC no rstanarm são o 4 correntes Markov de amostragem (chains = 4) e o 2.000 iterações de cada corrente (iter = 2000). Sendo que, por padrão, HMC descarta a primeira metade (1.000) das iterações como aquecimento (warmup = floor(iter/2)).\nRelembrando o exemplo da aula de regressão linear, vamos usar o mesmo dataset kidiq. São dados de uma survey de mulheres adultas norte-americanas e seus respectivos filhos. Datado de 2007 possui 434 observações e 4 variáveis:\nkid_score: QI da criança;\nmom_hs: binária (0 ou 1) se a mãe possui diploma de ensino médio;\nmom_iq: QI da mãe; e\nmom_age: idade da mãe.\nVamos estimar um modelo de regressão linear Bayesiano na qual a variável dependente é kid_score e as independentes são mom_hs e mom_iq.\n\n\noptions(mc.cores = parallel::detectCores())\noptions(Ncpus = parallel::detectCores())\n\nlibrary(rstanarm)\nmodel <- stan_glm(\n  kid_score ~ mom_hs + mom_iq,\n  data = kidiq\n  )\n\n\n\nMétricas da simulação MCMC\nUm modelo estimado pelo rstanarm pode ser inspecionado em relação ao desempenho da amostragem MCMC. Ao chamarmos a função summary() no modelo estimado há uma parte chamada MCMC diagnostics.\n\n\nsummary(model)\n\n\n\nModel Info:\n function:     stan_glm\n family:       gaussian [identity]\n formula:      kid_score ~ mom_hs + mom_iq\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 434\n predictors:   3\n\nEstimates:\n              mean   sd   10%   50%   90%\n(Intercept) 25.7    6.1 17.8  25.7  33.4 \nmom_hs       6.0    2.2  3.2   6.0   8.7 \nmom_iq       0.6    0.1  0.5   0.6   0.6 \nsigma       18.2    0.6 17.4  18.2  19.0 \n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 86.8    1.2 85.3  86.8  88.3 \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n              mcse Rhat n_eff\n(Intercept)   0.1  1.0  5382 \nmom_hs        0.0  1.0  4536 \nmom_iq        0.0  1.0  4801 \nsigma         0.0  1.0  4834 \nmean_PPD      0.0  1.0  4348 \nlog-posterior 0.0  1.0  1766 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nA seção MCMC diagnostics possui três colunas de valores para cada parâmetro estimado do modelo.\nNo nosso caso, temos três parâmetros importantes:\nvalor do coeficiente da variável mom_hs\nvalor do coeficiente da variável mom_iq\nvalor do erro residual do modelo linear sigma\nAs três métricas são:\nmcse: Monte Carlo Standard Error, o erro de mensuração da amostragem Monte Carlo do parâmetro\nn_eff: uma aproximação crua do número de amostras efetivas amostradas pelo MCMC\nRhat: uma métrica de convergência e estabilidade da corrente Markov\nA métrica mais importante para levarmos em consideração é a Rhat que é uma métrica que mensura se as correntes Markov são estáveis e convergiram para um valor durante o progresso total das simulações. Ela é basicamente a proporção de variação ao compararmos duas metades das correntes. Valor de \\(1\\) implica em convergência e estabilidade. Como padrão o Rhat deve ser menor que \\(1.05\\) para que a estimação Bayesiana seja válida.\nO que fazer se não obtermos convergência?\nDependendo do modelo e dos dados é possível que HMC (mesmo com NUTS) não atinja convergência. Nesse caso, ao rodar o modelo rstanarm dará diversos avisos de divergências.\n\n\nbad_model <- stan_glm(\n  kid_score ~ mom_hs + mom_iq,\n  data = kidiq,\n  chains = 2,\n  iter = 200\n  )\n\n\n\nE vemos que o Rhat dos parâmetros estimados do modelo estão bem acima do limiar de \\(1.05\\).\n\n\nsummary(bad_model)\n\n\n\nModel Info:\n function:     stan_glm\n family:       gaussian [identity]\n formula:      kid_score ~ mom_hs + mom_iq\n algorithm:    sampling\n sample:       200 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 434\n predictors:   3\n\nEstimates:\n              mean   sd   10%   50%   90%\n(Intercept) 26.2    6.4 17.4  26.5  34.5 \nmom_hs       5.6    2.3  2.9   5.6   8.4 \nmom_iq       0.6    0.1  0.5   0.6   0.6 \nsigma       18.2    0.7 17.3  18.2  19.0 \n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 86.7    1.1 85.2  86.7  88.0 \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n              mcse Rhat n_eff\n(Intercept)   0.5  1.0  182  \nmom_hs        0.1  1.0  244  \nmom_iq        0.0  1.0  202  \nsigma         0.1  1.0  123  \nmean_PPD      0.2  1.1   52  \nlog-posterior 0.2  1.0   92  \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nGráficos de Diagnósticos do MCMC\nO pacote rstanarm tem diversos gráficos interessantes de diagnósticos de convergência das simulações MCMC.\nTraceplot\nO traceplot é a sobreposição das amostragens MCMC das correntes para cada parâmetro estimado. A ideia é que as correntes se misturam e que não haja nenhuma inclinação ao longo das iterações.\nDetalhe: aqui o traceplot usa somente as iterações válidas, após a remoção das iterações de warmup.\n\n\nplot(model, \"trace\")\n\n\n\nplot(bad_model, \"trace\")\n\n\n\n\nPosterior Predictive Check\nUm bom gráfico de diagnóstico é o posterior predictive check que compara o histograma da variável dependente \\(y\\) contra o histograma variáveis dependentes simuladas pelo modelo \\(y_{\\text{rep}}\\). A ideia é que os histogramas reais e simulados se misturem e não haja divergências.\n\n\npp_check(model)\n\n\n\npp_check(bad_model)\n\n\n\n\nO quê fazer para que as métricas sejam convergentes\nSe o seu modelo Bayesiano está com problemas de convergência há alguns passos que podem ser tentados. Aqui listados do mais simples para o mais complexo:\nAumentar o número de iterações e correntes: primeira opção é aumentar o número de iterações do MCMC com o argumento iter = XXX e também é possível aumentar o número de correntes com o argumento chains = X. Lembrando que o padrão é iter = 2000 e chains = 4.\nAlterar a rotina de adaptação do HMC: a segunda opção é fazer com que o algoritmo de amostragem HMC fique mais conservador (com proposições de pulos menores). Isto pode ser alterado com o argumento adapt_delta da lista de opções control. control=list(adapt_delta=0.9). O padrão do adapt_delta é control=list(adapt_delta=0.8). Então quaquer valor entre \\(0.8\\) e \\(1.0\\) o torna mais conservador.\nReparametrização do Modelo: a terceira opção é reparametrizar o modelo. Há duas maneiras de parametrizar o modelo: a primeira com parametrização centrada (centered parameterization) e a segunda com parametrização não-centrada (non-centered parameterization). Não são assuntos que vamos cobrir aqui no curso. Recomendo o material de um dos desenvolvedores da linguagem Stan, Michael Betancourt.\nColetar mais dados: às vezes o modelo é complexo demais e precisamos de uma amostragem maior para conseguirmos estimativas estáveis.\nRepensar o modelo: falha de convergência quando temos uma amostragem adequada geralmente é por conta de uma especificação de priors e verossimilhança que não são compatíveis com os dados. Nesse caso, é preciso repensar o processo generativo de dados no qual os pressupostos do modelo estão ancorados.\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.3 (2020-10-10)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n[1] carData_3.0-4   gapminder_0.3.0 skimr_2.1.2     rstanarm_2.21.1\n[5] Rcpp_1.0.5      readxl_1.3.1   \n\nloaded via a namespace (and not attached):\n  [1] nlme_3.1-151         matrixStats_0.57.0   xts_0.12.1          \n  [4] lubridate_1.7.9.2    threejs_0.3.3        rprojroot_2.0.2     \n  [7] rstan_2.21.2         repr_1.1.0           tools_4.0.3         \n [10] utf8_1.1.4           R6_2.5.0             DT_0.16             \n [13] colorspace_2.0-0     withr_2.3.0          tidyselect_1.1.0    \n [16] gridExtra_2.3        prettyunits_1.1.1    processx_3.4.5      \n [19] downlit_0.2.1        curl_4.3             compiler_4.0.3      \n [22] cli_2.2.0            shinyjs_2.0.0        labeling_0.4.2      \n [25] colourpicker_1.1.0   bookdown_0.21        scales_1.1.1        \n [28] dygraphs_1.1.1.6     ggridges_0.5.2       callr_3.5.1         \n [31] stringr_1.4.0        digest_0.6.27        StanHeaders_2.21.0-7\n [34] minqa_1.2.4          rmarkdown_2.6        base64enc_0.1-3     \n [37] pkgconfig_2.0.3      htmltools_0.5.0      lme4_1.1-26         \n [40] fastmap_1.0.1        highr_0.8            htmlwidgets_1.5.3   \n [43] rlang_0.4.10         rstudioapi_0.13      shiny_1.5.0         \n [46] farver_2.0.3         generics_0.1.0       zoo_1.8-8           \n [49] jsonlite_1.7.2       crosstalk_1.1.0.1    gtools_3.8.2        \n [52] dplyr_1.0.2          distill_1.1          inline_0.3.17       \n [55] magrittr_2.0.1       loo_2.4.1            bayesplot_1.7.2     \n [58] Matrix_1.3-0         munsell_0.5.0        fansi_0.4.1         \n [61] lifecycle_0.2.0      stringi_1.5.3        yaml_2.2.1          \n [64] MASS_7.3-53          pkgbuild_1.2.0       plyr_1.8.6          \n [67] grid_4.0.3           parallel_4.0.3       promises_1.1.1      \n [70] crayon_1.3.4         miniUI_0.1.1.1       lattice_0.20-41     \n [73] splines_4.0.3        knitr_1.30           ps_1.5.0            \n [76] pillar_1.4.7         igraph_1.2.6         boot_1.3-25         \n [79] markdown_1.1         shinystan_2.5.0      reshape2_1.4.4      \n [82] codetools_0.2-18     stats4_4.0.3         rstantools_2.1.1    \n [85] glue_1.4.2           evaluate_0.14        V8_3.4.0            \n [88] RcppParallel_5.0.2   nloptr_1.2.2.2       vctrs_0.3.6         \n [91] httpuv_1.5.4         cellranger_1.1.0     tidyr_1.1.2         \n [94] gtable_0.3.0         purrr_0.3.4          assertthat_0.2.1    \n [97] ggplot2_3.3.3        xfun_0.19            mime_0.9            \n[100] xtable_1.8-4         later_1.1.0.1        survival_3.2-7      \n[103] rsconnect_0.8.16     tibble_3.0.4         shinythemes_1.1.2   \n[106] statmod_1.4.35       ellipsis_0.3.1      \n\n\n\n\n",
      "last_modified": "2020-12-31T05:44:16-03:00"
    },
    {
      "path": "6-Regressao_Binomial.html",
      "title": "Modelos Lineares Generalizados - Binomial",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nComparativo com a Regressão Linear\nExemplo\n\nRegressão logística com o rstanarm\nInterpretação dos coeficientes\nPriors\nAtividade Prática\nAmbiente\n\nSaindo do universo dos modelos lineares, começamos a nos aventurar nos modelos linares generalizados (generalized linear models - GLM). O primeiro deles é a regressão logística (também chamada de regressão binomial).\nUma regressão logística se comporta exatamente como um modelo linear: faz uma predição simplesmente computando uma soma ponderada das variáveis independentes, mais uma constante. Porém ao invés de retornar um valor contínuo, como a regressão linear, retorna a função logística desse valor.\n\\[\\operatorname{Logística}(x) = \\frac{1}{1 + e^{(-x)}}\\]\nUsamos regressão logística quando a nossa variável dependente é binária. Ela possui apenas dois valores distintos, geralmente codificados como \\(0\\) ou \\(1\\).\n\n\nx <- seq(-10, 10, length.out = 100)\nsig <- 1 / (1 + exp(-x))\nplot(x, sig, type = \"l\", lwd=2, ylab = \"Logística(x)\")\n\n\n\n\nComparativo com a Regressão Linear\n\\[ \\operatorname{Linear} = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\dots + \\theta_n x_n\\]\n\\(\\operatorname{Linear}\\) - regressão linear\n\\(\\theta\\) - parâmetro do modelo\n\\(n\\) - número de atributos (features)\n\\(x_i\\) - o valor do inésimo atributo (feature)\n\\(\\hat{p} = \\sigma(\\operatorname{Linear}) = \\frac{1}{1 + e^{-\\operatorname{Linear}}}\\)\n\\(\\hat{p}\\) - probabilidade prevista da observação ser 1\n\\(\\hat{y}=\\left\\{\\begin{array}{ll} 0 & \\text { se } \\hat{p} < 0.5 \\\\ 1 & \\text { se } \\hat{p} \\geq 0.5 \\end{array}\\right.\\)\nExemplo\n\\[\\mathrm{Previsão~de~Morte} = \\sigma \\big(-10 + 10\\times \\mathrm{cancer} + 12 \\times \\mathrm{diabetes} + 8 \\times \\mathrm{obesidade} \\big)\\]\nRegressão logística com o rstanarm\nO rstanarm pode tolerar qualquer modelo linear generalizado e regressão logística não é uma exceção. Para rodar um modelo binomial no rstanarm é preciso simplesmente alterar o argumento family da função stan_glm.\nPara exemplo, usaremos um dataset chamado wells do pacote rstanarm. É uma survey com 3200 residentes de uma pequena área de Bangladesh na qual os lençóis freáticos estão contaminados por arsênico. Respondentes com altos níveis de arsênico nos seus poços foram encorajados para trocar a sua fonte de água para uma níveis seguros de arsênico.\nPossui as seguintes variáveis:\nswitch: dependente indicando se o respondente trocou ou não de poço\narsenic: nível de arsênico do poço do respondente\ndist: distância em metros da casa do respondente até o poço seguro mais próximo\nassociation: dummy se os membros da casa do respondente fazem parte de alguma organização da comunidade\neduc: quantidade de anos de educação que o chefe da família respondente possui\n\n\noptions(mc.cores = parallel::detectCores())\noptions(Ncpus = parallel::detectCores())\n\nlibrary(rstanarm)\ndata(wells)\n\nmodel_binomial <- stan_glm(\n  switch ~ dist + arsenic + assoc + educ,\n  data = wells,\n  family = binomial()\n    )\n\n\n\n\n\nsummary(model_binomial)\n\n\n\nModel Info:\n function:     stan_glm\n family:       binomial [logit]\n formula:      switch ~ dist + arsenic + assoc + educ\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 3020\n predictors:   5\n\nEstimates:\n              mean   sd   10%   50%   90%\n(Intercept) -0.2    0.1 -0.3  -0.2   0.0 \ndist         0.0    0.0  0.0   0.0   0.0 \narsenic      0.5    0.0  0.4   0.5   0.5 \nassoc       -0.1    0.1 -0.2  -0.1   0.0 \neduc         0.0    0.0  0.0   0.0   0.1 \n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 0.6    0.0  0.6   0.6   0.6  \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n              mcse Rhat n_eff\n(Intercept)   0.0  1.0  6972 \ndist          0.0  1.0  4800 \narsenic       0.0  1.0  4876 \nassoc         0.0  1.0  5751 \neduc          0.0  1.0  6112 \nmean_PPD      0.0  1.0  4560 \nlog-posterior 0.0  1.0  1516 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nInterpretação dos coeficientes\nAo vermos a fórmula de regressão binomial vemos que para analisarmos o efeito de um preditor na variável dependente temos que calcular o valor logístico dos coeficientes do preditor. E interpretamos como chances (odds ratio) na qual 1 é neutro e qualquer valor abaixo de 1 tende a respostas codificadas como 0 e qualquer valor acima de 1 tende a respostas codificadas como 1.\n\\[\\text{odds ratio} = e^{(x)}\\]\n\n\ncoeff <- exp(model_binomial$coefficients)\ncoeff\n\n\n(Intercept)        dist     arsenic       assoc        educ \n       0.85        0.99        1.60        0.88        1.04 \n\n(Intercept): a chance basal de respondentes mudarem de poço (15% de não mudarem)\ndist: a cada metro de distância diminui a chance de troca de poço em 1%\narsenic: a cada incremento do nível de arsênico aumenta a chance de troca de poço em 60%\nassoc: residências com membros que fazem parte de alguma organização da comunidade diminui a chance de troca de poço em 12%\neduc: a cada incremento dos anos de estudo aumenta a chance de troca de poço em 4%\nPriors\nrstanarm possui as seguintes configurações como padrão de priors para regressão binomial:\nConstante (Intercept): centralizada com média \\(\\mu = 0\\) e desvio padrão de \\(2.5 \\sigma_y\\) - prior_intercept = normal(0, 2.5 * sd_y)\nCoeficientes: para cada coeficiente média \\(\\mu = 0\\) and standard deviation of \\(2.5\\times\\frac{1}{\\sigma_{x_k}}\\) - prior = normal(0, 2.5 * 1/sd_xk)\nErro residual (prior_aux): uma distribuição exponencial com taxa \\(\\frac{1}{\\sigma_y}\\): prior_aux = exponential(1/sd_y)\nAtividade Prática\nDois datasets estão disponíveis na pasta datasets/:\nTitanic Survival: datasets/Titanic_Survival.csv\nIBM HR Analytics Employee Attrition & Performance: datasets/IBM_HR_Attrition.csv\n\n\n###\n\n\n\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.3 (2020-10-10)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n[1] carData_3.0-4   gapminder_0.3.0 skimr_2.1.2     rstanarm_2.21.1\n[5] Rcpp_1.0.5      readxl_1.3.1   \n\nloaded via a namespace (and not attached):\n  [1] nlme_3.1-151         matrixStats_0.57.0   xts_0.12.1          \n  [4] lubridate_1.7.9.2    threejs_0.3.3        rprojroot_2.0.2     \n  [7] rstan_2.21.2         repr_1.1.0           tools_4.0.3         \n [10] utf8_1.1.4           R6_2.5.0             DT_0.16             \n [13] colorspace_2.0-0     withr_2.3.0          tidyselect_1.1.0    \n [16] gridExtra_2.3        prettyunits_1.1.1    processx_3.4.5      \n [19] downlit_0.2.1        curl_4.3             compiler_4.0.3      \n [22] cli_2.2.0            shinyjs_2.0.0        labeling_0.4.2      \n [25] colourpicker_1.1.0   bookdown_0.21        scales_1.1.1        \n [28] dygraphs_1.1.1.6     ggridges_0.5.2       callr_3.5.1         \n [31] stringr_1.4.0        digest_0.6.27        StanHeaders_2.21.0-7\n [34] minqa_1.2.4          rmarkdown_2.6        base64enc_0.1-3     \n [37] pkgconfig_2.0.3      htmltools_0.5.0      lme4_1.1-26         \n [40] fastmap_1.0.1        highr_0.8            htmlwidgets_1.5.3   \n [43] rlang_0.4.10         rstudioapi_0.13      shiny_1.5.0         \n [46] farver_2.0.3         generics_0.1.0       zoo_1.8-8           \n [49] jsonlite_1.7.2       crosstalk_1.1.0.1    gtools_3.8.2        \n [52] dplyr_1.0.2          distill_1.1          inline_0.3.17       \n [55] magrittr_2.0.1       loo_2.4.1            bayesplot_1.7.2     \n [58] Matrix_1.3-0         munsell_0.5.0        fansi_0.4.1         \n [61] lifecycle_0.2.0      stringi_1.5.3        yaml_2.2.1          \n [64] MASS_7.3-53          pkgbuild_1.2.0       plyr_1.8.6          \n [67] grid_4.0.3           parallel_4.0.3       promises_1.1.1      \n [70] crayon_1.3.4         miniUI_0.1.1.1       lattice_0.20-41     \n [73] splines_4.0.3        knitr_1.30           ps_1.5.0            \n [76] pillar_1.4.7         igraph_1.2.6         boot_1.3-25         \n [79] markdown_1.1         shinystan_2.5.0      reshape2_1.4.4      \n [82] codetools_0.2-18     stats4_4.0.3         rstantools_2.1.1    \n [85] glue_1.4.2           evaluate_0.14        V8_3.4.0            \n [88] RcppParallel_5.0.2   nloptr_1.2.2.2       vctrs_0.3.6         \n [91] httpuv_1.5.4         cellranger_1.1.0     tidyr_1.1.2         \n [94] gtable_0.3.0         purrr_0.3.4          assertthat_0.2.1    \n [97] ggplot2_3.3.3        xfun_0.19            mime_0.9            \n[100] xtable_1.8-4         later_1.1.0.1        survival_3.2-7      \n[103] rsconnect_0.8.16     tibble_3.0.4         shinythemes_1.1.2   \n[106] statmod_1.4.35       ellipsis_0.3.1      \n\n\n\n\n",
      "last_modified": "2020-12-31T05:44:19-03:00"
    },
    {
      "path": "7-Regressao_Poisson.html",
      "title": "Modelos Lineares Generalizados - Poisson",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nRegressão de Poisson com o rstanarm\nInterpretação dos coeficientes\nPriors\nAtividade Prática\nAmbiente\n\nSaindo do universo dos modelos lineares, começamos a nos aventurar nos modelos linares generalizados (generalized linear models - GLM). O segundo deles é a regressão de Poisson.\nUma regressão de Poisson se comporta exatamente como um modelo linear: faz uma predição simplesmente computando uma soma ponderada das variáveis independentes, mais uma constante. Porém ao invés de retornar um valor contínuo, como a regressão linear, retorna o logarítmo natural desse valor.\n\\[\\log(y)= \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\dots + \\theta_n x_n\\] que é o mesmo que\n\\[y = e^{(\\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\dots + \\theta_n x_n)}\\] Regressão de Poisson é usada quando a nossa variável dependente só pode tomar valores positivos e discretos (número inteiros), geralmente em contextos de dados de contagem.\n\n\nx <- seq(-5, 5, length.out = 100)\nplot(x, exp(x), type = \"l\", lwd=2, ylab = \"Exponencial(x)\")\n\n\n\n\nRegressão de Poisson com o rstanarm\nO rstanarm pode tolerar qualquer modelo linear generalizado e regressão de Poisson não é uma exceção. Para rodar um modelo de Poisson no rstanarm é preciso simplesmente alterar o argumento family da função stan_glm.\nPara exemplo, usaremos um dataset chamado roaches do pacote rstanarm. É uma base de dados com 262 observações sobre a eficácia de um sistema de controle de pragas em reduzir o número de baratas (roaches) em apartamentos urbanos.\nPossui as seguintes variáveis:\ny: variável dependente - número de baratas mortas\nroach1: número de baratas antes da dedetização\ntreatment: dummy para indicar se o apartamento foi dedetizado ou não\nsenior: dummy para indicar se há apenas idosos no apartamento\nexposure2: número de dias que as armadilhas de baratas foram usadas\n\n\noptions(mc.cores = parallel::detectCores())\noptions(Ncpus = parallel::detectCores())\n\nlibrary(rstanarm)\ndata(roaches)\n\nmodel_poisson <- stan_glm(\n  y ~ roach1 + treatment + senior,\n  data = roaches,\n  family = poisson()\n    )\n\n\n\n\n\nsummary(model_poisson)\n\n\n\nModel Info:\n function:     stan_glm\n family:       poisson [log]\n formula:      y ~ roach1 + treatment + senior\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 262\n predictors:   4\n\nEstimates:\n              mean   sd   10%   50%   90%\n(Intercept)  3.1    0.0  3.1   3.1   3.2 \nroach1       0.0    0.0  0.0   0.0   0.0 \ntreatment   -0.5    0.0 -0.5  -0.5  -0.5 \nsenior      -0.4    0.0 -0.4  -0.4  -0.3 \n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 25.6    0.4 25.1  25.7  26.2 \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n              mcse Rhat n_eff\n(Intercept)   0.0  1.0  3521 \nroach1        0.0  1.0  3872 \ntreatment     0.0  1.0  3266 \nsenior        0.0  1.0  3080 \nmean_PPD      0.0  1.0  3851 \nlog-posterior 0.0  1.0  1974 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nInterpretação dos coeficientes\nAo vermos a fórmula de regressão de Poisson vemos que para analisarmos o efeito de um preditor na variável dependente temos que calcular o valor \\(e\\) elevado ao coeficiente do preditor\n\\[y = e^{(\\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\dots + \\theta_n x_n)}\\]\n\n\ncoeff <- exp(model_poisson$coefficients)\ncoeff\n\n\n(Intercept)      roach1   treatment      senior \n      23.00        1.01        0.60        0.69 \n\n(Intercept): a taxa basal de exterminação das baratas \\(y\\)\nroach1: a cada uma barata antes da exterminação há um aumento de 1.01 barata exterminada a mais\ntreatment: se o apartamento foi dedetizado há um aumento de 0.6 barata exterminada a mais\nsenior: se o apartamento possui somente idoso há um aumento de 0.69 barata exterminada a mais\nPriors\nrstanarm possui as seguintes configurações como padrão de priors para regressão de Poisson:\nConstante (Intercept): centralizada com média \\(\\mu = 0\\) e desvio padrão de \\(2.5 \\sigma_y\\) - prior_intercept = normal(0, 2.5 * sd_y)\nCoeficientes: para cada coeficiente média \\(\\mu = 0\\) and standard deviation of \\(2.5\\times\\frac{1}{\\sigma_{x_k}}\\) - prior = normal(0, 2.5 * 1/sd_xk)\nErro residual (prior_aux): uma distribuição exponencial com taxa \\(\\frac{1}{\\sigma_y}\\): prior_aux = exponential(1/sd_y)\nAtividade Prática\nUm datasets está disponível na pasta datasets/:\nNew York City - East River Bicycle Crossings: datasets/NYC_bicycle.csv\n\n\n###\n\n\n\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.3 (2020-10-10)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n[1] carData_3.0-4   gapminder_0.3.0 skimr_2.1.2     rstanarm_2.21.1\n[5] Rcpp_1.0.5      readxl_1.3.1   \n\nloaded via a namespace (and not attached):\n  [1] nlme_3.1-151         matrixStats_0.57.0   xts_0.12.1          \n  [4] lubridate_1.7.9.2    threejs_0.3.3        rprojroot_2.0.2     \n  [7] rstan_2.21.2         repr_1.1.0           tools_4.0.3         \n [10] utf8_1.1.4           R6_2.5.0             DT_0.16             \n [13] colorspace_2.0-0     withr_2.3.0          tidyselect_1.1.0    \n [16] gridExtra_2.3        prettyunits_1.1.1    processx_3.4.5      \n [19] downlit_0.2.1        curl_4.3             compiler_4.0.3      \n [22] cli_2.2.0            shinyjs_2.0.0        labeling_0.4.2      \n [25] colourpicker_1.1.0   bookdown_0.21        scales_1.1.1        \n [28] dygraphs_1.1.1.6     ggridges_0.5.2       callr_3.5.1         \n [31] stringr_1.4.0        digest_0.6.27        StanHeaders_2.21.0-7\n [34] minqa_1.2.4          rmarkdown_2.6        base64enc_0.1-3     \n [37] pkgconfig_2.0.3      htmltools_0.5.0      lme4_1.1-26         \n [40] fastmap_1.0.1        highr_0.8            htmlwidgets_1.5.3   \n [43] rlang_0.4.10         rstudioapi_0.13      shiny_1.5.0         \n [46] farver_2.0.3         generics_0.1.0       zoo_1.8-8           \n [49] jsonlite_1.7.2       crosstalk_1.1.0.1    gtools_3.8.2        \n [52] dplyr_1.0.2          distill_1.1          inline_0.3.17       \n [55] magrittr_2.0.1       loo_2.4.1            bayesplot_1.7.2     \n [58] Matrix_1.3-0         munsell_0.5.0        fansi_0.4.1         \n [61] lifecycle_0.2.0      stringi_1.5.3        yaml_2.2.1          \n [64] MASS_7.3-53          pkgbuild_1.2.0       plyr_1.8.6          \n [67] grid_4.0.3           parallel_4.0.3       promises_1.1.1      \n [70] crayon_1.3.4         miniUI_0.1.1.1       lattice_0.20-41     \n [73] splines_4.0.3        knitr_1.30           ps_1.5.0            \n [76] pillar_1.4.7         igraph_1.2.6         boot_1.3-25         \n [79] markdown_1.1         shinystan_2.5.0      reshape2_1.4.4      \n [82] codetools_0.2-18     stats4_4.0.3         rstantools_2.1.1    \n [85] glue_1.4.2           evaluate_0.14        V8_3.4.0            \n [88] RcppParallel_5.0.2   nloptr_1.2.2.2       vctrs_0.3.6         \n [91] httpuv_1.5.4         cellranger_1.1.0     tidyr_1.1.2         \n [94] gtable_0.3.0         purrr_0.3.4          assertthat_0.2.1    \n [97] ggplot2_3.3.3        xfun_0.19            mime_0.9            \n[100] xtable_1.8-4         later_1.1.0.1        survival_3.2-7      \n[103] rsconnect_0.8.16     tibble_3.0.4         shinythemes_1.1.2   \n[106] statmod_1.4.35       ellipsis_0.3.1      \n\n\n\n\n",
      "last_modified": "2020-12-31T05:44:22-03:00"
    },
    {
      "path": "8-Regressao_Robusta.html",
      "title": "Modelos Lineares Generalizados - Regressão Robusta",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nComparativo Normal vs Student\nModelos Lineares Robustos com o pacote brms\nExemplo com os dados de Prestígio de Duncan (1961)\nPriors do brms\n\nAtividade Prática\nAmbiente\n\nLembrando da curva normal gaussiana que possui um formato de sino. Ela não é muito alongada nas “pontas”. Ou seja, as observações não fogem muito da média. Quando usamos essa distribuição como verossimilhança na inferência modelos Bayesianos, forçamos a que todas as estimativas sejam condicionadas à uma distribuição normal da variável dependente. Se nos dados houverem muitas observações com valores discrepantes (bem diferentes da média - outliers), isso faz com que as estimativas dos coeficientes das variáveis independentes fiquem instáveis. Isso ocorre porquê a distribuição normal não consegue contemplar observações muito divergentes da média sem mudar a média de local.\n\n\nx <- seq(-4, 4, length = 100)\nplot(x, dnorm(x),\n     type = \"l\",\n     col = \"red\",\n     lwd = 3,\n     xlab=\"valor de x\",\n     ylab=\"Densidade\",\n     main=\"Distribuição Normal\",\n     sub = \"Média 0 e Desvio Padrão 1\",\n     xlim = c(-4, 4),\n     ylim = c(0, 0.4))\n\n\n\n\nEntão precisamos de uma distribuição mais “maleável” como verossimilhança. Precisamos de uma distribuição que seja mais robusta à observações discrepantes (outliers). Precisamos de uma distribuição similar à Normal mas que possua caudas mais longas para justamente contemplar observações muito longe da média sem ter que mudar a média de local. Para isso temos a distribuição t de Student. Lembrando o formato dela:\n\n\nx <- seq(-4, 4, length = 100)\nplot(x, dt(x, 2),\n     type = \"l\",\n     col = \"blue\",\n     lwd = 3,\n     xlab=\"valor de x\",\n     ylab=\"Densidade\",\n     main=\"Distribuição t de Student\",\n     sub = \"Média 0 e Graus de Liberdade 2\",\n     xlim = c(-4, 4),\n     ylim = c(0, 0.4))\n\n\n\n\nComparativo Normal vs Student\nReparem nas caudas:\n\n\nplot(NA, xlab=\"valor de x\",\n  ylab = \"Densidade\",\n  main = \"Comparativo de Distribuições\",\n  sub = \"Normal vs t de Student\",\n  xlim = c(-4, 4),\n  ylim = c(0, 0.4))\nlines(x, dnorm(x), lwd = 2, col = \"red\")\nlines(x, dt(x, df = 2), lwd = 2, col = \"blue\")\nlegend(\"topright\", legend=c(\"Normal\", \"Student\"),\n       col=c(\"red\", \"blue\"), title=\"Distribuições\", lty=1)\n\n\n\n\nModelos Lineares Robustos com o pacote brms\nO rstanarm não possui a possibilidade de usar distribuições t de Student como verossimilhança do modelo Bayesiano. Para usarmos distribuições t de Student, precisamos do pacote brms. O brms usa a mesma síntaxe que o rstanarm e a única diferença é que o brms não possui os modelos pré-compilados então os modelos devem ser todos compilados antes de serem rodados. A diferença prática é que você irá esperar alguns instantes antes do R começar a simular MCMC e amostrar do modelo.\nA função que usa-se para designar modelos lineares no brms é a brm():\nbrm(y ~ x1 + x2 + x3,\n    data = df,\n    family = student)\nExemplo com os dados de Prestígio de Duncan (1961)\nPara exemplicar regressão robusta vamos usar um dataset que tem muitas observações discrepantes (outliers) chamado Duncan. Ele possui 45 observações sobre ocupações nos EUA e 4 variáveis:\ntype: Tipo de ocupação. Uma variável qualitativa:\nprof - profissional ou de gestão\nwc - white-collar (colarinho branco)\nbc - blue-collar (colarinho azul)\n\nincome: Porcentagem de pessoas da ocupação que ganham acima $ 3.500 por ano em 1950 (mais ou menos $36.000 em 2017);\neducation: Porcentagem de pessoas da ocupação que possuem diploma de ensino médio em 1949 (que, sendo cínicos, podemos dizer que é de certa maneira equivalente com diploma de Doutorado em 2017); e\nprestige:Porcentagem de respondentes na pesquisa que classificam a sua ocupação como no mínimo “boa” em respeito à prestígio.\n\n\nduncan <- read.csv2(\"datasets/Duncan.csv\", row.names = 1, stringsAsFactors = T)\n\nhist(duncan$prestige,\n     main = \"Histograma do Prestígio\",\n     xlab = \"Prestígio\",\n     ylab = \"Frequência\")\n\n\n\n\nPrimeiro modelo: Regressão Linear\nVamos estimar primeiramente uma regressão linear usando a distribuição Normal como verossimilhança:\n\n\nlibrary(rstanarm)\nmodel_1 <- stan_glm(\n  prestige ~ income + education,\n  data = duncan,\n  family = gaussian\n)\n\n\n\nE na sequência o sumário das estimativas do modelo, assim como os diagnósticos da MCMC:\n\n\nsummary(model_1)\n\n\n\nModel Info:\n function:     stan_glm\n family:       gaussian [identity]\n formula:      prestige ~ income + education\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 45\n predictors:   3\n\nEstimates:\n              mean   sd    10%   50%   90%\n(Intercept)  -6.0    4.3 -11.5  -6.0  -0.7\nincome        0.6    0.1   0.4   0.6   0.8\neducation     0.5    0.1   0.4   0.5   0.7\nsigma        13.7    1.5  11.9  13.6  15.7\n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 47.6    2.9 43.9  47.7  51.3 \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n              mcse Rhat n_eff\n(Intercept)   0.1  1.0  4321 \nincome        0.0  1.0  2257 \neducation     0.0  1.0  2337 \nsigma         0.0  1.0  2680 \nmean_PPD      0.0  1.0  3496 \nlog-posterior 0.0  1.0  1521 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nAparentemente parece que o modelo possui boas métricas mas quando olhamos o posterior predictive check, vemos uma bagunça:\n\n\npp_check(model_1, nsamples = 45)\n\n\n\n\nSegundo modelo: Regressão Robusta\nPara rodar um modelo Bayesiano que usa como verossimilhança a distribuição t de Student é somente usar a mesma síntaxe que o stan_glm mas colocando argumento family = student:\n\n\nlibrary(brms)\nmodel_2 <- brm(\n  prestige ~ income + education,\n  data = duncan,\n  family = student\n)\n\n\n\nE na sequência o sumário das estimativas do modelo, assim como os diagnósticos da MCMC. Vemos que as estimativas não alteraram muito. Além disso temos um novo parâmetro estimado pelo modelo que é o parâmetro nu (\\(\\nu\\)), que é os graus de liberdade da distribuição t de Student usada como verossimilhança:\n\n\nsummary(model_2, prob =  0.9)\n\n\n Family: student \n  Links: mu = identity; sigma = identity; nu = identity \nFormula: prestige ~ income + education \n   Data: duncan (Number of observations: 45) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nPopulation-Level Effects: \n          Estimate Est.Error l-90% CI u-90% CI Rhat Bulk_ESS Tail_ESS\nIntercept    -6.68      4.08   -13.34    -0.02 1.00     4783     3577\nincome        0.65      0.13     0.43     0.87 1.00     1937     2405\neducation     0.52      0.11     0.34     0.69 1.00     2038     2215\n\nFamily Specific Parameters: \n      Estimate Est.Error l-90% CI u-90% CI Rhat Bulk_ESS Tail_ESS\nsigma    12.35      1.90     9.21    15.43 1.00     2213     1553\nnu       18.06     13.38     3.59    45.21 1.00     2284     1865\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nMas a posterior predictive check ficou com um aspecto muito melhor que o modelo linear:\n\n\npp_check(model_2, nsamples = 45)\n\n\n\n\nPriors do brms\nbrms possui as seguintes configurações como padrão de priors para regressão robusta usando t de Student:\nConstante (Intercept): t de Student com média \\(\\mu = \\text{median}_y\\), desvio padrão de \\(\\max(2.5, MAD(y)\\) e graus de liberdade \\(3\\) - prior = student_t(3, median_y, mad_y), class = intercept\nCoeficientes: para cada coeficiente média \\(\\mu = 0\\) e desvio padrão de \\(2.5\\times\\frac{1}{\\sigma_{x_k}}\\) - prior = normal(0, 2.5 * 1/sd_xk)\nErro residual (sigma): t de Student com média \\(\\mu = 0\\), desvio padrão de \\(\\max(2.5, MAD(y)\\) e graus de liberdade \\(3\\) - prior = student_t(3, 0, mad_y), class = sigma\nGraus de liberdade (nu): distribuição gamma com \\(\\alpha = 2\\) e \\(\\beta = 0.1\\) - prior = gamma(2, 0.1), class = nu\nAtividade Prática\nO dataset Boston Housing está disponível em datasets/Boston_Housing.csv. Possui 506 observações e possui 14 variáveis:\nCRIM - per capita crime rate by town\nZN - proportion of residential land zoned for lots over 25,000 sq.ft.\nINDUS - proportion of non-retail business acres per town.\nCHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\nNOX - nitric oxides concentration (parts per 10 million)\nRM - average number of rooms per dwelling\nAGE - proportion of owner-occupied units built prior to 1940\nDIS - weighted distances to five Boston employment centres\nRAD - index of accessibility to radial highways\nTAX - full-value property-tax rate per $10,000\nPTRATIO - pupil-teacher ratio by town\nB - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\nLSTAT - % lower status of the population\nMEDV - Median value of owner-occupied homes in $1000’s\n\n\n###\n\n\n\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.3 (2020-10-10)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n[1] brms_2.14.4     carData_3.0-4   gapminder_0.3.0 skimr_2.1.2    \n[5] rstanarm_2.21.1 Rcpp_1.0.5      readxl_1.3.1   \n\nloaded via a namespace (and not attached):\n  [1] TH.data_1.0-10       minqa_1.2.4          colorspace_2.0-0    \n  [4] ellipsis_0.3.1       ggridges_0.5.2       rsconnect_0.8.16    \n  [7] rprojroot_2.0.2      estimability_1.3     markdown_1.1        \n [10] base64enc_0.1-3      rstudioapi_0.13      farver_2.0.3        \n [13] rstan_2.21.2         DT_0.16              mvtnorm_1.1-1       \n [16] fansi_0.4.1          lubridate_1.7.9.2    bridgesampling_1.0-0\n [19] codetools_0.2-18     splines_4.0.3        downlit_0.2.1       \n [22] knitr_1.30           shinythemes_1.1.2    projpred_2.0.2      \n [25] bayesplot_1.7.2      jsonlite_1.7.2       nloptr_1.2.2.2      \n [28] shiny_1.5.0          compiler_4.0.3       emmeans_1.5.3       \n [31] backports_1.2.1      assertthat_0.2.1     Matrix_1.3-0        \n [34] fastmap_1.0.1        cli_2.2.0            later_1.1.0.1       \n [37] htmltools_0.5.0      prettyunits_1.1.1    tools_4.0.3         \n [40] igraph_1.2.6         coda_0.19-4          gtable_0.3.0        \n [43] glue_1.4.2           reshape2_1.4.4       dplyr_1.0.2         \n [46] V8_3.4.0             cellranger_1.1.0     vctrs_0.3.6         \n [49] nlme_3.1-151         crosstalk_1.1.0.1    xfun_0.19           \n [52] stringr_1.4.0        ps_1.5.0             lme4_1.1-26         \n [55] mime_0.9             miniUI_0.1.1.1       lifecycle_0.2.0     \n [58] gtools_3.8.2         statmod_1.4.35       MASS_7.3-53         \n [61] zoo_1.8-8            scales_1.1.1         colourpicker_1.1.0  \n [64] Brobdingnag_1.2-6    promises_1.1.1       sandwich_3.0-0      \n [67] parallel_4.0.3       inline_0.3.17        shinystan_2.5.0     \n [70] gamm4_0.2-6          yaml_2.2.1           curl_4.3            \n [73] gridExtra_2.3        ggplot2_3.3.3        loo_2.4.1           \n [76] StanHeaders_2.21.0-7 distill_1.1          stringi_1.5.3       \n [79] highr_0.8            dygraphs_1.1.1.6     boot_1.3-25         \n [82] pkgbuild_1.2.0       repr_1.1.0           rlang_0.4.10        \n [85] pkgconfig_2.0.3      matrixStats_0.57.0   evaluate_0.14       \n [88] lattice_0.20-41      purrr_0.3.4          rstantools_2.1.1    \n [91] htmlwidgets_1.5.3    labeling_0.4.2       processx_3.4.5      \n [94] tidyselect_1.1.0     plyr_1.8.6           magrittr_2.0.1      \n [97] bookdown_0.21        R6_2.5.0             generics_0.1.0      \n[100] multcomp_1.4-15      mgcv_1.8-33          pillar_1.4.7        \n[103] withr_2.3.0          xts_0.12.1           abind_1.4-5         \n[106] survival_3.2-7       tibble_3.0.4         crayon_1.3.4        \n[109] utf8_1.1.4           rmarkdown_2.6        grid_4.0.3          \n[112] callr_3.5.1          threejs_0.3.3        digest_0.6.27       \n[115] xtable_1.8-4         tidyr_1.1.2          httpuv_1.5.4        \n[118] RcppParallel_5.0.2   stats4_4.0.3         munsell_0.5.0       \n[121] shinyjs_2.0.0       \n\n\n\n\n",
      "last_modified": "2020-12-31T05:44:53-03:00"
    },
    {
      "path": "9-Regressao_Multinivel.html",
      "title": "Modelos Multiniveis ou Modelos Hierárquicos",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nQuando usar Modelos Multiníveis?\nHyperprior\nTrês abordagens\nRandom Intercept Model\nRandom Slope Model\nRandom Intercept-Slope Model\nExemplo com o dataset cheese\n\nPriors de Modelos Multiníveis\nAtividade Prática\nAmbiente\n\nModelos hierárquicos Bayesianos (também chamados de modelos multiníveis) são um modelo estatístico escrito em níveis múltiplos (forma hierárquica) que estima os parâmetros da distribuição posterior usando o método Bayesiano. Os submodelos se combinam para formar o modelo hierárquico, e o teorema de Bayes é usado para integrá-los aos dados observados e contabilizar toda a incerteza que está presente. O resultado dessa integração é a distribuição posterior, também conhecida como estimativa de probabilidade atualizada, à medida que evidências adicionais sobre a distribuição anterior são adquiridas.\nA modelagem hierárquica é usada quando as informações estão disponíveis em vários níveis diferentes de unidades de observação. A forma hierárquica de análise e organização auxilia no entendimento de problemas multiparâmetros e também desempenha um papel importante no desenvolvimento de estratégias computacionais.\nOs modelos hierárquicos são descrições matemáticas que envolvem vários parâmetros, de modo que as estimativas de alguns parâmetros dependem significativamente dos valores de outros parâmetros.\nModelo HierarquicoQuando usar Modelos Multiníveis?\nModelos multiníveis são particularmente apropriados para projetos de pesquisa onde os dados dos participantes são organizados em mais de um nível (ou seja, dados aninhados - nested data). As unidades de análise geralmente são indivíduos (em um nível inferior) que estão aninhados em unidades contextuais/agregadas (em um nível superior).\nHá um pressuposto principal que não pode ser violado em modelos multiníveis que é o de permutabilidade. Esse pressuposto parte do princípio que os grupos são permutáveis. Se esse pressuposto é violado na sua inferência, então modelos multiníveis não são apropriados.\nHyperprior\nComo as priors dos parâmetros são amostradas de uma outra prior do hiperparâmetro (parâmetro do nível superior), as priors do nível superior são chamadas de hyperpriors. Isso faz com que estimativas de um grupo ajudem o modelo a estimar melhor os outros grupos e dando estimativas mais robustas e estáveis.\nTrês abordagens\nModelos multiníveis geralmente se dividem em três abordagens:\nRandom intercept model: Modelo no qual cada grupo recebe uma constante (intercept) diferente\nRandom slope model: Modelo no qual cada grupo recebe um coeficiente diferente para cada variável independente\nRandom intercept-slope model: Modelo no qual cada grupo recebe tanto uma constante (intercept) quanto um coeficiente diferente para cada variável independente\nRandom Intercept Model\nA primeira abordagem é o random intercept model na qual especificamos para cada grupo uma constante diferente. Essas constantes são amostrada de uma hyperprior.\nO pacote rstanarm tem as funcionalidades completas para rodar modelos multiníveis e a única coisa a se fazer é alterar a formula. Há uma segunda mudança também que não usamos mais a função stan_glm() mas sim a função stan_glmer().\nNo caso de random intercept model, a formula a ser usada segue este padrão:\ny ~ (1 | group) + x1 + x2\nRandom Slope Model\nA segunda abordagem é o random slope model na qual especificamos para cada grupo um coeficiente diferente para cada variável independente. Esses coeficientes são amostrada de uma hyperprior.\nNo caso de random slope model, a formula a ser usada segue este padrão:\ny ~ (0 + x1 | group) + (0 + x2 | group)\nRandom Intercept-Slope Model\nA terceira abordagem é o random intercept-slope model na qual especificamos para cada grupo uma constante diferente além de coeficientes diferentes para cada variável independente. Essas constantes e coeficientes são amostrados de duas ou mais hyperpriors.\nNo caso de random intercept-slope model, a formula a ser usada segue este padrão:\ny ~ (1 + x1 | group) + (1 + x2 | group)\nExemplo com o dataset cheese\nO dataset cheese possui 160 observações de avaliações de queijo. Um grupo de 10 avaliadores “rurais” e 10 “urbanos” avaliaram 4 queijos diferentes \\((A,B,C,D)\\) em duas amostras. Portanto \\(4 \\cdot 20 \\cdot 2 = 160\\). Possui 4 variáveis:\ncheese: tipo do queijo \\((A,B,C,D)\\)\nrater: avaliador \\((1,\\dots, 10)\\)\nbackground: origem do avaliador em “urbano” ou “rural”\ny: variável dependente - nota da avaliação\n\n\ncheese <- read.csv2(\"datasets/cheese.csv\", stringsAsFactors = T, row.names = 1)\n\n\n\nRandom Intercept Model\nNo primeiro exemplo vamos usar um modelo que cada grupo de cheese recebe uma constante diferente:\n\n\nlibrary(rstanarm)\nrandom_intercept <- stan_glmer(\n  y ~ (1 | cheese) + background,\n  data = cheese\n)\n\n\n\nNo sumário do modelo vemos que os avaliadores urbanos avaliam melhor os queijos que os avaliadores rurais, mas também observamos que cada queijo possui uma “taxa basal” de avaliação. Sendo \\(B\\) o pior queijo e \\(C\\) o melhor queijo:\n\n\nsummary(random_intercept)\n\n\n\nModel Info:\n function:     stan_glmer\n family:       gaussian [identity]\n formula:      y ~ (1 | cheese) + background\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 160\n groups:       cheese (4)\n\nEstimates:\n                                        mean   sd    10%   50%   90%\n(Intercept)                            66.7    5.5  60.0  66.7  73.4\nbackgroundurban                         7.4    1.1   6.0   7.4   8.8\nb[(Intercept) cheese:A]                 4.3    5.6  -2.4   4.2  10.9\nb[(Intercept) cheese:B]               -13.6    5.6 -20.3 -13.6  -6.9\nb[(Intercept) cheese:C]                 9.0    5.6   2.2   8.9  15.8\nb[(Intercept) cheese:D]                 1.9    5.6  -4.8   1.8   8.6\nsigma                                   7.1    0.4   6.6   7.0   7.6\nSigma[cheese:(Intercept),(Intercept)] 132.0  135.1  42.5  95.9 251.3\n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 70.8    0.8 69.8  70.8  71.9 \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n                                      mcse Rhat n_eff\n(Intercept)                           0.2  1.0  1159 \nbackgroundurban                       0.0  1.0  3575 \nb[(Intercept) cheese:A]               0.2  1.0  1172 \nb[(Intercept) cheese:B]               0.2  1.0  1166 \nb[(Intercept) cheese:C]               0.2  1.0  1183 \nb[(Intercept) cheese:D]               0.2  1.0  1162 \nsigma                                 0.0  1.0  3765 \nSigma[cheese:(Intercept),(Intercept)] 3.7  1.0  1308 \nmean_PPD                              0.0  1.0  3880 \nlog-posterior                         0.1  1.0  1340 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nRandom Slope Model\nNo segundo exemplo vamos usar um modelo que cada grupo de cheese recebe um coeficiente diferente para background:\n\n\nrandom_slope <- stan_glmer(\n  y ~ (0 + background | cheese),\n  data = cheese\n)\n\n\n\nAqui vemos que todos os queijos recebem a mesma constante mas cada queijo possui um coeficiente diferente para background do avaliador:\n\n\nsummary(random_slope)\n\n\n\nModel Info:\n function:     stan_glmer\n family:       gaussian [identity]\n formula:      y ~ (0 + background | cheese)\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 160\n groups:       cheese (4)\n\nEstimates:\n                                                mean   sd    10%\n(Intercept)                                    69.8    5.7  62.9\nb[backgroundrural cheese:A]                     1.0    5.8  -6.1\nb[backgroundurban cheese:A]                     8.9    5.9   1.6\nb[backgroundrural cheese:B]                   -15.5    6.0 -23.1\nb[backgroundurban cheese:B]                   -10.1    5.7 -17.1\nb[backgroundrural cheese:C]                     5.5    5.7  -1.5\nb[backgroundurban cheese:C]                    13.8    5.9   6.5\nb[backgroundrural cheese:D]                    -0.6    5.8  -7.8\nb[backgroundurban cheese:D]                     5.6    5.9  -1.6\nsigma                                           7.1    0.4   6.6\nSigma[cheese:backgroundrural,backgroundrural] 130.5  121.2  40.4\nSigma[cheese:backgroundurban,backgroundrural]  70.7   85.8   3.3\nSigma[cheese:backgroundurban,backgroundurban] 156.5  127.7  52.2\n                                                50%   90%\n(Intercept)                                    69.8  76.7\nb[backgroundrural cheese:A]                     1.1   8.0\nb[backgroundurban cheese:A]                     8.9  16.2\nb[backgroundrural cheese:B]                   -15.4  -8.2\nb[backgroundurban cheese:B]                   -10.1  -3.2\nb[backgroundrural cheese:C]                     5.6  12.5\nb[backgroundurban cheese:C]                    13.9  21.2\nb[backgroundrural cheese:D]                    -0.6   6.5\nb[backgroundurban cheese:D]                     5.5  12.8\nsigma                                           7.1   7.7\nSigma[cheese:backgroundrural,backgroundrural]  95.2 259.0\nSigma[cheese:backgroundurban,backgroundrural]  53.9 160.4\nSigma[cheese:backgroundurban,backgroundurban] 119.4 299.8\n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 70.9    0.8 69.8  70.9  71.8 \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n                                              mcse Rhat n_eff\n(Intercept)                                   0.2  1.0   733 \nb[backgroundrural cheese:A]                   0.2  1.0   766 \nb[backgroundurban cheese:A]                   0.2  1.0   773 \nb[backgroundrural cheese:B]                   0.2  1.0   785 \nb[backgroundurban cheese:B]                   0.2  1.0   788 \nb[backgroundrural cheese:C]                   0.2  1.0   748 \nb[backgroundurban cheese:C]                   0.2  1.0   780 \nb[backgroundrural cheese:D]                   0.2  1.0   790 \nb[backgroundurban cheese:D]                   0.2  1.0   749 \nsigma                                         0.0  1.0  3126 \nSigma[cheese:backgroundrural,backgroundrural] 2.8  1.0  1814 \nSigma[cheese:backgroundurban,backgroundrural] 2.1  1.0  1704 \nSigma[cheese:backgroundurban,backgroundurban] 3.4  1.0  1433 \nmean_PPD                                      0.0  1.0  3982 \nlog-posterior                                 0.1  1.0  1290 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nRandom Intercept-Slope Model\nNo terceiro exemplo vamos usar um modelo que cada grupo de cheese recebe uma constante diferente e um coeficiente diferente para background:\n\n\nrandom_intercept_slope <- stan_glmer(\n  y ~ (1 + background | cheese),\n  data = cheese\n)\n\n\n\nAqui vemos que os queijos recebem a constantes diferentes e que cada queijo possui um coeficiente diferente para background do avaliador:\n\n\nsummary(random_intercept_slope)\n\n\n\nModel Info:\n function:     stan_glmer\n family:       gaussian [identity]\n formula:      y ~ (1 + background | cheese)\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 160\n groups:       cheese (4)\n\nEstimates:\n                                                mean   sd    10%\n(Intercept)                                    66.5    7.6  57.4\nb[(Intercept) cheese:A]                         4.4    7.6  -4.3\nb[backgroundurban cheese:A]                     7.8    2.2   5.1\nb[(Intercept) cheese:B]                       -12.0    7.9 -21.0\nb[backgroundurban cheese:B]                     4.7    2.3   1.8\nb[(Intercept) cheese:C]                         8.8    7.5   0.1\nb[backgroundurban cheese:C]                     8.3    2.2   5.5\nb[(Intercept) cheese:D]                         2.8    7.6  -5.7\nb[backgroundurban cheese:D]                     6.0    2.1   3.4\nsigma                                           7.1    0.4   6.6\nSigma[cheese:(Intercept),(Intercept)]         145.8  144.6  43.9\nSigma[cheese:backgroundurban,(Intercept)]      11.2   70.3 -55.9\nSigma[cheese:backgroundurban,backgroundurban]  86.6   86.0  25.0\n                                                50%   90%\n(Intercept)                                    66.5  75.0\nb[(Intercept) cheese:A]                         4.5  13.4\nb[backgroundurban cheese:A]                     7.8  10.5\nb[(Intercept) cheese:B]                       -11.9  -2.7\nb[backgroundurban cheese:B]                     4.7   7.6\nb[(Intercept) cheese:C]                         8.8  17.8\nb[backgroundurban cheese:C]                     8.4  11.2\nb[(Intercept) cheese:D]                         2.9  11.7\nb[backgroundurban cheese:D]                     6.0   8.7\nsigma                                           7.1   7.7\nSigma[cheese:(Intercept),(Intercept)]         105.0 283.6\nSigma[cheese:backgroundurban,(Intercept)]      10.7  78.4\nSigma[cheese:backgroundurban,backgroundurban]  61.1 175.1\n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 70.8    0.8 69.8  70.8  71.9 \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n                                              mcse Rhat n_eff\n(Intercept)                                   0.3  1.0   520 \nb[(Intercept) cheese:A]                       0.3  1.0   520 \nb[backgroundurban cheese:A]                   0.0  1.0  4503 \nb[(Intercept) cheese:B]                       0.4  1.0   505 \nb[backgroundurban cheese:B]                   0.0  1.0  2982 \nb[(Intercept) cheese:C]                       0.3  1.0   533 \nb[backgroundurban cheese:C]                   0.0  1.0  4434 \nb[(Intercept) cheese:D]                       0.3  1.0   520 \nb[backgroundurban cheese:D]                   0.0  1.0  4707 \nsigma                                         0.0  1.0  3925 \nSigma[cheese:(Intercept),(Intercept)]         5.1  1.0   814 \nSigma[cheese:backgroundurban,(Intercept)]     2.4  1.0   854 \nSigma[cheese:backgroundurban,backgroundurban] 2.0  1.0  1843 \nmean_PPD                                      0.0  1.0  4096 \nlog-posterior                                 0.1  1.0  1047 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nPriors de Modelos Multiníveis\nRelembrando a tabela de priors da Aula 4:\nArgumento\nUsado em\nAplica-se à\nprior_intercept\nTodas funções de modelagem exceto stan_polr and stan_nlmer\nConstante (intercept) do modelo, após centralização dos preditores\nprior\nTodas funções de modelagem\nCoeficientes de Regressão, não inclui coeficientes que variam por grupo em modelos multiníveis (veja prior_covariance)\nprior_aux\nstan_glm, stan_glmer, stan_gamm4, stan_nlmer\nParâmetro auxilizar (ex: desvio padrão (standard error - DP), interpretação depende do modelo\nprior_covariance\nstan_glmer, stan_gamm4, stan_nlmer\nMatrizes de covariância em modelos multiníveis\nConstante(Intercept): centralizada com média \\(\\mu_{y_{group}}\\) para cada grupo e desvio padrão de \\(2.5 \\sigma_{y_{group}}\\) para cada grupo - prior_intercept = normal(mean_y_group, 2.5 * sd_y_group)\nCoeficientes: aqui não especifica-se uma prior para cada coeficiente, mas sim uma prior para a matriz de correlação das variáveis independentes usando uma distribuição LKJ - prior_covariance = lkj(regularization = 1, concentration = 1, shape = 1, scale = 1)\nAtividade Prática\nPara atividade prática, temos o dataset rikz em datasets/rikz.csv.\nFor each of 9 intertidal areas (denoted ‘Beaches’), the researchers sampled five sites (denoted ‘Sites’) and at each site they measured abiotic variables and the diversity of macro-fauna (e.g. aquatic invertebrates). Here, species richness refers to the total number of species found at a given site while NAP ( i.e. Normal Amsterdams Peil) refers to the height of the sampling location relative to the mean sea level and represents a measure of the amount of food available for birds, etc. For our purpose, the main question is:\nWhat is the influence of NAP on species richness?\nRicz Dataset\n\nrikz <- read.csv2(\"datasets/rikz.csv\", row.names = 1)\nrikz$Beach <- as.factor(rikz$Beach)\nrikz$Site <- as.factor(rikz$Site)\n\n\n\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.3 (2020-10-10)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n[1] brms_2.14.4     carData_3.0-4   gapminder_0.3.0 skimr_2.1.2    \n[5] rstanarm_2.21.1 Rcpp_1.0.5      readxl_1.3.1   \n\nloaded via a namespace (and not attached):\n  [1] TH.data_1.0-10       minqa_1.2.4          colorspace_2.0-0    \n  [4] ellipsis_0.3.1       ggridges_0.5.2       rsconnect_0.8.16    \n  [7] rprojroot_2.0.2      estimability_1.3     markdown_1.1        \n [10] base64enc_0.1-3      rstudioapi_0.13      farver_2.0.3        \n [13] rstan_2.21.2         DT_0.16              mvtnorm_1.1-1       \n [16] fansi_0.4.1          lubridate_1.7.9.2    bridgesampling_1.0-0\n [19] codetools_0.2-18     splines_4.0.3        downlit_0.2.1       \n [22] knitr_1.30           shinythemes_1.1.2    projpred_2.0.2      \n [25] bayesplot_1.7.2      jsonlite_1.7.2       nloptr_1.2.2.2      \n [28] shiny_1.5.0          compiler_4.0.3       emmeans_1.5.3       \n [31] backports_1.2.1      assertthat_0.2.1     Matrix_1.3-0        \n [34] fastmap_1.0.1        cli_2.2.0            later_1.1.0.1       \n [37] htmltools_0.5.0      prettyunits_1.1.1    tools_4.0.3         \n [40] igraph_1.2.6         coda_0.19-4          gtable_0.3.0        \n [43] glue_1.4.2           reshape2_1.4.4       dplyr_1.0.2         \n [46] V8_3.4.0             cellranger_1.1.0     vctrs_0.3.6         \n [49] nlme_3.1-151         crosstalk_1.1.0.1    xfun_0.19           \n [52] stringr_1.4.0        ps_1.5.0             lme4_1.1-26         \n [55] mime_0.9             miniUI_0.1.1.1       lifecycle_0.2.0     \n [58] gtools_3.8.2         statmod_1.4.35       MASS_7.3-53         \n [61] zoo_1.8-8            scales_1.1.1         colourpicker_1.1.0  \n [64] Brobdingnag_1.2-6    promises_1.1.1       sandwich_3.0-0      \n [67] parallel_4.0.3       inline_0.3.17        shinystan_2.5.0     \n [70] gamm4_0.2-6          yaml_2.2.1           curl_4.3            \n [73] gridExtra_2.3        ggplot2_3.3.3        loo_2.4.1           \n [76] StanHeaders_2.21.0-7 distill_1.1          stringi_1.5.3       \n [79] highr_0.8            dygraphs_1.1.1.6     boot_1.3-25         \n [82] pkgbuild_1.2.0       repr_1.1.0           rlang_0.4.10        \n [85] pkgconfig_2.0.3      matrixStats_0.57.0   evaluate_0.14       \n [88] lattice_0.20-41      purrr_0.3.4          rstantools_2.1.1    \n [91] htmlwidgets_1.5.3    labeling_0.4.2       processx_3.4.5      \n [94] tidyselect_1.1.0     plyr_1.8.6           magrittr_2.0.1      \n [97] bookdown_0.21        R6_2.5.0             generics_0.1.0      \n[100] multcomp_1.4-15      mgcv_1.8-33          pillar_1.4.7        \n[103] withr_2.3.0          xts_0.12.1           abind_1.4-5         \n[106] survival_3.2-7       tibble_3.0.4         crayon_1.3.4        \n[109] utf8_1.1.4           rmarkdown_2.6        grid_4.0.3          \n[112] callr_3.5.1          threejs_0.3.3        digest_0.6.27       \n[115] xtable_1.8-4         tidyr_1.1.2          httpuv_1.5.4        \n[118] RcppParallel_5.0.2   stats4_4.0.3         munsell_0.5.0       \n[121] shinyjs_2.0.0       \n\n\n\n\n",
      "last_modified": "2020-12-31T05:45:11-03:00"
    },
    {
      "path": "aux-Dados_Faltantes.html",
      "title": "Dados Faltantes",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nRemover dados faltantes\nImputar valores nos dados faltantes\nImputar a média\nImputar a mediana\nImputar o último valor ocorrido\n\nComparação dos resultados\nAmbiente\n\nDados faltantes são um problema comum em qualquer análise de dados. Temos duas abordagens básicas para lidar com dados faltantes:\nremover os dados faltantes\nimputar valores nos dados faltantes\nRemover dados faltantes\nA remoção de dados faltantes se divide em duas principais abordagens usando a função na.omit() do pacote base stats:\nremoção de observações com dados faltantes: aqui removemos as linhas com dados faltantes df <- na.omit(df)\nremoção de variáveis com dados faltantes: aqui removemos as colunas com dados faltantes df <- t(na.omit(t(df)))\nImputar valores nos dados faltantes\nDentre as diversas maneiras de imputar valores ao dados faltantes, as mais comuns são três:\nimputar a média\nimputar a mediana\nimputar o último valor ocorrido (muito usada em séries temporais)\nMas ainda há maneiras mais avançadas e que desempenham melhor em certas condições (não cobriremos essas técnicas nesse curso):\nk-nearest neighbors imputation\nrandom forest imputation\nHá um pacote de R chamado DescTools que é uma coleção de funções focadas especialmente na parte descritiva de análise de um dataset.\nPara mostrar as abordagens, geramos um dataset de uma série temporal de uma semana com dados faltantes:\n\n\nlibrary(DescTools)\nset.seed(123)\ndf <- data.frame(\n  dia = c(\"seg\", \"ter\", \"qua\", \"qui\", \"sex\", \"sab\", \"dom\"),\n  valor = runif(7))\nindices_aleatorios <- sample(1:nrow(df), 2)\ndf[indices_aleatorios[1], 2] <- NA\ndf[indices_aleatorios[2], 2] <- NA\n\n\n\nImputar a média\n\n\ndf$media <- Impute(df$valor, FUN = mean(df$valor, na.rm = T))\n\n\n\nImputar a mediana\n\n\ndf$mediana <- Impute(df$valor, FUN = median(df$valor, na.rm = T))\n\n\n\nImputar o último valor ocorrido\n\n\ndf$ultimo <- LOCF(df$valor)\n\n\n\nComparação dos resultados\n\n\ndf\n\n\n  dia valor media mediana ultimo\n1 seg  0.29  0.29    0.29   0.29\n2 ter  0.79  0.79    0.79   0.79\n3 qua    NA  0.69    0.79   0.79\n4 qui  0.88  0.88    0.88   0.88\n5 sex  0.94  0.94    0.94   0.94\n6 sab    NA  0.69    0.79   0.94\n7 dom  0.53  0.53    0.53   0.53\n\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.3 (2020-10-10)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n[1] DescTools_0.99.39 brms_2.14.4       carData_3.0-4    \n[4] gapminder_0.3.0   skimr_2.1.2       rstanarm_2.21.1  \n[7] Rcpp_1.0.5        readxl_1.3.1     \n\nloaded via a namespace (and not attached):\n  [1] backports_1.2.1      plyr_1.8.6           igraph_1.2.6        \n  [4] repr_1.1.0           splines_4.0.3        crosstalk_1.1.0.1   \n  [7] ggplot2_3.3.3        TH.data_1.0-10       rstantools_2.1.1    \n [10] inline_0.3.17        digest_0.6.27        htmltools_0.5.0     \n [13] rsconnect_0.8.16     fansi_0.4.1          magrittr_2.0.1      \n [16] RcppParallel_5.0.2   matrixStats_0.57.0   xts_0.12.1          \n [19] sandwich_3.0-0       prettyunits_1.1.1    colorspace_2.0-0    \n [22] xfun_0.19            dplyr_1.0.2          callr_3.5.1         \n [25] crayon_1.3.4         jsonlite_1.7.2       Exact_2.1           \n [28] lme4_1.1-26          survival_3.2-7       zoo_1.8-8           \n [31] glue_1.4.2           gtable_0.3.0         emmeans_1.5.3       \n [34] V8_3.4.0             pkgbuild_1.2.0       rstan_2.21.2        \n [37] abind_1.4-5          scales_1.1.1         mvtnorm_1.1-1       \n [40] miniUI_0.1.1.1       xtable_1.8-4         stats4_4.0.3        \n [43] StanHeaders_2.21.0-7 DT_0.16              htmlwidgets_1.5.3   \n [46] threejs_0.3.3        ellipsis_0.3.1       pkgconfig_2.0.3     \n [49] loo_2.4.1            farver_2.0.3         utf8_1.1.4          \n [52] tidyselect_1.1.0     labeling_0.4.2       rlang_0.4.10        \n [55] reshape2_1.4.4       later_1.1.0.1        munsell_0.5.0       \n [58] cellranger_1.1.0     tools_4.0.3          cli_2.2.0           \n [61] generics_0.1.0       ggridges_0.5.2       evaluate_0.14       \n [64] stringr_1.4.0        fastmap_1.0.1        yaml_2.2.1          \n [67] processx_3.4.5       knitr_1.30           purrr_0.3.4         \n [70] rootSolve_1.8.2.1    nlme_3.1-151         mime_0.9            \n [73] projpred_2.0.2       compiler_4.0.3       bayesplot_1.7.2     \n [76] shinythemes_1.1.2    rstudioapi_0.13      curl_4.3            \n [79] gamm4_0.2-6          e1071_1.7-4          tibble_3.0.4        \n [82] statmod_1.4.35       stringi_1.5.3        highr_0.8           \n [85] ps_1.5.0             Brobdingnag_1.2-6    lattice_0.20-41     \n [88] Matrix_1.3-0         nloptr_1.2.2.2       markdown_1.1        \n [91] shinyjs_2.0.0        vctrs_0.3.6          pillar_1.4.7        \n [94] lifecycle_0.2.0      bridgesampling_1.0-0 estimability_1.3    \n [97] lmom_2.8             httpuv_1.5.4         R6_2.5.0            \n[100] bookdown_0.21        promises_1.1.1       gridExtra_2.3       \n[103] gld_2.6.2            codetools_0.2-18     distill_1.1         \n[106] boot_1.3-25          colourpicker_1.1.0   MASS_7.3-53         \n[109] gtools_3.8.2         assertthat_0.2.1     rprojroot_2.0.2     \n[112] withr_2.3.0          shinystan_2.5.0      multcomp_1.4-15     \n[115] expm_0.999-5         mgcv_1.8-33          parallel_4.0.3      \n[118] grid_4.0.3           class_7.3-17         tidyr_1.1.2         \n[121] coda_0.19-4          minqa_1.2.4          rmarkdown_2.6       \n[124] downlit_0.2.1        shiny_1.5.0          lubridate_1.7.9.2   \n[127] base64enc_0.1-3      dygraphs_1.1.1.6    \n\n\n\n\n",
      "last_modified": "2020-12-31T05:45:12-03:00"
    },
    {
      "path": "aux-Regressao_Coeficientes.html",
      "title": "Diferenças entre Coeficientes padronizados vs brutos",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nSimulação\nMédia e Desvio Padrões\nCoeficientes Brutos vs Padronizados\n\nAmbiente\n\nEm tabelas de regressão temos geralmente temos duas opções de reportar os coeficientes:\nCoeficientes Brutos: não há transformações e as associações das variáveis independentes/controles (covariáveis) com a dependente são reportadas em suas medidas originais. Exemplo: A cada 1 unidades de aumento de \\(x\\), \\(y\\) aumenta 0.45.\nCoeficientes Padronizados: os coeficientes são transformados para expressarem as associações das variáveis independentes/controles (covariáveis) com a dependente em relação à variação dos seus desvios padrões. Exemplo: A cada 1 desvio padrão de variação positiva de \\(x\\), \\(y\\) possui variação de 0.1 desvio padrão.\nSimulação\nPara explicar melhor esses conceitos, simularemos alguns dados:\n\\(x\\): 1,000 observações amostradas de uma distribuição normal com média 1 e desvio padrão 0.1. \\(x \\sim \\mathcal{N} (1, 0.1)\\)\n\\(y\\): uma combinação linear de \\(100x\\) com uma constante e um erro pequeno normalmente distribuído. \\(y = 10 + 100x + \\epsilon\\) e \\(\\epsilon \\sim \\mathcal{N} (0, 1)\\).\n\n\nN <- 1000\nx <- rnorm(N, 1, 0.1)\nerror <- rnorm(N, 0, 1)\ny <- rep(10, N) + 100*x + error\n\ndf <- data.frame(x, y)\n\n\n\n\n\nlibrary(skimr)\nskim(df)\n\n\nTable 1: Data summary\nName\ndf\nNumber of rows\n1000\nNumber of columns\n2\n_______________________\n\nColumn type frequency:\n\nnumeric\n2\n________________________\n\nGroup variables\nNone\nVariable type: numeric\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\nx\n0\n1\n1\n0.1\n0.67\n0.93\n1\n1.1\n1.3\n▁▃▇▃▁\ny\n0\n1\n110\n10.1\n75.94\n103.01\n109\n116.5\n142.7\n▁▃▇▃▁\n\nMédia e Desvio Padrões\nPrestem atenção:\n\\(x\\): média 1, desvio padrão 0.1\n\\(y\\): média 109.6, desvio padrão 10.05\nCoeficientes Brutos vs Padronizados\nAgora vamos rodar uma regressão e mostrar coeficientes tanto os coeficientes brutos e os padronizados\n\n\nlibrary(lm.beta)\nmodel <- lm.beta(lm(y ~ x, df))\nsummary(model)\n\n\n\nCall:\nlm(formula = y ~ x, data = df)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-3.701 -0.727 -0.009  0.683  2.728 \n\nCoefficients:\n            Estimate Standardized Std. Error t value\n(Intercept)    9.460        0.000      0.324    29.2\nx            100.506        0.995      0.324   310.5\n                       Pr(>|t|)    \n(Intercept) <0.0000000000000002 ***\nx           <0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1 on 998 degrees of freedom\nMultiple R-squared:  0.99,  Adjusted R-squared:  0.99 \nF-statistic: 9.64e+04 on 1 and 998 DF,  p-value: <0.0000000000000002\n\nPor fim, ambas colunas mostram a mesma coisa\nColuna não padronizada Estimate: a cada 1 unidade que \\(x\\) aumenta, \\(y\\) aumenta 100.51\nColuna padronizada Standardized: a cada 1 desvio padrão de \\(x\\) de incremento (dp = 0.1), há um aumento de 0.99 desvio padrão de \\(y\\) (10). Um total de 100.51. \\(\\big( \\frac{0.955 * \\operatorname{sd}_y}{\\operatorname{sd}_x}\\big)\\)\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.3 (2020-10-10)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n[1] lm.beta_1.5-1     DescTools_0.99.39 brms_2.14.4      \n[4] carData_3.0-4     gapminder_0.3.0   skimr_2.1.2      \n[7] rstanarm_2.21.1   Rcpp_1.0.5        readxl_1.3.1     \n\nloaded via a namespace (and not attached):\n  [1] backports_1.2.1      plyr_1.8.6           igraph_1.2.6        \n  [4] repr_1.1.0           splines_4.0.3        crosstalk_1.1.0.1   \n  [7] ggplot2_3.3.3        TH.data_1.0-10       rstantools_2.1.1    \n [10] inline_0.3.17        digest_0.6.27        htmltools_0.5.0     \n [13] rsconnect_0.8.16     fansi_0.4.1          magrittr_2.0.1      \n [16] RcppParallel_5.0.2   matrixStats_0.57.0   xts_0.12.1          \n [19] sandwich_3.0-0       prettyunits_1.1.1    colorspace_2.0-0    \n [22] xfun_0.19            dplyr_1.0.2          callr_3.5.1         \n [25] crayon_1.3.4         jsonlite_1.7.2       Exact_2.1           \n [28] lme4_1.1-26          survival_3.2-7       zoo_1.8-8           \n [31] glue_1.4.2           gtable_0.3.0         emmeans_1.5.3       \n [34] V8_3.4.0             pkgbuild_1.2.0       rstan_2.21.2        \n [37] abind_1.4-5          scales_1.1.1         mvtnorm_1.1-1       \n [40] miniUI_0.1.1.1       xtable_1.8-4         stats4_4.0.3        \n [43] StanHeaders_2.21.0-7 DT_0.16              htmlwidgets_1.5.3   \n [46] threejs_0.3.3        ellipsis_0.3.1       pkgconfig_2.0.3     \n [49] loo_2.4.1            farver_2.0.3         utf8_1.1.4          \n [52] tidyselect_1.1.0     labeling_0.4.2       rlang_0.4.10        \n [55] reshape2_1.4.4       later_1.1.0.1        munsell_0.5.0       \n [58] cellranger_1.1.0     tools_4.0.3          cli_2.2.0           \n [61] generics_0.1.0       ggridges_0.5.2       evaluate_0.14       \n [64] stringr_1.4.0        fastmap_1.0.1        yaml_2.2.1          \n [67] processx_3.4.5       knitr_1.30           purrr_0.3.4         \n [70] rootSolve_1.8.2.1    nlme_3.1-151         mime_0.9            \n [73] projpred_2.0.2       compiler_4.0.3       bayesplot_1.7.2     \n [76] shinythemes_1.1.2    rstudioapi_0.13      curl_4.3            \n [79] gamm4_0.2-6          e1071_1.7-4          tibble_3.0.4        \n [82] statmod_1.4.35       stringi_1.5.3        highr_0.8           \n [85] ps_1.5.0             Brobdingnag_1.2-6    lattice_0.20-41     \n [88] Matrix_1.3-0         nloptr_1.2.2.2       markdown_1.1        \n [91] shinyjs_2.0.0        vctrs_0.3.6          pillar_1.4.7        \n [94] lifecycle_0.2.0      bridgesampling_1.0-0 estimability_1.3    \n [97] lmom_2.8             httpuv_1.5.4         R6_2.5.0            \n[100] bookdown_0.21        promises_1.1.1       gridExtra_2.3       \n[103] gld_2.6.2            codetools_0.2-18     distill_1.1         \n[106] boot_1.3-25          colourpicker_1.1.0   MASS_7.3-53         \n[109] gtools_3.8.2         assertthat_0.2.1     rprojroot_2.0.2     \n[112] withr_2.3.0          shinystan_2.5.0      multcomp_1.4-15     \n[115] expm_0.999-5         mgcv_1.8-33          parallel_4.0.3      \n[118] grid_4.0.3           class_7.3-17         tidyr_1.1.2         \n[121] coda_0.19-4          minqa_1.2.4          rmarkdown_2.6       \n[124] downlit_0.2.1        shiny_1.5.0          lubridate_1.7.9.2   \n[127] base64enc_0.1-3      dygraphs_1.1.1.6    \n\n\n\n\n",
      "last_modified": "2020-12-31T05:45:13-03:00"
    },
    {
      "path": "aux-Tabelas_para_Publicacao.html",
      "title": "Como montar tabelas de modelos Bayesianos prontas para publicação",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nEstatísticas Descritivas\nTabela de Correlações\nRegressão Linear Bayesiana\nTabela de Regressão Linear\n\nModelo de Regressão Binomial/Logística\nTabela de Regressão Binomial/Logística\n\nAmbiente\n\n\n\n\nAo invés de ser obrigado a passar horas a fio formatando tabelas em Excel softwares pagos, você pode usar pacotes gratuitos do R para formatar automaticamente suas tabelas:\nEstatísticas Descritivas: gtsummary::tbl_summary()\nCorrelações: sjPlot::tab_corr()\nRegressões: sjPlot::tab_model()\nEstatísticas Descritivas\nO pacote gtsummary possui um conjunto de funções para sumarizar dados e tabelas. Eu particularmente gosto da função gtsummary::tbl_summary(). Ela formata uma tabela de Estatística Descritiva de maneira bem conveniente.\n\n\ngtsummary::tbl_summary(\n  kidiq,\n  by = mom_hs,\n  type = all_continuous() ~ \"continuous2\",\n  statistic = list(\n    all_continuous() ~ c(\"{N_nonmiss}\",\n                         \"{median} ({p25}, {p75})\", \n                         \"{min}, {max}\"),\n    all_categorical() ~ \"{n} ({p}%)\"),\n  missing = \"no\",\n  digits = all_continuous() ~ 2) %>%\n  # add p value and overall\n  add_p(pvalue_fun = ~style_pvalue(.x, digits = 2)) %>% \n  add_overall() %>%\n  # bold variable labels, italicize levels\n  bold_labels() %>%\n  italicize_levels() %>%\n  # change stuff\n  modify_header(label ~ \"**Variable**\") %>% \n  modify_spanning_header(c(\"stat_1\", \"stat_2\") ~ \"**Mom High School**\") %>% \n  add_n()\n\n\nhtml {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#pkiiayrfbm .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#pkiiayrfbm .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#pkiiayrfbm .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#pkiiayrfbm .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 4px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#pkiiayrfbm .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#pkiiayrfbm .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#pkiiayrfbm .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#pkiiayrfbm .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#pkiiayrfbm .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#pkiiayrfbm .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#pkiiayrfbm .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#pkiiayrfbm .gt_group_heading {\n  padding: 8px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#pkiiayrfbm .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#pkiiayrfbm .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#pkiiayrfbm .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#pkiiayrfbm .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#pkiiayrfbm .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 12px;\n}\n\n#pkiiayrfbm .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#pkiiayrfbm .gt_first_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n}\n\n#pkiiayrfbm .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#pkiiayrfbm .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#pkiiayrfbm .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#pkiiayrfbm .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#pkiiayrfbm .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#pkiiayrfbm .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding: 4px;\n}\n\n#pkiiayrfbm .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#pkiiayrfbm .gt_sourcenote {\n  font-size: 90%;\n  padding: 4px;\n}\n\n#pkiiayrfbm .gt_left {\n  text-align: left;\n}\n\n#pkiiayrfbm .gt_center {\n  text-align: center;\n}\n\n#pkiiayrfbm .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#pkiiayrfbm .gt_font_normal {\n  font-weight: normal;\n}\n\n#pkiiayrfbm .gt_font_bold {\n  font-weight: bold;\n}\n\n#pkiiayrfbm .gt_font_italic {\n  font-style: italic;\n}\n\n#pkiiayrfbm .gt_super {\n  font-size: 65%;\n}\n\n#pkiiayrfbm .gt_footnote_marks {\n  font-style: italic;\n  font-size: 65%;\n}\nVariable\n      N\n      Overall, N = 434\n      \n        Mom High School\n      \n      p-value1\n    no, N = 93\n      yes, N = 341\n    kid_score\n      434.00\n      \n      \n      \n      <0.001\n    N\n      \n      434.00\n      93.00\n      341.00\n      \n    Median (IQR)\n      \n      90.00 (74.00, 102.00)\n      80.00 (58.00, 95.00)\n      92.00 (77.00, 103.00)\n      \n    Range\n      \n      20.00, 144.00\n      20.00, 136.00\n      38.00, 144.00\n      \n    mom_iq\n      434.00\n      \n      \n      \n      <0.001\n    N\n      \n      434.00\n      93.00\n      341.00\n      \n    Median (IQR)\n      \n      97.92 (88.66, 110.27)\n      88.66 (81.83, 99.16)\n      100.24 (90.45, 113.17)\n      \n    Range\n      \n      71.04, 138.89\n      74.23, 127.54\n      71.04, 138.89\n      \n    mom_age\n      434.00\n      \n      \n      \n      <0.001\n    N\n      \n      434.00\n      93.00\n      341.00\n      \n    Median (IQR)\n      \n      23.00 (21.00, 25.00)\n      21.00 (20.00, 24.00)\n      23.00 (21.00, 25.00)\n      \n    Range\n      \n      17.00, 29.00\n      17.00, 28.00\n      17.00, 29.00\n      \n    \n        \n          1\n          \n           \n          Statistical tests performed: Wilcoxon rank-sum test\n          \n      \n    \n\nTabela de Correlações\nPara as tabelas de correlações, eu uso o pacote sjPlot com a função sjPlot::tab_cor()\nOs astericos significam:\n* - \\(p < 0.05\\)\n** - \\(p < 0.01\\)\n*** - \\(p < 0.001\\)\n\n\nsjPlot::tab_corr(\n  kidiq %>% mutate(mom_hs = as.integer(mom_hs)),\n  digits = 2,\n  triangle = \"lower\"\n)\n\n\n\n \n\n\nkid_score\n\n\nmom_hs\n\n\nmom_iq\n\n\nmom_age\n\n\nkid_score\n\n\n \n\n\n \n\n\n \n\n\n \n\n\nmom_hs\n\n\n0.24***\n\n\n \n\n\n \n\n\n \n\n\nmom_iq\n\n\n0.45***\n\n\n0.28***\n\n\n \n\n\n \n\n\nmom_age\n\n\n0.09\n\n\n0.21***\n\n\n0.09\n\n\n \n\n\nComputed correlation used pearson-method with listwise-deletion.\n\n\nRegressão Linear Bayesiana\nVamos começar com o caso simples da Aula 2 - Regressão Linear\n\n\nmodel <- stan_glm(\n  kid_score ~ mom_hs + mom_iq,\n  data = kidiq\n  )\n\n\n\nTabela de Regressão Linear\nPara as tabelas de regressões eu geralmente uso o mesmo pacote sjPlot, mas agora com a função sjPlot::tab_model() que aceita um modelo bayesiano.\n\n\ntab_model(model, show.reflvl = TRUE)\n\n\n\n \n\n\nkid_score\n\n\nPredictors\n\n\nEstimates\n\n\nCI (95%)\n\n\n(Intercept)\n\n\n25.80\n\n\n14.22 – 37.44\n\n\nno\n\n\nReference\n\n\n\n\nyes\n\n\n5.95\n\n\n1.57 – 10.47\n\n\nmom_iq\n\n\n0.56\n\n\n0.44 – 0.68\n\n\nObservations\n\n\n434\n\n\nR2 Bayes\n\n\n0.214\n\n\nModelo de Regressão Binomial/Logística\nVamos utilizar o caso da Aula 6 - Regressão Binomial\n\n\nmodel_binomial <- stan_glm(\n  switch ~ dist + arsenic + assoc + educ,\n  data = wells,\n  family = binomial()\n)\n\n\n\nTabela de Regressão Binomial/Logística\nA função sjPlot::tab_model() quando aplicada à um modelo bayesiano linear generalizado (binomial, Poisson etc.) já faz a transformação necessária para uma melhor interpretação dos coeficientes.\nNo caso de modelos binomiais/logísticos geralmente é aplicada uma exponenciação (exp()) dos coeficientes para transformá-los em razões de probabilidades (odds ratio)\nCaso queira deixar os coeficientes brutos (raw coefficients) use transform = NULL\n\n\ntab_model(model_binomial, show.reflvl = TRUE)\n\n\n\n \n\n\nswitch\n\n\nPredictors\n\n\nOdds Ratios\n\n\nCI (95%)\n\n\n(Intercept)\n\n\n0.85\n\n\n0.71 – 1.04\n\n\narsenic\n\n\n1.60\n\n\n1.47 – 1.73\n\n\nassoc\n\n\n0.88\n\n\n0.76 – 1.03\n\n\ndist\n\n\n0.99\n\n\n0.99 – 0.99\n\n\neduc\n\n\n1.04\n\n\n1.02 – 1.06\n\n\nObservations\n\n\n3020\n\n\nR2 Bayes\n\n\n0.067\n\n\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.3 (2020-10-10)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n [1] sjPlot_2.8.6      gtsummary_1.3.5   dplyr_1.0.2      \n [4] lm.beta_1.5-1     DescTools_0.99.39 brms_2.14.4      \n [7] carData_3.0-4     gapminder_0.3.0   skimr_2.1.2      \n[10] rstanarm_2.21.1   Rcpp_1.0.5        readxl_1.3.1     \n\nloaded via a namespace (and not attached):\n  [1] backports_1.2.1      plyr_1.8.6           igraph_1.2.6        \n  [4] repr_1.1.0           splines_4.0.3        crosstalk_1.1.0.1   \n  [7] ggplot2_3.3.3        TH.data_1.0-10       rstantools_2.1.1    \n [10] inline_0.3.17        digest_0.6.27        htmltools_0.5.0     \n [13] rsconnect_0.8.16     fansi_0.4.1          checkmate_2.0.0     \n [16] magrittr_2.0.1       modelr_0.1.8         RcppParallel_5.0.2  \n [19] matrixStats_0.57.0   xts_0.12.1           sandwich_3.0-0      \n [22] prettyunits_1.1.1    colorspace_2.0-0     mitools_2.4         \n [25] xfun_0.19            callr_3.5.1          crayon_1.3.4        \n [28] jsonlite_1.7.2       Exact_2.1            lme4_1.1-26         \n [31] survival_3.2-7       zoo_1.8-8            glue_1.4.2          \n [34] gtable_0.3.0         emmeans_1.5.3        sjstats_0.18.0      \n [37] sjmisc_2.8.5         V8_3.4.0             pkgbuild_1.2.0      \n [40] rstan_2.21.2         abind_1.4-5          scales_1.1.1        \n [43] mvtnorm_1.1-1        DBI_1.1.0            ggeffects_1.0.1     \n [46] miniUI_0.1.1.1       performance_0.6.1    xtable_1.8-4        \n [49] survey_4.0           stats4_4.0.3         StanHeaders_2.21.0-7\n [52] DT_0.16              htmlwidgets_1.5.3    threejs_0.3.3       \n [55] ellipsis_0.3.1       pkgconfig_2.0.3      loo_2.4.1           \n [58] farver_2.0.3         sass_0.2.0           utf8_1.1.4          \n [61] effectsize_0.4.1     tidyselect_1.1.0     labeling_0.4.2      \n [64] rlang_0.4.10         reshape2_1.4.4       later_1.1.0.1       \n [67] munsell_0.5.0        cellranger_1.1.0     tools_4.0.3         \n [70] cli_2.2.0            generics_0.1.0       sjlabelled_1.1.7    \n [73] broom_0.7.3          ggridges_0.5.2       evaluate_0.14       \n [76] stringr_1.4.0        fastmap_1.0.1        yaml_2.2.1          \n [79] processx_3.4.5       knitr_1.30           purrr_0.3.4         \n [82] rootSolve_1.8.2.1    nlme_3.1-151         mime_0.9            \n [85] projpred_2.0.2       compiler_4.0.3       bayesplot_1.7.2     \n [88] shinythemes_1.1.2    rstudioapi_0.13      curl_4.3            \n [91] gamm4_0.2-6          e1071_1.7-4          gt_0.2.2            \n [94] tibble_3.0.4         statmod_1.4.35       stringi_1.5.3       \n [97] parameters_0.10.1    highr_0.8            ps_1.5.0            \n[100] Brobdingnag_1.2-6    forcats_0.5.0        lattice_0.20-41     \n[103] Matrix_1.3-0         commonmark_1.7       nloptr_1.2.2.2      \n[106] markdown_1.1         shinyjs_2.0.0        vctrs_0.3.6         \n[109] pillar_1.4.7         lifecycle_0.2.0      bridgesampling_1.0-0\n[112] estimability_1.3     insight_0.11.1       lmom_2.8            \n[115] httpuv_1.5.4         R6_2.5.0             bookdown_0.21       \n[118] promises_1.1.1       gridExtra_2.3        gld_2.6.2           \n[121] codetools_0.2-18     distill_1.1          boot_1.3-25         \n[124] colourpicker_1.1.0   MASS_7.3-53          gtools_3.8.2        \n[127] assertthat_0.2.1     rprojroot_2.0.2      withr_2.3.0         \n[130] shinystan_2.5.0      multcomp_1.4-15      bayestestR_0.8.0    \n[133] expm_0.999-5         mgcv_1.8-33          parallel_4.0.3      \n[136] grid_4.0.3           class_7.3-17         tidyr_1.1.2         \n[139] coda_0.19-4          minqa_1.2.4          snakecase_0.11.0    \n[142] rmarkdown_2.6        downlit_0.2.1        shiny_1.5.0         \n[145] lubridate_1.7.9.2    base64enc_0.1-3      dygraphs_1.1.1.6    \n\n\n\n\n",
      "last_modified": "2020-12-31T05:45:24-03:00"
    },
    {
      "path": "index.html",
      "title": "Estatística Bayesiana com R e RStan",
      "description": "Companion para a disciplina de Estatística Bayesiana para alunos de Mestrado e Doutorado da UNINOVE\n",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nAulas\nO que esta disciplina não é\nRStudio na Núvem Gratuito\nProfessor\n\nComo usar esse conteúdo?\nReferências\nLivros\nArtigos\n\n\nAulas\nConteúdos Primários:\nComandos Básicos de R\nRegressão Linear Bayesiana\nDistribuições Estatísticas\nPriors\nMarkov Chain Montecarlo (MCMC)\nRegressão Binomial Bayesiana\nRegressão de Poisson Bayesiana\nRegressão Robusta Bayesiana\nModelos Multiníveis\nConteúdos Auxiliares:\nDados Faltantes\nCoeficientes de uma Regressão\nTabelas para Publicação\nO que esta disciplina não é\nNão será coberto conteúdos sobre leitura, manipulação e exportação de dados com R. Para isso recomendo fortemente o livro R para Data Science que pode ser encontrado gratuitamente aqui e possui uma versão impressa em português.\n\nRStudio na Núvem Gratuito\nClique no ícone abaixo para abrir uma sessão do RStudio no Projeto Binder.\n\nProfessor\nProf. Dr. José Eduardo Storopoli - Currículo Lattes - ORCID - CV\njosees@uni9.pro.br\nComo usar esse conteúdo?\nEste conteúdo possui licença livre para uso (CC BY-SA). Caso queira utilizar o conteúdo para um curso ou estudos, por favor colabore nesse repositório quaisquer aprimorações que foram realizadas.\nPara configurar um ambiente local:\nClone o repositório do GitHub: git clone https://github.com/storopoli/Estatistica-Bayesiana.git\nAcesse o diretório: cd Estatistica-Bayesiana\nInstale os pacotes necessários: Rscript install.R\nReferências\nLivros\nGelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian data analysis. Chapman and Hall/CRC.\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan. CRC press.\nGelman, A., Hill, J., & Vehtari, A. (2020). Regression and other stories. Cambridge University Press.\nArtigos\nBenjamin, D. J., Berger, J. O., Johannesson, M., Nosek, B. A., Wagenmakers, E.-J., Berk, R., … Johnson, V. E. (2018). Redefine statistical significance. Nature Human Behaviour, 2(1), 6–10. https://doi.org/10.1038/s41562-017-0189-z\nCarpenter, B., Gelman, A., Hoffman, M. D., Lee, D., Goodrich, B., Betancourt, M., … Riddell, A. (2017). Stan : A Probabilistic Programming Language. Journal of Statistical Software, 76(1). https://doi.org/10.18637/jss.v076.i01\nEtz, A. (2018). Introduction to the Concept of Likelihood and Its Applications. Advances in Methods and Practices in Psychological Science, 1(1), 60–69. https://doi.org/10.1177/2515245917744314\nEtz, A., Gronau, Q. F., Dablander, F., Edelsbrunner, P. A., & Baribault, B. (2018). How to become a Bayesian in eight easy steps: An annotated reading list. Psychonomic Bulletin and Review, 25(1), 219–234. https://doi.org/10.3758/s13423-017-1317-5\nGeyer, C. J. (2011). Introduction to markov chain monte carlo. In S. Brooks, A. Gelman, G. L. Jones, & X.-L. Meng (Eds.), Handbook of markov chain monte carlo.\nMcShane, B. B., Gal, D., Gelman, A., Robert, C., & Tackett, J. L. (2019). Abandon Statistical Significance. American Statistician, 73(sup1), 235–245. https://doi.org/10.1080/00031305.2018.1527253\nvan Ravenzwaaij, D., Cassey, P., & Brown, S. D. (2018). A simple introduction to Markov Chain Monte–Carlo sampling. Psychonomic Bulletin and Review, 25(1), 143–154. https://doi.org/10.3758/s13423-016-1015-8\nVandekerckhove, J., Matzke, D., Wagenmakers, E.-J., & others. (2015). Model comparison and the principle of parsimony. In J. R. Busemeyer, Z. Wang, J. T. Townsend, & A. Eidels (Eds.), Oxford handbook of computational and mathematical psychology (pp. 300–319). Oxford University Press Oxford.\nVan de Schoot, R., Kaplan, D., Denissen, J., Asendorpf, J. B., Neyer, F. J., & van Aken, M. A. G. (2014). A Gentle Introduction to Bayesian Analysis: Applications to Developmental Research. Child Development, 85(3), 842–860. https://doi.org/10.1111/cdev.12169\nWagenmakers, E.-J. (2007). A practical solution to the pervasive problems of p values. Psychonomic Bulletin & Review, 14(5), 779–804. https://doi.org/10.3758/BF03194105\n\n\n\n",
      "last_modified": "2020-12-31T05:46:46-03:00"
    },
    {
      "path": "README.html",
      "author": [],
      "contents": "\n\nContents\nEstatística Bayesiana\nProfessor\nComo usar esse conteúdo?\nAulas\nReferências\nLivros\nArtigos\n\n\n\nEstatística Bayesiana\nDisciplina de Estatística Bayesiana da UNINOVE\nDisciplina do Mestrado e Doutorado em Administração da UNINOVE\nSegundo Semestre de 2020\nRStudio: \nProfessor\nProf. Dr. José Eduardo Storopoli - Currículo Lattes - ORCID - CV\njosees@uni9.pro.br\nComo usar esse conteúdo?\nEste conteúdo possui licença livre para uso. Caso queira utilizar o conteúdo para um curso ou estudos, por favor colabore nesse repositório quaisquer aprimorações que foram realizadas.\nPara configurar um ambiente local:\nClone o repositório do GitHub: git clone https://github.com/storopoli/Estatistica-Bayesiana.git\nAcesse o diretório: cd Estatistica-Bayesiana\nInstale os pacotes necessários: Rscript install.R\nAulas\nComandos Básicos de R\nRegressão Linear Bayesiana\nDistribuições Estatísticas\nPriors\nMarkov Chain Montecarlo (MCMC)\nRegressão Binomial Bayesiana\nRegressão de Poisson Bayesiana\nRegressão Robusta Bayesiana\nModelos Multiníveis\nDados Faltantes\nCoeficientes de uma Regressão\nTabelas para Publicação\nReferências\nLivros\nGelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian data analysis. Chapman and Hall/CRC.\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan. CRC press.\nGelman, A., Hill, J., & Vehtari, A. (2020). Regression and other stories. Cambridge University Press.\nArtigos\nBásicos\nBenjamin, D. J., Berger, J. O., Johannesson, M., Nosek, B. A., Wagenmakers, E.-J., Berk, R., … Johnson, V. E. (2018). Redefine statistical significance. Nature Human Behaviour, 2(1), 6–10. https://doi.org/10.1038/s41562-017-0189-z\nCarpenter, B., Gelman, A., Hoffman, M. D., Lee, D., Goodrich, B., Betancourt, M., … Riddell, A. (2017). Stan : A Probabilistic Programming Language. Journal of Statistical Software, 76(1). https://doi.org/10.18637/jss.v076.i01\nEtz, A. (2018). Introduction to the Concept of Likelihood and Its Applications. Advances in Methods and Practices in Psychological Science, 1(1), 60–69. https://doi.org/10.1177/2515245917744314\nEtz, A., Gronau, Q. F., Dablander, F., Edelsbrunner, P. A., & Baribault, B. (2018). How to become a Bayesian in eight easy steps: An annotated reading list. Psychonomic Bulletin and Review, 25(1), 219–234. https://doi.org/10.3758/s13423-017-1317-5\nGeyer, C. J. (2011). Introduction to markov chain monte carlo. In S. Brooks, A. Gelman, G. L. Jones, & X.-L. Meng (Eds.), Handbook of markov chain monte carlo.\nMcShane, B. B., Gal, D., Gelman, A., Robert, C., & Tackett, J. L. (2019). Abandon Statistical Significance. American Statistician, 73(sup1), 235–245. https://doi.org/10.1080/00031305.2018.1527253\nvan Ravenzwaaij, D., Cassey, P., & Brown, S. D. (2018). A simple introduction to Markov Chain Monte–Carlo sampling. Psychonomic Bulletin and Review, 25(1), 143–154. https://doi.org/10.3758/s13423-016-1015-8\nVandekerckhove, J., Matzke, D., Wagenmakers, E.-J., & others. (2015). Model comparison and the principle of parsimony. In J. R. Busemeyer, Z. Wang, J. T. Townsend, & A. Eidels (Eds.), Oxford handbook of computational and mathematical psychology (pp. 300–319). Oxford University Press Oxford.\nVan de Schoot, R., Kaplan, D., Denissen, J., Asendorpf, J. B., Neyer, F. J., & van Aken, M. A. G. (2014). A Gentle Introduction to Bayesian Analysis: Applications to Developmental Research. Child Development, 85(3), 842–860. https://doi.org/10.1111/cdev.12169\nWagenmakers, E.-J. (2007). A practical solution to the pervasive problems of p values. Psychonomic Bulletin & Review, 14(5), 779–804. https://doi.org/10.3758/BF03194105\nComplementares\nCohen, J. (1994). The earth is round (p < .05). American Psychologist, 49(12), 997–1003. https://doi.org/10.1037/0003-066X.49.12.997\nDienes, Z. (2011). Bayesian versus orthodox statistics: Which side are you on? Perspectives on Psychological Science, 6(3), 274–290. https://doi.org/10.1177/1745691611406920\nEtz, A., & Vandekerckhove, J. (2018). Introduction to Bayesian Inference for Psychology. Psychonomic Bulletin & Review, 25(1), 5–34. https://doi.org/10.3758/s13423-017-1262-3\nKerr, N. L. (1998). HARKing: Hypothesizing after the results are known. Personality and Social Psychology Review, 2(3), 196–217. https://doi.org/10.1207/s15327957pspr0203_4\nKruschke, J. K., & Vanpaemel, W. (2015). Bayesian estimation in hierarchical models. In J. R. Busemeyer, Z. Wang, J. T. Townsend, & A. Eidels (Eds.), The Oxford handbook of computational and mathematical psychology (pp. 279–299). Oxford University Press Oxford, UK.\nKruschke, J. K., & Liddell, T. M. (2018a). Bayesian data analysis for newcomers. Psychonomic Bulletin and Review, 25(1), 155–177. https://doi.org/10.3758/s13423-017-1272-1\nKruschke, J. K., & Liddell, T. M. (2018b). The Bayesian New Statistics: Hypothesis testing, estimation, meta-analysis, and power analysis from a Bayesian perspective. Psychonomic Bulletin and Review, 25(1), 178–206. https://doi.org/10.3758/s13423-016-1221-4\nLakens, D., Adolfi, F. G., Albers, C. J., Anvari, F., Apps, M. A. J., Argamon, S. E., … Zwaan, R. A. (2018, March 1). Justify your alpha. Nature Human Behaviour, Vol. 2, pp. 168–171. https://doi.org/10.1038/s41562-018-0311-x\nMorey, R. D., Hoekstra, R., Rouder, J. N., Lee, M. D., & Wagenmakers, E.-J. (2016). The fallacy of placing confidence in confidence intervals. Psychonomic Bulletin & Review, 23(1), 103–123. https://doi.org/10.3758/s13423-015-0947-8\nMourão Júnior, C. A. (2019). Quanto vale o valor-p? Arquivos de Ciências Do Esporte, 7(2), 72–74. http://seer.uftm.edu.br/revistaeletronica/index.php/aces\nMurphy, K. R., & Aguinis, H. (2019). HARKing: How Badly Can Cherry-Picking and Question Trolling Produce Bias in Published Results? Journal of Business and Psychology, 34(1). https://doi.org/10.1007/s10869-017-9524-7\nStark, P. B., & Saltelli, A. (2018). Cargo-cult statistics and scientific crisis. Significance, 15(4), 40–43. https://doi.org/10.1111/j.1740-9713.2018.01174.x\n",
      "last_modified": "2020-12-31T05:46:46-03:00"
    }
  ],
  "collections": []
}

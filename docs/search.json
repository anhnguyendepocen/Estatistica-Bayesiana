{
  "articles": [
    {
      "path": "1-Comandos_Basicos.html",
      "title": "Comandos Básicos de R",
      "description": "Introdução ao R e aos comandos básicos do R.\n",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "August 2, 2020",
      "contents": "\n\nContents\nLendo Arquivos de Dados\nCSV\nExcel\n\nGráficos\nAmbiente\n\n\nEste arquivo é um documento R Markdown. Ele é uma proposta de prosa com código em R, além de ser o formato preferido nosso de comunicar nossas análises. Quando renderizamos o documento no formato desejado. Todo código que é inserido nele é executado e as saídas são incorporadas no documento final. Isto vale para tabelas e gráficos. Por exemplo, podemos pedir para o R imprimir algo com a função print() e o resultado será o código que foi executado e o seu resultado.\n\n\nprint(\"Você executou um código\")\n\n\n[1] \"Você executou um código\"\n\nO formato R Markdown é muito flexível. Podemos fazer relatórios (em PDF, Word e HTML), apresentações (em PDF, PowerPoint e HTML), artigos acadêmicos, livros, websites1, blogs, CVs, etc.\n\nO site do primeiro autor foi feito usando a biblioteca {postcars} de R. O CV também foi feito em R usando a biblioteca {vitae}.\nLendo Arquivos de Dados\nCom o R conseguimos ler diversos tipo de arquivos de dados: CSV, texto, HTML, Excel, Stata, SPSS, Planilhas Google, Banco de Dados Relacionais, entre outros… Vamos demonstrar como ler arquivso de dados dos dois formatos mais comuns: CSV e Excel.\nCSV\nPara ler um arquivo CSV (.csv) no R execute a função read.csv() para arquivos CSV formato americano (vírgula como separador e decimais como ponto) ou a função read.csv2() para arquivos CSV formato europeu/brasileiro (ponto-e-vírgula como separador e decimais como vírgula). Não esqueça de designar a leitura para uma variável com o designador <-.\n\n\ndf <- read.csv2(\"datasets/mtcars.csv\", row.names = 1)\nhead(df)\n\n\n                  mpg cyl disp  hp drat  wt qsec vs am gear carb\nMazda RX4          21   6  160 110  3.9 2.6   16  0  1    4    4\nMazda RX4 Wag      21   6  160 110  3.9 2.9   17  0  1    4    4\nDatsun 710         23   4  108  93  3.9 2.3   19  1  1    4    1\nHornet 4 Drive     21   6  258 110  3.1 3.2   19  1  0    3    1\nHornet Sportabout  19   8  360 175  3.1 3.4   17  0  0    3    2\nValiant            18   6  225 105  2.8 3.5   20  1  0    3    1\n\nExcel\nPara ler um arquivo Excel (.xls ou .xlsx) no R é necessário importar um pacote chamado readxl que contem a função read_excel. Para importar um pacote no R executamos o comando library() com um argumento único sendo o nome do pacote. Caso não tenha o pacote instalado, deve instalar ele com o comando install.packages(). Não esqueça de colocar o nome do pacote entre aspas \"nome_do_pacote\" dentro do parênteses da função.\n\n\n# install.packages(\"readxl\")\nlibrary(readxl)\ndf <- read_excel(\"datasets/mtcars.xlsx\")\nhead(df)\n\n\n# A tibble: 6 x 12\n  ...1       mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear\n  <chr>    <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n1 Mazda R…  21       6   160   110  3.9   2.62  16.5     0     1     4\n2 Mazda R…  21       6   160   110  3.9   2.88  17.0     0     1     4\n3 Datsun …  22.8     4   108    93  3.85  2.32  18.6     1     1     4\n4 Hornet …  21.4     6   258   110  3.08  3.22  19.4     1     0     3\n5 Hornet …  18.7     8   360   175  3.15  3.44  17.0     0     0     3\n6 Valiant   18.1     6   225   105  2.76  3.46  20.2     1     0     3\n# … with 1 more variable: carb <dbl>\n\nGráficos\nGeralmente no R você pode plotar mostrar graficamente diversos objetos com o comando plot(). Quando você plota um dataset (conjunto de dados lido de um aquivo), o R retorna um gráfico chamado Pair Plot:\nNa diagonal: nome da variável (coluna do dataset)\nFora da diagonal: um gráfico de dispersão entre a variável no eixo horizontal e a variável no eixo vertical\nExemplo: na figura 1 veja a relação entre disp (cilindrada) e hp (cavalos de potência). Ela é uma relação positiva. Quanto maior disp maior hp.\n\n\nplot(mtcars)\n\n\n\n\nFigure 1: Pair Plot do dataset mtcars\n\n\n\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.3 (2020-10-10)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n[1] readxl_1.3.1\n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.5       knitr_1.30       magrittr_2.0.1  \n [4] downlit_0.2.1    rlang_0.4.10     fansi_0.4.1     \n [7] highr_0.8        stringr_1.4.0    tools_4.0.3     \n[10] parallel_4.0.3   xfun_0.19        utf8_1.1.4      \n[13] cli_2.2.0        htmltools_0.5.0  ellipsis_0.3.1  \n[16] yaml_2.2.1       digest_0.6.27    assertthat_0.2.1\n[19] tibble_3.0.4     lifecycle_0.2.0  crayon_1.3.4    \n[22] vctrs_0.3.6      distill_1.1      glue_1.4.2      \n[25] evaluate_0.14    rmarkdown_2.6    stringi_1.5.3   \n[28] compiler_4.0.3   pillar_1.4.7     cellranger_1.1.0\n[31] pkgconfig_2.0.3 \n\n\nesse website foi todo feito com R↩︎\n",
      "last_modified": "2021-01-03T04:51:06-03:00"
    },
    {
      "path": "2-Regressao_Linear.html",
      "title": "Regressão Linear Bayesiana",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "August 2, 2020",
      "contents": "\n\nContents\nrstanarm\nRegressão Linear\nExemplo - Score de QI de crianças\nDescritivo das variáveis\nModelo 1 - mom_hs\nModelo 2 - mom_iq\nModelo 3 - mom_hs + mom_iq\nModelo 4 - mom_hs * mom_iq\n\nVariáveis qualitativas\nAtividade Prática\nWHO Life Expectancy\nWine Quality Kaggle Dataset\n\nReferências\nAmbiente\n\n\n\nA principal ferramenta para computação Bayesiana é a linguagem probabilística Stan. O nome homenageia Stanislaw Ulam: um matemático polonês membro do projeto Manhattan (bomba atômica americana) e um dos principais criadores do método de Monte Carlo de simulação. Stan foi lançado em 2012 e é a principal ferramenta utilizada hoje para inferência estatística Bayesiana. O programa roda em linguagem C++, mas possui interfaces para R, Python, MATLAB, Julia, Stata, Mathematica, Scala e Shell.\nO problema do Stan é que ele é uma linguagem de programação e, portanto, possui um acesso dificultado a não-programadores. Abaixo um código que mostra como é um programa escrito em Stan:\n\ndata {\n  int<lower=0> N;\n  vector<lower=0, upper=200>[N] kid_score;\n  vector<lower=0, upper=200>[N] mom_iq;\n}\nparameters {\n  vector[2] beta;\n  real<lower=0> sigma;\n}\nmodel {\n  sigma ~ cauchy(0, 2.5);\n  kid_score ~ normal(beta[1] + beta[2] * mom_iq, sigma);\n}\n\nrstanarm\nPara remediar isso, temos interfaces abstratas que interpretam a intenção do usuário e lidam com a parte mais obral de codificação. A principal delas é o pacote rstanarm, que a etmologia pode ser quebrada em:\nr: pacote para R\nstan: usa a linguagem probabilística Stan\narm: acrônimo para Applied Regression Modeling\nO código anterior de Stan ficaria assim no rstanarm:\n\n\nstan_glm(kid_score ~ mom_iq, data = dataset)\n\n\n\nRegressão Linear\nA ideia aqui é modelar uma variável dependente sendo a combinação linear de variáveis independentes.\n\\[y = \\alpha + \\boldsymbol{\\beta} \\textbf{X} + \\epsilon\\]\nAonde \\(y\\) é a variável dependente, \\(\\alpha\\) um constante, \\(\\boldsymbol{\\beta}\\) um vetor de coeficientes, \\(\\textbf{X}\\) uma matriz de dados e \\(\\epsilon\\) o erro do modelo.\nExemplo - Score de QI de crianças\nVamos aplicar modelagem estatística Bayesiana em um dataset famoso chamado kidiq. São dados de uma survey de mulheres adultas norte-americanas e seus respectivos filhos. Datado de 2007 possui 434 observações e 4 variáveis:\nkid_score: QI da criança;\nmom_hs: binária (0 ou 1) se a mãe possui diploma de ensino médio;\nmom_iq: QI da mãe; e\nmom_age: idade da mãe.\nVamos usar 4 modelos para modelar QI da criança (kid_score). Os primeiros dois modelos terão apenas um único preditor (mom_hs ou mom_iq), o terceiro usará dois preditores (mom_hs + mom_iq) e o quarto incluirá uma interação entre esses dois preditores (mom_hs * mom_iq),\nDescritivo das variáveis\nAntes de tudo, analise SEMPRE os dados em mãos. Graficamente e com tabelas.\nGráficos\n\n\n# Detectar quantos cores/processadores\noptions(mc.cores = parallel::detectCores())\noptions(Ncpus = parallel::detectCores())\n\nlibrary(rstanarm)\ndata(kidiq)\n\nboxplot(kidiq)\n\n\n\n\nTabelas\nPessoalmente uso o pacote skimr com a função skim():\n\n\nlibrary(skimr)\n\nskim(kidiq)\n\n\nTable 1: Data summary\nName\nkidiq\nNumber of rows\n434\nNumber of columns\n4\n_______________________\n\nColumn type frequency:\n\nnumeric\n4\n________________________\n\nGroup variables\nNone\nVariable type: numeric\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\nkid_score\n0\n1\n86.80\n20.41\n20\n74\n90\n102\n144\n▁▃▇▇▁\nmom_hs\n0\n1\n0.79\n0.41\n0\n1\n1\n1\n1\n▂▁▁▁▇\nmom_iq\n0\n1\n100.00\n15.00\n71\n89\n98\n110\n139\n▃▇▆▃▂\nmom_age\n0\n1\n22.79\n2.70\n17\n21\n23\n25\n29\n▂▅▇▃▂\n\nModelo 1 - mom_hs\nPrimeiro modelo é apenas a variável mom_hs como preditora:\n\n\nmodel_1 <- stan_glm(\n  kid_score ~ mom_hs,\n  data = kidiq\n  )\n\n\n\nPara ver os valores estimados pelo modelo usamos a função print:\n\n\nprint(model_1)\n\n\nstan_glm\n family:       gaussian [identity]\n formula:      kid_score ~ mom_hs\n observations: 434\n predictors:   2\n------\n            Median MAD_SD\n(Intercept) 77.6    2.1  \nmom_hs      11.7    2.2  \n\nAuxiliary parameter(s):\n      Median MAD_SD\nsigma 19.9    0.7  \n\n------\n* For help interpreting the printed output see ?print.stanreg\n* For info on the priors used see ?prior_summary.stanreg\n\nAlém disso, temos a função summary que traz tudo que queremos:\n\n\nsummary(model_1)\n\n\n\nModel Info:\n function:     stan_glm\n family:       gaussian [identity]\n formula:      kid_score ~ mom_hs\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 434\n predictors:   2\n\nEstimates:\n              mean   sd   10%   50%   90%\n(Intercept) 77.6    2.1 74.9  77.6  80.2 \nmom_hs      11.8    2.3  8.8  11.7  14.7 \nsigma       19.9    0.7 19.0  19.9  20.8 \n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 86.8    1.4 85.1  86.8  88.6 \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n              mcse Rhat n_eff\n(Intercept)   0.0  1.0  3826 \nmom_hs        0.0  1.0  3713 \nsigma         0.0  1.0  3640 \nmean_PPD      0.0  1.0  3427 \nlog-posterior 0.0  1.0  1770 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nModelo 2 - mom_iq\nSegundo modelo é apenas a variável mom_iq como preditora:\n\n\nmodel_2 <- stan_glm(\n  kid_score ~ mom_iq,\n  data = kidiq\n  )\n\n\n\nPodemos também especificar os percentis desejados no sumário:\n\n\nsummary(model_2, probs = c(0.025, 0.975))\n\n\n\nModel Info:\n function:     stan_glm\n family:       gaussian [identity]\n formula:      kid_score ~ mom_iq\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 434\n predictors:   2\n\nEstimates:\n              mean   sd   2.5%   98%\n(Intercept) 25.9    5.9 14.7   37.4 \nmom_iq       0.6    0.1  0.5    0.7 \nsigma       18.3    0.6 17.1   19.6 \n\nFit Diagnostics:\n           mean   sd   2.5%   98%\nmean_PPD 86.8    1.2 84.3   89.3 \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n              mcse Rhat n_eff\n(Intercept)   0.1  1.0  3782 \nmom_iq        0.0  1.0  3751 \nsigma         0.0  1.0  3713 \nmean_PPD      0.0  1.0  3990 \nlog-posterior 0.0  1.0  1691 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nModelo 3 - mom_hs + mom_iq\nTerceiro modelo usa as duas variáveis mom_hs e mom_iq como preditoras:\n\n\nmodel_3 <- stan_glm(\n  kid_score ~ mom_hs + mom_iq,\n  data = kidiq\n  )\n\n\n\n\n\nprint(model_3)\n\n\nstan_glm\n family:       gaussian [identity]\n formula:      kid_score ~ mom_hs + mom_iq\n observations: 434\n predictors:   3\n------\n            Median MAD_SD\n(Intercept) 25.9    6.1  \nmom_hs       6.0    2.2  \nmom_iq       0.6    0.1  \n\nAuxiliary parameter(s):\n      Median MAD_SD\nsigma 18.2    0.6  \n\n------\n* For help interpreting the printed output see ?print.stanreg\n* For info on the priors used see ?prior_summary.stanreg\n\nModelo 4 - mom_hs * mom_iq\nQuarto modelo usa as duas variáveis mom_hs e mom_iq como preditoras por meio de uma interação entre as duas:\n\n\nmodel_4 <- stan_glm(\n  kid_score ~ mom_hs * mom_iq,\n  data = kidiq\n  )\n\n\n\n\n\nprint(model_4)\n\n\nstan_glm\n family:       gaussian [identity]\n formula:      kid_score ~ mom_hs * mom_iq\n observations: 434\n predictors:   4\n------\n              Median MAD_SD\n(Intercept)   -9.8   13.8  \nmom_hs        49.5   15.8  \nmom_iq         1.0    0.1  \nmom_hs:mom_iq -0.5    0.2  \n\nAuxiliary parameter(s):\n      Median MAD_SD\nsigma 18.0    0.6  \n\n------\n* For help interpreting the printed output see ?print.stanreg\n* For info on the priors used see ?prior_summary.stanreg\n\nVariáveis qualitativas\nPara as variáveis qualitativas, o R usa um tipo especial de variável chamado factor. A codificação é em números inteiros \\(1,2,\\dots,K\\) mas a relação é distinta/nominal. Ou seja 1 é distinto de 2 e não 1 é 2x menor que 2. Não há relação quantitativa entre os valores das variáveis factor.\nIsso resolve o problema de termos variáveis qualitativas (também chamadas de dummy) em modelos de regressão. Para um factor com \\(K\\) quantidade de classes distintas, temos a possibilidade de criar \\(K-1\\) coeficientes de regressão. Um para cada classe e usando uma como basal (baseline).\n\n\nlibrary(gapminder)\nlevels(gapminder$continent)\n\n\n[1] \"Africa\"   \"Americas\" \"Asia\"     \"Europe\"   \"Oceania\" \n\nmodel_5 <- stan_glm(lifeExp ~ gdpPercap + factor(continent), data = gapminder)\n\n\n\n\n\nprint(model_5)\n\n\nstan_glm\n family:       gaussian [identity]\n formula:      lifeExp ~ gdpPercap + factor(continent)\n observations: 1704\n predictors:   6\n------\n                          Median MAD_SD\n(Intercept)               47.9    0.3  \ngdpPercap                  0.0    0.0  \nfactor(continent)Americas 13.6    0.6  \nfactor(continent)Asia      8.7    0.6  \nfactor(continent)Europe   17.6    0.6  \nfactor(continent)Oceania  18.1    1.8  \n\nAuxiliary parameter(s):\n      Median MAD_SD\nsigma 8.4    0.1   \n\n------\n* For help interpreting the printed output see ?print.stanreg\n* For info on the priors used see ?prior_summary.stanreg\n\nObs: para mudar o basal de referência de um factor use a função relevel() do R.\nAtividade Prática\nDois datasets estão disponíveis na pasta datasets/:\nWHO Life Expectancy Kaggle Dataset: datasets/WHO_Life_Exp.csv\nWine Quality Kaggle Dataset: datasets/Wine_Quality.csv\nWHO Life Expectancy\nEsse dataset possui 193 países nos últimos 15 anos.\nVariáveis\ncountry\nyear\nstatus\nlife_expectancy\nadult_mortality\ninfant_deaths\nalcohol\npercentage_expenditure\nhepatitis_b\nmeasles\nbmi\nunder_five_deaths\npolio\ntotal_expenditure\ndiphtheria\nhiv_aids\ngdp\npopulation\nthinness_1_19_years\nthinness_5_9_years\nincome_composition_of_resources\nschooling\nWine Quality Kaggle Dataset\nEsse dataset possui 1599 vinhos e estão relacionados com variantes tintas do vinho “Vinho Verde” português. Para mais detalhes, consulte a referência [Cortez et al., 2009]. Devido a questões de privacidade e logística, apenas variáveis físico-químicas (entradas) e sensoriais (a saída) estão disponíveis (por exemplo, não há dados sobre os tipos de uva, marca de vinho, preço de venda do vinho, etc.).\nfixed_acidity\nvolatile_acidity\ncitric_acid\nresidual_sugar\nchlorides\nfree_sulfur_dioxide\ntotal_sulfur_dioxide\ndensity\np_h\nsulphates\nalcohol\nquality\n\n\n###\n\n\n\nReferências\nP. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009.\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.3 (2020-10-10)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n[1] gapminder_0.3.0 skimr_2.1.2     rstanarm_2.21.1 Rcpp_1.0.5     \n[5] readxl_1.3.1   \n\nloaded via a namespace (and not attached):\n  [1] nlme_3.1-151         matrixStats_0.57.0   xts_0.12.1          \n  [4] lubridate_1.7.9.2    threejs_0.3.3        rprojroot_2.0.2     \n  [7] rstan_2.21.2         repr_1.1.0           tools_4.0.3         \n [10] utf8_1.1.4           R6_2.5.0             DT_0.16             \n [13] colorspace_2.0-0     withr_2.3.0          tidyselect_1.1.0    \n [16] gridExtra_2.3        prettyunits_1.1.1    processx_3.4.5      \n [19] downlit_0.2.1        curl_4.3             compiler_4.0.3      \n [22] cli_2.2.0            shinyjs_2.0.0        colourpicker_1.1.0  \n [25] bookdown_0.21        scales_1.1.1         dygraphs_1.1.1.6    \n [28] ggridges_0.5.2       callr_3.5.1          stringr_1.4.0       \n [31] digest_0.6.27        StanHeaders_2.21.0-7 minqa_1.2.4         \n [34] rmarkdown_2.6        base64enc_0.1-3      pkgconfig_2.0.3     \n [37] htmltools_0.5.0      lme4_1.1-26          fastmap_1.0.1       \n [40] highr_0.8            htmlwidgets_1.5.3    rlang_0.4.10        \n [43] rstudioapi_0.13      shiny_1.5.0          generics_0.1.0      \n [46] zoo_1.8-8            jsonlite_1.7.2       crosstalk_1.1.0.1   \n [49] gtools_3.8.2         dplyr_1.0.2          distill_1.1         \n [52] inline_0.3.17        magrittr_2.0.1       loo_2.4.1           \n [55] bayesplot_1.7.2      Matrix_1.3-0         munsell_0.5.0       \n [58] fansi_0.4.1          lifecycle_0.2.0      stringi_1.5.3       \n [61] yaml_2.2.1           MASS_7.3-53          pkgbuild_1.2.0      \n [64] plyr_1.8.6           grid_4.0.3           parallel_4.0.3      \n [67] promises_1.1.1       crayon_1.3.4         miniUI_0.1.1.1      \n [70] lattice_0.20-41      splines_4.0.3        knitr_1.30          \n [73] ps_1.5.0             pillar_1.4.7         igraph_1.2.6        \n [76] boot_1.3-25          markdown_1.1         shinystan_2.5.0     \n [79] reshape2_1.4.4       codetools_0.2-18     stats4_4.0.3        \n [82] rstantools_2.1.1     glue_1.4.2           evaluate_0.14       \n [85] V8_3.4.0             RcppParallel_5.0.2   nloptr_1.2.2.2      \n [88] vctrs_0.3.6          httpuv_1.5.4         cellranger_1.1.0    \n [91] tidyr_1.1.2          gtable_0.3.0         purrr_0.3.4         \n [94] assertthat_0.2.1     ggplot2_3.3.3        xfun_0.19           \n [97] mime_0.9             xtable_1.8-4         later_1.1.0.1       \n[100] survival_3.2-7       rsconnect_0.8.16     tibble_3.0.4        \n[103] shinythemes_1.1.2    statmod_1.4.35       ellipsis_0.3.1      \n\n\n\n\n",
      "last_modified": "2021-01-03T04:51:20-03:00"
    },
    {
      "path": "3-Distribuicoes_Estatisticas.html",
      "title": "Distribuições Estatísticas",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "August 2, 2020",
      "contents": "\n\nContents\nDiscretas\nUniforme Discreta\nBinomial\nPoisson\n\nContínuas\nNormal / Gaussiana\nLog-normal\nExponencial\nDistribuição t de Student\n\nDashboard de Distribuições\nAmbiente\n\n\nA estatística usa distribuições probabilísticas como o motor de sua inferência na elaboração dos valores dos parâmetros estimados e suas incertezas.\nUma distribuição de probabilidade é a função matemática que fornece as probabilidades de ocorrência de diferentes resultados possíveis para um experimento. É uma descrição matemática de um fenômeno aleatório em termos de seu espaço amostral e as probabilidades de eventos (subconjuntos do espaço amostral)\nGeralmente usamos a notação X ~ Dist(par1, par2, ...). Onde X é a variável Dist é a distribuição e par os parâmetros que definem como a distribuição se comporta.\nDiscretas\nDistribuições de probabilidade discretas são aquelas que os resultados são números discretos (também chamados de números inteiros): \\(\\dots, -2, 1, 0,1,2,\\dots, N\\) e \\(N \\in \\mathbb{Z}\\).\nUniforme Discreta\nA distribuição uniforme discreta é uma distribuição de probabilidade simétrica em que um número finito de valores são igualmente prováveis de serem observados. Cada um dos \\(n\\) valores tem probabilidade igual \\(\\frac{1}{n}\\). Outra maneira de dizer “distribuição uniforme discreta” seria “um número conhecido e finito de resultados igualmente prováveis de acontecer”.\nA distribuição uniforme discreta possui dois parâmetros e sua notação é \\(U(a, b)\\):\nLimite Inferior (\\(a\\))\nLimite Superior (\\(b\\))\nExemplo: Um dado.\n\n\nx <- seq(1, 6)\ny <- dunif(x, min = 1, max = 6)\n\nplot(x, y, xlab=\"valor de x\",\n  ylab=\"Densidade\",\n  main=\"Distribuição Uniforme Discreta\",\n  lwd=2, col=\"red\"\n)\n\n\n\n\nBinomial\nA distribuição binomial descreve um evento do número de sucessos em uma sequência de \\(n\\) experimentos independentes, cada um fazendo uma pergunta sim-não.\nA distribuição binomial é freqüentemente usada para modelar o número de sucessos em uma amostra de tamanho \\(n\\) desenhada com substituição de uma população de tamanho \\(N\\).\nA distribuição binomial possui dois parâmetros e sua notação é \\(Bin(n, p)\\):\nNúmero de Experimentos (\\(n\\))\nProbabiliade de Sucessos (\\(p\\))\nExemplo: quantidade de caras em 5 lançamentos de uma moeda.\n\n\nx <- seq(0, 5)\n\nprobs <- c(0.1, 0.2, 0.5)\ncolors <- c(\"red\", \"blue\", \"darkgreen\")\nlabels <- c(\"p=0.1\", \"p=0.2\", \"p=0.5\")\n\nplot(NA, xlab=\"valor de x\",\n  ylab=\"Densidade\",\n  main=\"Comparativo de Distribuições Binomiais\",\n  xlim = c(0, 5),\n  ylim = c(0, 1))\n\nfor (i in 1:4){\n  lines(x, dbinom(x, 5, prob = probs[i]), lwd=2, col=colors[i])\n}\n\nlegend(\"topright\", inset=.05, title=\"Desvio Padrões\",\n  labels, lwd=2, lty=c(1, 1, 1, 1, 2), col=colors)\n\n\n\n\nPoisson\nA distribuição Poisson expressa a probabilidade de um determinado número de eventos ocorrerem em um intervalo fixo de tempo ou espaço se esses eventos ocorrerem com uma taxa média constante conhecida e independentemente do tempo desde o último evento. A distribuição de Poisson também pode ser usada para o número de eventos em outros intervalos especificados, como distância, área ou volume.\nA distribuição Poisson possui um parâmetro e sua notação é \\(pois(\\lambda)\\):\nTaxa (\\(\\lambda\\))\nExemplo: Quantidade de e-mails que você recebe diariamente. Quantidade de buracos que você encontra na rua.\n\n\nx <- seq(0, 20)\n\nrates <- c(1, 4, 10)\ncolors <- c(\"red\", \"blue\", \"darkgreen\")\nlabels <- c(\"taxa=1\", \"taxa=4\", \"taxa=10\")\n\nplot(NA, xlab=\"valor de x\",\n  ylab=\"Densidade\",\n  main=\"Comparativo de Distribuições Poisson\",\n  xlim = c(0, 20),\n  ylim = c(0, 0.5))\n\nfor (i in 1:4){\n  lines(x, dpois(x, lambda = rates[i]), lwd=2, col=colors[i])\n}\n\nlegend(\"topright\", inset=.05, title=\"Taxas\",\n  labels, lwd=2, lty=c(1, 1, 1, 1, 2), col=colors)\n\n\n\n\nContínuas\nDistribuições de probabilidade contínuas são aquelas que os resultados são valores em uma faixa contínua (também chamados de número reais): \\([-\\infty, \\infty] \\in \\mathbb{R}\\).\nNormal / Gaussiana\nEssa distribuição geralmente é usada nas ciências sociais e naturais para representar variáveis contínuas na qual as suas distribuições não são conhecidas. Esse pressuposto é por conta do teorema do limite central. O teorema do limite central afirma que, em algumas condições, a média de muitas amostras (observações) de uma variável aleatória com média e variância finitas é ela própria uma variável aleatória cuja distribuição converge para uma distribuição normal à medida que o número de amostras aumenta. Portanto, as quantidades físicas que se espera sejam a soma de muitos processos independentes (como erros de medição) muitas vezes têm distribuições que são quase normais.\nA distribuição normal possui dois parâmetros e sua notação é \\(N(\\mu, \\sigma^2)\\):\nMédia (\\(\\mu\\)): média da distribuição e também a moda e a mediana\nDesvio Padrão (\\(\\sigma\\)): a variância da distribuição (\\(\\sigma^2\\)) é uma média de dispersão das observações em relação à média\nExemplo: Altura, Peso etc.\n\n\nx <- seq(-4, 4, length = 100)\n\ndps <- c(0.5, 1, 2, 5)\ncolors <- c(\"red\", \"blue\", \"darkgreen\", \"gold\")\nlabels <- c(\"dp=0.5\", \"dp=1\", \"dp=2\", \"dp=5\")\n\nplot(NA, xlab=\"valor de x\",\n  ylab=\"Densidade\",\n  main=\"Comparativo de Distribuições Normais\",\n  xlim = c(-4, 4),\n  ylim = c(0, 1))\n\nfor (i in 1:4){\n  lines(x, dnorm(x, mean = 0, sd = dps[i]), lwd=2, col=colors[i])\n}\n\nlegend(\"topright\", inset=.05, title=\"Desvio Padrões\",\n  labels, lwd=2, lty=c(1, 1, 1, 1, 2), col=colors)\n\n\n\n\nLog-normal\nA distribuição Log-normal é uma distribuição de probabilidade contínua de uma variável aleatória cujo logaritmo é normalmente distribuído. Assim, se a variável aleatória \\(X\\) for distribuída normalmente por log, então \\(Y = \\ln (X)\\) terá uma distribuição normal.\nUma variável aleatória com distribuição logarítmica aceita apenas valores reais positivos. É um modelo conveniente e útil para medições em ciências exatas e de engenharia, bem como medicina, economia e outros campos, por ex. para energias, concentrações, comprimentos, retornos financeiros e outros valores.\nUm processo log-normal é a realização estatística do produto multiplicativo de muitas variáveis aleatórias independentes, cada uma das quais positiva.\nA distribuição log-normal possui dois parâmetros e sua notação é \\(Lognormal(\\mu, \\sigma^2)\\):\nMédia (\\(\\mu\\)): média do logaritmo natural da distribuição\nDesvio Padrão (\\(\\sigma\\)): a variância do logaritmo natural da distribuição (\\(\\sigma^2\\)) é uma média de dispersão das observações em relação à média\n\n\nx <- seq(0, 3, length = 100)\n\ndps <- c(0.25, 0.5, 1, 1.5)\ncolors <- c(\"red\", \"blue\", \"darkgreen\", \"gold\")\nlabels <- c(\"dp=0.25\", \"dp=0.5\", \"dp=1\", \"dp=1.5\")\n\nplot(NA, xlab=\"valor de x\",\n  ylab=\"Densidade\",\n  main=\"Comparativo de Distribuições Log-Normais\",\n  xlim = c(0, 3),\n  ylim = c(0, 2))\n\nfor (i in 1:4){\n  lines(x, dlnorm(x, mean = 0, sd = dps[i]), lwd=2, col=colors[i])\n}\n\nlegend(\"topright\", inset=.05, title=\"Desvio Padrões\",\n  labels, lwd=2, lty=c(1, 1, 1, 1, 2), col=colors)\n\n\n\n\nExponencial\nA distribuição exponencial é a distribuição de probabilidade do tempo entre eventos que ocorrem de forma contínua e independente a uma taxa média constante.\nA distribuição exponencial possui um parâmetro e sua notação é \\(Exp (\\lambda)\\):\nTaxa (\\(\\lambda\\))\nExemplo: Quanto tempo até o próximo terremoto. Quanto tempo até o próximo ônibus.\n\n\nx <- seq(0, 5, length = 100)\n\nrates <- c(0.5, 1, 1.5, 2)\ncolors <- c(\"red\", \"blue\", \"darkgreen\", \"gold\")\nlabels <- c(\"taxa=0.5\", \"taxa=1.0\", \"taxa=1.5\", \"taxa=2.0\")\n\nplot(NA, xlab=\"valor de x\",\n  ylab=\"Densidade\",\n  main=\"Comparativo de Distribuições Exponenciais\",\n  xlim = c(0, 5),\n  ylim = c(0, 1.5))\n\nfor (i in 1:4){\n  lines(x, dexp(x,rate = rates[i]), lwd=2, col=colors[i])\n}\n\nlegend(\"topright\", inset=.05, title=\"Taxas\",\n  labels, lwd=2, lty=c(1, 1, 1, 1, 2), col=colors)\n\n\n\n\nDistribuição t de Student\nA distribuição t de Student surge ao estimar a média de uma população normalmente distribuída em situações onde o tamanho da amostra é pequeno e o desvio padrão da população é desconhecido.\nSe tomarmos uma amostra de \\(n\\) observações de uma distribuição normal, então a distribuição t com \\(\\nu = n-1\\) graus de liberdade pode ser definida como a distribuição da localização da média da amostra em relação à média verdadeira, dividida pela desvio padrão da amostra, após multiplicar pelo termo padronizador \\(\\sqrt{n}\\).\nA distribuição t é simétrica e em forma de sino, como a distribuição normal, mas tem caudas mais pesadas, o que significa que é mais propensa a produzir valores que estão longe de sua média.\nA distribuição t de Student possui um parâmetro e sua notação é \\(Student (\\nu)\\):\nGraus de Liberdade (\\(\\nu\\)): controla o quanto ela se assemelha com uma distribuição normal\nExemplo: Uma base de dados cheia de outliers.\n\n\nx <- seq(-4, 4, length = 100)\n\ndegfs <- c(1, 3, 8, 30)\ncolors <- c(\"red\", \"blue\", \"darkgreen\", \"gold\")\nlabels <- c(\"df=1\", \"df=3\", \"df=8\", \"df=30\")\n\nplot(NA, xlab=\"valor de x\",\n  ylab=\"Densidade\",\n  main=\"Comparativo de Distribuições t de Student\",\n  xlim = c(-4, 4),\n  ylim = c(0, 0.5))\n\nfor (i in 1:4){\n  lines(x, dt(x,df = degfs[i]), lwd=2, col=colors[i])\n}\n\nlegend(\"topright\", inset=.05, title=\"Graus de Liberdade\",\n  labels, lwd=2, lty=c(1, 1, 1, 1, 2), col=colors)\n\n\n\n\nDashboard de Distribuições\nPara acessar todo o zoológico de distribuições use essa ferramenta do Ben Lambert (estatístico do Imperial College of London): https://ben18785.shinyapps.io/distribution-zoo/\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.3 (2020-10-10)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n[1] gapminder_0.3.0 skimr_2.1.2     rstanarm_2.21.1 Rcpp_1.0.5     \n[5] readxl_1.3.1   \n\nloaded via a namespace (and not attached):\n  [1] nlme_3.1-151         matrixStats_0.57.0   xts_0.12.1          \n  [4] lubridate_1.7.9.2    threejs_0.3.3        rprojroot_2.0.2     \n  [7] rstan_2.21.2         repr_1.1.0           tools_4.0.3         \n [10] utf8_1.1.4           R6_2.5.0             DT_0.16             \n [13] colorspace_2.0-0     withr_2.3.0          tidyselect_1.1.0    \n [16] gridExtra_2.3        prettyunits_1.1.1    processx_3.4.5      \n [19] downlit_0.2.1        curl_4.3             compiler_4.0.3      \n [22] cli_2.2.0            shinyjs_2.0.0        colourpicker_1.1.0  \n [25] bookdown_0.21        scales_1.1.1         dygraphs_1.1.1.6    \n [28] ggridges_0.5.2       callr_3.5.1          stringr_1.4.0       \n [31] digest_0.6.27        StanHeaders_2.21.0-7 minqa_1.2.4         \n [34] rmarkdown_2.6        base64enc_0.1-3      pkgconfig_2.0.3     \n [37] htmltools_0.5.0      lme4_1.1-26          fastmap_1.0.1       \n [40] highr_0.8            htmlwidgets_1.5.3    rlang_0.4.10        \n [43] rstudioapi_0.13      shiny_1.5.0          generics_0.1.0      \n [46] zoo_1.8-8            jsonlite_1.7.2       crosstalk_1.1.0.1   \n [49] gtools_3.8.2         dplyr_1.0.2          distill_1.1         \n [52] inline_0.3.17        magrittr_2.0.1       loo_2.4.1           \n [55] bayesplot_1.7.2      Matrix_1.3-0         munsell_0.5.0       \n [58] fansi_0.4.1          lifecycle_0.2.0      stringi_1.5.3       \n [61] yaml_2.2.1           MASS_7.3-53          pkgbuild_1.2.0      \n [64] plyr_1.8.6           grid_4.0.3           parallel_4.0.3      \n [67] promises_1.1.1       crayon_1.3.4         miniUI_0.1.1.1      \n [70] lattice_0.20-41      splines_4.0.3        knitr_1.30          \n [73] ps_1.5.0             pillar_1.4.7         igraph_1.2.6        \n [76] boot_1.3-25          markdown_1.1         shinystan_2.5.0     \n [79] reshape2_1.4.4       codetools_0.2-18     stats4_4.0.3        \n [82] rstantools_2.1.1     glue_1.4.2           evaluate_0.14       \n [85] V8_3.4.0             RcppParallel_5.0.2   nloptr_1.2.2.2      \n [88] vctrs_0.3.6          httpuv_1.5.4         cellranger_1.1.0    \n [91] tidyr_1.1.2          gtable_0.3.0         purrr_0.3.4         \n [94] assertthat_0.2.1     ggplot2_3.3.3        xfun_0.19           \n [97] mime_0.9             xtable_1.8-4         later_1.1.0.1       \n[100] survival_3.2-7       rsconnect_0.8.16     tibble_3.0.4        \n[103] shinythemes_1.1.2    statmod_1.4.35       ellipsis_0.3.1      \n\n\n\n\n",
      "last_modified": "2021-01-03T04:51:21-03:00"
    },
    {
      "path": "4-Priors.html",
      "title": "As famosas e controversas Priors",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "August 2, 2020",
      "contents": "\n\nContents\nTipos de Priors\nPriors para os Modelos\nUniforme (Flat Prior)\nInformativas\nPadrões do rstanarm\nExemplo usando o mtcars\n\nPor quê não é interessante usar priors uniformes (flat priors)\nAtividade\n\nAmbiente\n\n\nA Estatística Bayesiana é caracterizada pelo uso de informação prévia embutida como probabilidade prévia \\(P(H)\\)\n\\[P(H | D)=\\frac{P(H) \\cdot P(D | H)}{P(D)}\\]\nTipos de Priors\nDe maneira geral, podemos ter 3 tipos de priors em uma abordagem Bayesiana:\nuniforme (Flat Prior): não recomendada\nfracamente informativa (weakly informative): pequena restrição com um pouco de senso comum e baixo conhecimento de domínio incorporado\ninformativa (informative): conhecimento de domínio incorporado\nPara se aprofundar mais recomendo a vignette do rstanarm sobre priors\nPriors para os Modelos\nArgumento\nUsado em\nAplica-se à\nprior_intercept\nTodas funções de modelagem exceto stan_polr and stan_nlmer\nConstante (intercept) do modelo, após centralização dos preditores\nprior\nTodas funções de modelagem\nCoeficientes de Regressão, não inclui coeficientes que variam por grupo em modelos multiníveis (veja prior_covariance)\nprior_aux\nstan_glm, stan_glmer, stan_gamm4, stan_nlmer\nParâmetro auxilizar (ex: desvio padrão (standard error - DP), interpretação depende do modelo\nprior_covariance\nstan_glmer, stan_gamm4, stan_nlmer\nMatrizes de covariância em modelos multiníveis\nUniforme (Flat Prior)\nEspecifica-se colocando o valor NULL (nulo em R) no. Exemplo:\nprior_intercept = NULL\nprior = NULL\nprior_aux = NULL\nColocando na função de modelo ficaria stan_glm(y ~ x1 + x2, data = df, prior = NULL, prior_intercept = NULL, prior_aux = NULL)\nInformativas\nColoca-se qualquer distribuição nos argumentos. Exemplo:\nprior = normal(0, 5)\nprior_intercept = student_t(4, 0, 10)\nprior_aux = cauchy(0, 3)\nColocando na função de modelo ficaria stan_glm(y ~ x1 + x2, data = df, prior = normal(0, 5), prior_intercept = student_t(4, 0, 10), prior_aux = cauchy(0, 3))\nPadrões do rstanarm\nAcontece se você não especifica nada nos argumentos de priors. O comportamento difere conforme o modelo. Aqui divido em modelos gaussianos (segue uma likelihood gaussiana ou normal) e outros (binomial, poisson etc)\nModelos Gaussianos\nConstante(Intercept): centralizada com média \\(\\mu_y\\) e desvio padrão de \\(2.5 \\sigma_y\\) - prior_intercept = normal(mean_y, 2.5 * sd_y)\nCoeficientes: para cada coeficiente média \\(\\mu = 0\\) e desvio padrão de \\(2.5\\times\\frac{\\sigma_y}{\\sigma_{x_k}}\\) - prior = normal(0, 2.5 * sd_y/sd_xk)\nOutros Modelos (Binomial, Poisson etc.)\nConstante(Intercept): centralizada com média \\(\\mu = 0\\) e desvio padrão de \\(2.5 \\sigma_y\\) - prior_intercept = normal(0, 2.5 * sd_y)\nCoeficientes: para cada coeficiente média \\(\\mu = 0\\) e desvio padrão de \\(2.5\\times\\frac{1}{\\sigma_{x_k}}\\) - prior = normal(0, 2.5 * 1/sd_xk)\n\nOBS: em todos os modelos prior_aux, o desvio padrão do erro do modelo, a prior padrão é uma distribuição exponencial com taxa \\(\\frac{1}{\\sigma_y}\\): prior_aux = exponential(1/sd_y)\n\nExemplo usando o mtcars\nVamos estimar modelos Bayesianos usando o dataset já conhecido mtcars. Para constar, calcularemos alguns valores antes de ver o sumário das priors:\n\\(\\mu_y\\): média do mpg - 20.09\n\\(2.5 \\sigma_y\\): 2.5 * sd(mtcars$mpg) - 15.07\n\\(2.5\\times\\frac{\\sigma_y}{\\sigma_{x_{\\text{wt}}}}\\): 2.5 * (sd(mtcars$mpg)/sd(mtcars$wt)) - 15.4\n\\(2.5\\times\\frac{\\sigma_y}{\\sigma_{x_{\\text{am}}}}\\): 2.5 * (sd(mtcars$mpg)/sd(mtcars$am)) - 30.2\n\\(\\frac{1}{\\sigma_y}\\): 1/sd(mtcars$mpg) - 0.17\nA função prior_summary resulta um sumário conciso das priors utilizadas em um modelo. Coloque como argumento o modelo estimado:\n\n\nlibrary(rstanarm)\ndefault_prior_test <- stan_glm(mpg ~ wt + am, data = mtcars, chains = 1)\n\n\n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 6.9e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.69 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.050094 seconds (Warm-up)\nChain 1:                0.06054 seconds (Sampling)\nChain 1:                0.110634 seconds (Total)\nChain 1: \n\nprior_summary(default_prior_test)\n\n\nPriors for model 'default_prior_test' \n------\nIntercept (after predictors centered)\n  Specified prior:\n    ~ normal(location = 20, scale = 2.5)\n  Adjusted prior:\n    ~ normal(location = 20, scale = 15)\n\nCoefficients\n  Specified prior:\n    ~ normal(location = [0,0], scale = [2.5,2.5])\n  Adjusted prior:\n    ~ normal(location = [0,0], scale = [15.40,30.20])\n\nAuxiliary (sigma)\n  Specified prior:\n    ~ exponential(rate = 1)\n  Adjusted prior:\n    ~ exponential(rate = 0.17)\n------\nSee help('prior_summary.stanreg') for more details\n\nAgora com priors especificadas:\nComo há dois coeficientes eu especifico médias iguais (\\(0\\)), porém desvios padrões diferentes (\\(5\\) para wt e \\(6\\) para am) usando a função de combinar do R (combine) - c()\n\n\ncustom_prior_test <- stan_glm(mpg ~ wt + am, data = mtcars, chains = 1,\n         prior = normal(c(0,0), c(5,6)),\n         prior_intercept = student_t(4, 0, 10),\n         prior_aux = cauchy(0, 3))\n\n\n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 2.1e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.21 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.056803 seconds (Warm-up)\nChain 1:                0.057048 seconds (Sampling)\nChain 1:                0.113851 seconds (Total)\nChain 1: \n\nprior_summary(custom_prior_test)\n\n\nPriors for model 'custom_prior_test' \n------\nIntercept (after predictors centered)\n ~ student_t(df = 4, location = 0, scale = 10)\n\nCoefficients\n ~ normal(location = [0,0], scale = [5,6])\n\nAuxiliary (sigma)\n ~ half-cauchy(location = 0, scale = 3)\n------\nSee help('prior_summary.stanreg') for more details\n\nPor quê não é interessante usar priors uniformes (flat priors)\nUma prior totalmente uniforme ou chapada (flat) é algo que devemos evitar pelo simples motivo que ela encompassa a premissa de que “tudo é possível”. Não há limites na crença de que tamanho o valor deve ser.\nPriors chapadas e super-vagas geralmente não são recomendadas e algum esforço deve ser incluído para ter, pelo menos, priors um pouco informativa. Por exemplo, é comum esperar que os tamanhos de efeito realistas sejam da ordem de magnitude \\(0.1\\) em uma escala padronizada (por exemplo, uma inovação educacional que pode melhorar as pontuações dos testes em \\(0.1\\) desvios padrão). Nesse caso, um prior de \\(N \\sim (0,1)\\) poderia ser considerado muito informativo, de uma maneira ruim, pois coloca a maior parte de sua massa em valores de parâmetro que são irrealisticamente grandes em valor absoluto. O ponto geral aqui é que se considerarmos uma prior como “fraca” ou “forte”, isso é uma propriedade não apenas da prior, mas também da pergunta que está sendo feita.\nQuando dizemos que a prior é “pouco informativa”, o que queremos dizer é que, se houver uma quantidade razoavelmente grande de dados, a likelihood dominará e a prior não será importante. Se os dados forem fracos, porém, esta “prior fracamente informativo” influenciará fortemente a inferência posterior.\nNão se esqueça que distribuição normal tem suporte \\(\\mathbb{R}\\), ou seja pode acontecer qualquer número entre \\(-\\infty\\) até \\(\\infty\\) independente da média \\(\\mu\\) ou desvio padrão \\(\\sigma\\).\nAtividade\nRegressão linear pensando nas priors. Usar o dataset do pacote carData chamado Salaries\n\n\nlibrary(carData)\ndata(\"Salaries\")\n?Salaries\n\n\n\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.3 (2020-10-10)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n[1] carData_3.0-4   gapminder_0.3.0 skimr_2.1.2     rstanarm_2.21.1\n[5] Rcpp_1.0.5      readxl_1.3.1   \n\nloaded via a namespace (and not attached):\n  [1] nlme_3.1-151         matrixStats_0.57.0   xts_0.12.1          \n  [4] lubridate_1.7.9.2    threejs_0.3.3        rprojroot_2.0.2     \n  [7] rstan_2.21.2         repr_1.1.0           tools_4.0.3         \n [10] utf8_1.1.4           R6_2.5.0             DT_0.16             \n [13] colorspace_2.0-0     withr_2.3.0          tidyselect_1.1.0    \n [16] gridExtra_2.3        prettyunits_1.1.1    processx_3.4.5      \n [19] downlit_0.2.1        curl_4.3             compiler_4.0.3      \n [22] cli_2.2.0            shinyjs_2.0.0        colourpicker_1.1.0  \n [25] bookdown_0.21        scales_1.1.1         dygraphs_1.1.1.6    \n [28] ggridges_0.5.2       callr_3.5.1          stringr_1.4.0       \n [31] digest_0.6.27        StanHeaders_2.21.0-7 minqa_1.2.4         \n [34] rmarkdown_2.6        base64enc_0.1-3      pkgconfig_2.0.3     \n [37] htmltools_0.5.0      lme4_1.1-26          fastmap_1.0.1       \n [40] highr_0.8            htmlwidgets_1.5.3    rlang_0.4.10        \n [43] rstudioapi_0.13      shiny_1.5.0          generics_0.1.0      \n [46] zoo_1.8-8            jsonlite_1.7.2       crosstalk_1.1.0.1   \n [49] gtools_3.8.2         dplyr_1.0.2          distill_1.1         \n [52] inline_0.3.17        magrittr_2.0.1       loo_2.4.1           \n [55] bayesplot_1.7.2      Matrix_1.3-0         munsell_0.5.0       \n [58] fansi_0.4.1          lifecycle_0.2.0      stringi_1.5.3       \n [61] yaml_2.2.1           MASS_7.3-53          pkgbuild_1.2.0      \n [64] plyr_1.8.6           grid_4.0.3           parallel_4.0.3      \n [67] promises_1.1.1       crayon_1.3.4         miniUI_0.1.1.1      \n [70] lattice_0.20-41      splines_4.0.3        knitr_1.30          \n [73] ps_1.5.0             pillar_1.4.7         igraph_1.2.6        \n [76] boot_1.3-25          markdown_1.1         shinystan_2.5.0     \n [79] reshape2_1.4.4       codetools_0.2-18     stats4_4.0.3        \n [82] rstantools_2.1.1     glue_1.4.2           evaluate_0.14       \n [85] V8_3.4.0             RcppParallel_5.0.2   nloptr_1.2.2.2      \n [88] vctrs_0.3.6          httpuv_1.5.4         cellranger_1.1.0    \n [91] tidyr_1.1.2          gtable_0.3.0         purrr_0.3.4         \n [94] assertthat_0.2.1     ggplot2_3.3.3        xfun_0.19           \n [97] mime_0.9             xtable_1.8-4         later_1.1.0.1       \n[100] survival_3.2-7       rsconnect_0.8.16     tibble_3.0.4        \n[103] shinythemes_1.1.2    statmod_1.4.35       ellipsis_0.3.1      \n\n\n\n\n",
      "last_modified": "2021-01-03T04:51:22-03:00"
    },
    {
      "path": "5-MCMC.html",
      "title": "Markov Chain Monte Carlo",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "August 2, 2020",
      "contents": "\n\nContents\nPara quê serve o denominador \\(P(\\text{data})\\)?\nSe removermos o denominador de Bayes o que temos?\nSimulação Montecarlo\nImplementação com o rstanarm\nMétricas da simulação MCMC\nO que fazer se não obtermos convergência?\n\nGráficos de Diagnósticos do MCMC\nTraceplot\nPosterior Predictive Check\n\nO quê fazer para que as métricas sejam convergentes\nAmbiente\n\n\nA principal barreira computacional para estatística bayesiana é o denominador \\(P(\\text{data})\\) da fórmula de Bayes:\n\\[P(\\theta | \\text{data})=\\frac{P(\\theta) \\cdot P(\\text{data} | \\theta)}{P(\\text{data})}\\]\nEm casos discretos podemos fazer o denominador virar a soma de todos os paramêtros usando a regra da cadeia de probabilidade:\n\\[P(A,B|C)=P(A|B,C) \\times P(B|C)\\]\nIsto também é chamado de marginalização:\n\\[P(\\text{data})=\\sum_{\\theta} P(\\text{data} | \\theta) \\times P(\\theta)\\]\nPorém no caso de valores contínuos o denominador \\(P(\\text{data})\\) vira uma integral bem grande e complicada de calcular:\n\\[P(\\text{data})=\\int_{\\theta} P(\\text{data} | \\theta) \\times P(\\theta)d \\theta\\]\nEm muitos casos essa integral vira intrátavel (incalculável) e portanto devemos achar outras maneiras de cálcular a probabilidade posterior \\(P(\\theta | \\text{data})\\) de Bayes sem usar o denominador \\(P(\\text{data})\\).\nPara quê serve o denominador \\(P(\\text{data})\\)?\nPara normalizar a posterior com o intuito de torná-la uma distribuição probabilística válida. Isto quer dizer que a soma de todas as probabilidades dos eventos possíveis da distribuição probabilística devem ser iguais a 1:\nno caso de distribuição probabilística discreta: \\(\\sum_{\\theta} P(\\theta | \\text{data}) = 1\\)\nno caso de distribuição probabilística contínua: \\(\\int_{\\theta} P(\\theta | \\text{data})d \\theta = 1\\)\nSe removermos o denominador de Bayes o que temos?\nAo removermos o denominador \\((\\text{data})\\) temos que a posterior \\(P(\\theta | \\text{data})\\) é proporcional à prior vezes a verossimilhança \\(P(\\theta) \\cdot P(\\text{data} | \\theta)\\)\n\\[P(\\theta | \\text{data}) \\propto P(\\theta) \\cdot P(\\text{data} | \\theta)\\]\nEste vídeo do YouTube explica muito bem o problema do denominador.\nSimulação Montecarlo\nAí que entra simulação Montecarlo. Simulação Montecarlo é usada quando não é possível coletar amostras de \\(\\theta\\) direto da distribuição probabilística posterior \\(P(\\theta | \\text{data})\\). Ao invés disso, nos coletamos amostras de maneira iterativa que a cada passo do processo nós esperamos que a distribuição da qual amostramos se torna cada vez mais similar à posterior \\(P(\\theta | \\text{data})\\).\n\nNão vamos cobrir a parte computacional ou a base matemática por trás de Markov Chain Monte Carlo (MCMC). Quem quiser, pode ler os capítulos 11 e 12 do livro Bayesian Data Analysis (3rd edition) de Gelman et al. (2014)\n\nImplementação com o rstanarm\nComo configuração padrão, o pacote rstanarm utiliza uma modalidade de MCMC que usa dinâmicas Hamiltoneanas chamada Hamiltonian Monte Carlo (HMC). HMC é a modalidade de MCMC mais eficiente para gerar inferências Bayesianas. Em especial, rstanarm e a linguagem Stan usam HMC com uma técnica chamada No-U-Turn Sampling (NUTS), que faz HMC ser bem eficiente e não desperdiça amostragens.\nAlém disso, os argumentos padrões do HMC no rstanarm são o 4 correntes Markov de amostragem (chains = 4) e o 2.000 iterações de cada corrente (iter = 2000). Sendo que, por padrão, HMC descarta a primeira metade (1.000) das iterações como aquecimento (warmup = floor(iter/2)).\nRelembrando o exemplo da aula de regressão linear, vamos usar o mesmo dataset kidiq. São dados de uma survey de mulheres adultas norte-americanas e seus respectivos filhos. Datado de 2007 possui 434 observações e 4 variáveis:\nkid_score: QI da criança;\nmom_hs: binária (0 ou 1) se a mãe possui diploma de ensino médio;\nmom_iq: QI da mãe; e\nmom_age: idade da mãe.\nVamos estimar um modelo de regressão linear Bayesiano na qual a variável dependente é kid_score e as independentes são mom_hs e mom_iq.\n\n\noptions(mc.cores = parallel::detectCores())\noptions(Ncpus = parallel::detectCores())\n\nlibrary(rstanarm)\nmodel <- stan_glm(\n  kid_score ~ mom_hs + mom_iq,\n  data = kidiq\n  )\n\n\n\nMétricas da simulação MCMC\nUm modelo estimado pelo rstanarm pode ser inspecionado em relação ao desempenho da amostragem MCMC. Ao chamarmos a função summary() no modelo estimado há uma parte chamada MCMC diagnostics.\n\n\nsummary(model)\n\n\n\nModel Info:\n function:     stan_glm\n family:       gaussian [identity]\n formula:      kid_score ~ mom_hs + mom_iq\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 434\n predictors:   3\n\nEstimates:\n              mean   sd   10%   50%   90%\n(Intercept) 25.8    5.9 18.4  25.8  33.3 \nmom_hs       6.0    2.2  3.1   5.9   8.7 \nmom_iq       0.6    0.1  0.5   0.6   0.6 \nsigma       18.2    0.6 17.4  18.2  19.0 \n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 86.8    1.2 85.2  86.8  88.4 \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n              mcse Rhat n_eff\n(Intercept)   0.1  1.0  4673 \nmom_hs        0.0  1.0  4157 \nmom_iq        0.0  1.0  4240 \nsigma         0.0  1.0  4253 \nmean_PPD      0.0  1.0  3979 \nlog-posterior 0.0  1.0  1959 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nA seção MCMC diagnostics possui três colunas de valores para cada parâmetro estimado do modelo.\nNo nosso caso, temos três parâmetros importantes:\nvalor do coeficiente da variável mom_hs\nvalor do coeficiente da variável mom_iq\nvalor do erro residual do modelo linear sigma\nAs três métricas são:\nmcse: Monte Carlo Standard Error, o erro de mensuração da amostragem Monte Carlo do parâmetro\nn_eff: uma aproximação crua do número de amostras efetivas amostradas pelo MCMC\nRhat: uma métrica de convergência e estabilidade da corrente Markov\nA métrica mais importante para levarmos em consideração é a Rhat que é uma métrica que mensura se as correntes Markov são estáveis e convergiram para um valor durante o progresso total das simulações. Ela é basicamente a proporção de variação ao compararmos duas metades das correntes. Valor de \\(1\\) implica em convergência e estabilidade. Como padrão o Rhat deve ser menor que \\(1.05\\) para que a estimação Bayesiana seja válida.\nO que fazer se não obtermos convergência?\nDependendo do modelo e dos dados é possível que HMC (mesmo com NUTS) não atinja convergência. Nesse caso, ao rodar o modelo rstanarm dará diversos avisos de divergências.\n\n\nbad_model <- stan_glm(\n  kid_score ~ mom_hs + mom_iq,\n  data = kidiq,\n  chains = 2,\n  iter = 200\n  )\n\n\n\nE vemos que o Rhat dos parâmetros estimados do modelo estão bem acima do limiar de \\(1.05\\).\n\n\nsummary(bad_model)\n\n\n\nModel Info:\n function:     stan_glm\n family:       gaussian [identity]\n formula:      kid_score ~ mom_hs + mom_iq\n algorithm:    sampling\n sample:       200 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 434\n predictors:   3\n\nEstimates:\n              mean   sd   10%   50%   90%\n(Intercept) 27.3    6.3 20.2  27.3  35.2 \nmom_hs       5.8    2.4  2.9   5.5   8.8 \nmom_iq       0.6    0.1  0.5   0.6   0.6 \nsigma       18.5    0.8 17.5  18.4  19.6 \n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 87.9    3.1 85.2  87.1  93.3 \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n              mcse Rhat n_eff\n(Intercept)   1.0  1.1   41  \nmom_hs        0.2  1.0  165  \nmom_iq        0.0  1.0  194  \nsigma         0.3  1.2   10  \nmean_PPD      1.6  1.6    4  \nlog-posterior 5.6  1.6    5  \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nGráficos de Diagnósticos do MCMC\nO pacote rstanarm tem diversos gráficos interessantes de diagnósticos de convergência das simulações MCMC.\nTraceplot\nO traceplot é a sobreposição das amostragens MCMC das correntes para cada parâmetro estimado. A ideia é que as correntes se misturam e que não haja nenhuma inclinação ao longo das iterações.\nDetalhe: aqui o traceplot usa somente as iterações válidas, após a remoção das iterações de warmup.\n\n\nplot(model, \"trace\")\n\n\n\nplot(bad_model, \"trace\")\n\n\n\n\nPosterior Predictive Check\nUm bom gráfico de diagnóstico é o posterior predictive check que compara o histograma da variável dependente \\(y\\) contra o histograma variáveis dependentes simuladas pelo modelo \\(y_{\\text{rep}}\\). A ideia é que os histogramas reais e simulados se misturem e não haja divergências.\n\n\npp_check(model)\n\n\n\npp_check(bad_model)\n\n\n\n\nO quê fazer para que as métricas sejam convergentes\nSe o seu modelo Bayesiano está com problemas de convergência há alguns passos que podem ser tentados. Aqui listados do mais simples para o mais complexo:\nAumentar o número de iterações e correntes: primeira opção é aumentar o número de iterações do MCMC com o argumento iter = XXX e também é possível aumentar o número de correntes com o argumento chains = X. Lembrando que o padrão é iter = 2000 e chains = 4.\nAlterar a rotina de adaptação do HMC: a segunda opção é fazer com que o algoritmo de amostragem HMC fique mais conservador (com proposições de pulos menores). Isto pode ser alterado com o argumento adapt_delta da lista de opções control. control=list(adapt_delta=0.9). O padrão do adapt_delta é control=list(adapt_delta=0.8). Então quaquer valor entre \\(0.8\\) e \\(1.0\\) o torna mais conservador.\nReparametrização do Modelo: a terceira opção é reparametrizar o modelo. Há duas maneiras de parametrizar o modelo: a primeira com parametrização centrada (centered parameterization) e a segunda com parametrização não-centrada (non-centered parameterization). Não são assuntos que vamos cobrir aqui no curso. Recomendo o material de um dos desenvolvedores da linguagem Stan, Michael Betancourt.\nColetar mais dados: às vezes o modelo é complexo demais e precisamos de uma amostragem maior para conseguirmos estimativas estáveis.\nRepensar o modelo: falha de convergência quando temos uma amostragem adequada geralmente é por conta de uma especificação de priors e verossimilhança que não são compatíveis com os dados. Nesse caso, é preciso repensar o processo generativo de dados no qual os pressupostos do modelo estão ancorados.\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.3 (2020-10-10)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n[1] carData_3.0-4   gapminder_0.3.0 skimr_2.1.2     rstanarm_2.21.1\n[5] Rcpp_1.0.5      readxl_1.3.1   \n\nloaded via a namespace (and not attached):\n  [1] nlme_3.1-151         matrixStats_0.57.0   xts_0.12.1          \n  [4] lubridate_1.7.9.2    threejs_0.3.3        rprojroot_2.0.2     \n  [7] rstan_2.21.2         repr_1.1.0           tools_4.0.3         \n [10] utf8_1.1.4           R6_2.5.0             DT_0.16             \n [13] colorspace_2.0-0     withr_2.3.0          tidyselect_1.1.0    \n [16] gridExtra_2.3        prettyunits_1.1.1    processx_3.4.5      \n [19] downlit_0.2.1        curl_4.3             compiler_4.0.3      \n [22] cli_2.2.0            shinyjs_2.0.0        labeling_0.4.2      \n [25] colourpicker_1.1.0   bookdown_0.21        scales_1.1.1        \n [28] dygraphs_1.1.1.6     ggridges_0.5.2       callr_3.5.1         \n [31] stringr_1.4.0        digest_0.6.27        StanHeaders_2.21.0-7\n [34] minqa_1.2.4          rmarkdown_2.6        base64enc_0.1-3     \n [37] pkgconfig_2.0.3      htmltools_0.5.0      lme4_1.1-26         \n [40] fastmap_1.0.1        highr_0.8            htmlwidgets_1.5.3   \n [43] rlang_0.4.10         rstudioapi_0.13      shiny_1.5.0         \n [46] farver_2.0.3         generics_0.1.0       zoo_1.8-8           \n [49] jsonlite_1.7.2       crosstalk_1.1.0.1    gtools_3.8.2        \n [52] dplyr_1.0.2          distill_1.1          inline_0.3.17       \n [55] magrittr_2.0.1       loo_2.4.1            bayesplot_1.7.2     \n [58] Matrix_1.3-0         munsell_0.5.0        fansi_0.4.1         \n [61] lifecycle_0.2.0      stringi_1.5.3        yaml_2.2.1          \n [64] MASS_7.3-53          pkgbuild_1.2.0       plyr_1.8.6          \n [67] grid_4.0.3           parallel_4.0.3       promises_1.1.1      \n [70] crayon_1.3.4         miniUI_0.1.1.1       lattice_0.20-41     \n [73] splines_4.0.3        knitr_1.30           ps_1.5.0            \n [76] pillar_1.4.7         igraph_1.2.6         boot_1.3-25         \n [79] markdown_1.1         shinystan_2.5.0      reshape2_1.4.4      \n [82] codetools_0.2-18     stats4_4.0.3         rstantools_2.1.1    \n [85] glue_1.4.2           evaluate_0.14        V8_3.4.0            \n [88] RcppParallel_5.0.2   nloptr_1.2.2.2       vctrs_0.3.6         \n [91] httpuv_1.5.4         cellranger_1.1.0     tidyr_1.1.2         \n [94] gtable_0.3.0         purrr_0.3.4          assertthat_0.2.1    \n [97] ggplot2_3.3.3        xfun_0.19            mime_0.9            \n[100] xtable_1.8-4         later_1.1.0.1        survival_3.2-7      \n[103] rsconnect_0.8.16     tibble_3.0.4         shinythemes_1.1.2   \n[106] statmod_1.4.35       ellipsis_0.3.1      \n\n\n\n\n",
      "last_modified": "2021-01-03T04:51:28-03:00"
    },
    {
      "path": "6-Regressao_Binomial.html",
      "title": "Modelos Lineares Generalizados - Binomial",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "August 2, 2020",
      "contents": "\n\nContents\nComparativo com a Regressão Linear\nExemplo\n\nRegressão logística com o rstanarm\nInterpretação dos coeficientes\nPriors\nAtividade Prática\nAmbiente\n\n\nSaindo do universo dos modelos lineares, começamos a nos aventurar nos modelos linares generalizados (generalized linear models - GLM). O primeiro deles é a regressão logística (também chamada de regressão binomial).\nUma regressão logística se comporta exatamente como um modelo linear: faz uma predição simplesmente computando uma soma ponderada das variáveis independentes, mais uma constante. Porém ao invés de retornar um valor contínuo, como a regressão linear, retorna a função logística desse valor.\n\\[\\operatorname{Logística}(x) = \\frac{1}{1 + e^{(-x)}}\\]\nUsamos regressão logística quando a nossa variável dependente é binária. Ela possui apenas dois valores distintos, geralmente codificados como \\(0\\) ou \\(1\\).\n\n\nx <- seq(-10, 10, length.out = 100)\nsig <- 1 / (1 + exp(-x))\nplot(x, sig, type = \"l\", lwd=2, ylab = \"Logística(x)\")\n\n\n\n\nComparativo com a Regressão Linear\n\\[ \\operatorname{Linear} = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\dots + \\theta_n x_n\\]\n\\(\\operatorname{Linear}\\) - regressão linear\n\\(\\theta\\) - parâmetro do modelo\n\\(n\\) - número de atributos (features)\n\\(x_i\\) - o valor do inésimo atributo (feature)\n\\(\\hat{p} = \\sigma(\\operatorname{Linear}) = \\frac{1}{1 + e^{-\\operatorname{Linear}}}\\)\n\\(\\hat{p}\\) - probabilidade prevista da observação ser 1\n\\(\\hat{y}=\\left\\{\\begin{array}{ll} 0 & \\text { se } \\hat{p} < 0.5 \\\\ 1 & \\text { se } \\hat{p} \\geq 0.5 \\end{array}\\right.\\)\nExemplo\n\\[\\mathrm{Previsão~de~Morte} = \\sigma \\big(-10 + 10\\times \\mathrm{cancer} + 12 \\times \\mathrm{diabetes} + 8 \\times \\mathrm{obesidade} \\big)\\]\nRegressão logística com o rstanarm\nO rstanarm pode tolerar qualquer modelo linear generalizado e regressão logística não é uma exceção. Para rodar um modelo binomial no rstanarm é preciso simplesmente alterar o argumento family da função stan_glm.\nPara exemplo, usaremos um dataset chamado wells do pacote rstanarm. É uma survey com 3200 residentes de uma pequena área de Bangladesh na qual os lençóis freáticos estão contaminados por arsênico. Respondentes com altos níveis de arsênico nos seus poços foram encorajados para trocar a sua fonte de água para uma níveis seguros de arsênico.\nPossui as seguintes variáveis:\nswitch: dependente indicando se o respondente trocou ou não de poço\narsenic: nível de arsênico do poço do respondente\ndist: distância em metros da casa do respondente até o poço seguro mais próximo\nassociation: dummy se os membros da casa do respondente fazem parte de alguma organização da comunidade\neduc: quantidade de anos de educação que o chefe da família respondente possui\n\n\noptions(mc.cores = parallel::detectCores())\noptions(Ncpus = parallel::detectCores())\n\nlibrary(rstanarm)\ndata(wells)\n\nmodel_binomial <- stan_glm(\n  switch ~ dist + arsenic + assoc + educ,\n  data = wells,\n  family = binomial()\n    )\n\n\n\n\n\nsummary(model_binomial)\n\n\n\nModel Info:\n function:     stan_glm\n family:       binomial [logit]\n formula:      switch ~ dist + arsenic + assoc + educ\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 3020\n predictors:   5\n\nEstimates:\n              mean   sd   10%   50%   90%\n(Intercept) -0.2    0.1 -0.3  -0.2   0.0 \ndist         0.0    0.0  0.0   0.0   0.0 \narsenic      0.5    0.0  0.4   0.5   0.5 \nassoc       -0.1    0.1 -0.2  -0.1   0.0 \neduc         0.0    0.0  0.0   0.0   0.1 \n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 0.6    0.0  0.6   0.6   0.6  \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n              mcse Rhat n_eff\n(Intercept)   0.0  1.0  5768 \ndist          0.0  1.0  4898 \narsenic       0.0  1.0  4988 \nassoc         0.0  1.0  6084 \neduc          0.0  1.0  5764 \nmean_PPD      0.0  1.0  4638 \nlog-posterior 0.0  1.0  1764 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nInterpretação dos coeficientes\nAo vermos a fórmula de regressão binomial vemos que para analisarmos o efeito de um preditor na variável dependente temos que calcular o valor logístico dos coeficientes do preditor. E interpretamos como chances (odds ratio) na qual 1 é neutro e qualquer valor abaixo de 1 tende a respostas codificadas como 0 e qualquer valor acima de 1 tende a respostas codificadas como 1.\n\\[\\text{odds ratio} = e^{(x)}\\]\n\n\ncoeff <- exp(model_binomial$coefficients)\ncoeff\n\n\n(Intercept)        dist     arsenic       assoc        educ \n       0.85        0.99        1.60        0.88        1.04 \n\n(Intercept): a chance basal de respondentes mudarem de poço (15% de não mudarem)\ndist: a cada metro de distância diminui a chance de troca de poço em 1%\narsenic: a cada incremento do nível de arsênico aumenta a chance de troca de poço em 60%\nassoc: residências com membros que fazem parte de alguma organização da comunidade diminui a chance de troca de poço em 12%\neduc: a cada incremento dos anos de estudo aumenta a chance de troca de poço em 4%\nPriors\nrstanarm possui as seguintes configurações como padrão de priors para regressão binomial:\nConstante (Intercept): centralizada com média \\(\\mu = 0\\) e desvio padrão de \\(2.5 \\sigma_y\\) - prior_intercept = normal(0, 2.5 * sd_y)\nCoeficientes: para cada coeficiente média \\(\\mu = 0\\) and standard deviation of \\(2.5\\times\\frac{1}{\\sigma_{x_k}}\\) - prior = normal(0, 2.5 * 1/sd_xk)\nErro residual (prior_aux): uma distribuição exponencial com taxa \\(\\frac{1}{\\sigma_y}\\): prior_aux = exponential(1/sd_y)\nAtividade Prática\nDois datasets estão disponíveis na pasta datasets/:\nTitanic Survival: datasets/Titanic_Survival.csv\nIBM HR Analytics Employee Attrition & Performance: datasets/IBM_HR_Attrition.csv\n\n\n###\n\n\n\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.3 (2020-10-10)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n[1] carData_3.0-4   gapminder_0.3.0 skimr_2.1.2     rstanarm_2.21.1\n[5] Rcpp_1.0.5      readxl_1.3.1   \n\nloaded via a namespace (and not attached):\n  [1] nlme_3.1-151         matrixStats_0.57.0   xts_0.12.1          \n  [4] lubridate_1.7.9.2    threejs_0.3.3        rprojroot_2.0.2     \n  [7] rstan_2.21.2         repr_1.1.0           tools_4.0.3         \n [10] utf8_1.1.4           R6_2.5.0             DT_0.16             \n [13] colorspace_2.0-0     withr_2.3.0          tidyselect_1.1.0    \n [16] gridExtra_2.3        prettyunits_1.1.1    processx_3.4.5      \n [19] downlit_0.2.1        curl_4.3             compiler_4.0.3      \n [22] cli_2.2.0            shinyjs_2.0.0        labeling_0.4.2      \n [25] colourpicker_1.1.0   bookdown_0.21        scales_1.1.1        \n [28] dygraphs_1.1.1.6     ggridges_0.5.2       callr_3.5.1         \n [31] stringr_1.4.0        digest_0.6.27        StanHeaders_2.21.0-7\n [34] minqa_1.2.4          rmarkdown_2.6        base64enc_0.1-3     \n [37] pkgconfig_2.0.3      htmltools_0.5.0      lme4_1.1-26         \n [40] fastmap_1.0.1        highr_0.8            htmlwidgets_1.5.3   \n [43] rlang_0.4.10         rstudioapi_0.13      shiny_1.5.0         \n [46] farver_2.0.3         generics_0.1.0       zoo_1.8-8           \n [49] jsonlite_1.7.2       crosstalk_1.1.0.1    gtools_3.8.2        \n [52] dplyr_1.0.2          distill_1.1          inline_0.3.17       \n [55] magrittr_2.0.1       loo_2.4.1            bayesplot_1.7.2     \n [58] Matrix_1.3-0         munsell_0.5.0        fansi_0.4.1         \n [61] lifecycle_0.2.0      stringi_1.5.3        yaml_2.2.1          \n [64] MASS_7.3-53          pkgbuild_1.2.0       plyr_1.8.6          \n [67] grid_4.0.3           parallel_4.0.3       promises_1.1.1      \n [70] crayon_1.3.4         miniUI_0.1.1.1       lattice_0.20-41     \n [73] splines_4.0.3        knitr_1.30           ps_1.5.0            \n [76] pillar_1.4.7         igraph_1.2.6         boot_1.3-25         \n [79] markdown_1.1         shinystan_2.5.0      reshape2_1.4.4      \n [82] codetools_0.2-18     stats4_4.0.3         rstantools_2.1.1    \n [85] glue_1.4.2           evaluate_0.14        V8_3.4.0            \n [88] RcppParallel_5.0.2   nloptr_1.2.2.2       vctrs_0.3.6         \n [91] httpuv_1.5.4         cellranger_1.1.0     tidyr_1.1.2         \n [94] gtable_0.3.0         purrr_0.3.4          assertthat_0.2.1    \n [97] ggplot2_3.3.3        xfun_0.19            mime_0.9            \n[100] xtable_1.8-4         later_1.1.0.1        survival_3.2-7      \n[103] rsconnect_0.8.16     tibble_3.0.4         shinythemes_1.1.2   \n[106] statmod_1.4.35       ellipsis_0.3.1      \n\n\n\n\n",
      "last_modified": "2021-01-03T04:51:32-03:00"
    },
    {
      "path": "7-Regressao_Poisson.html",
      "title": "Modelos Lineares Generalizados - Poisson",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "August 2, 2020",
      "contents": "\n\nContents\nRegressão de Poisson com o rstanarm\nInterpretação dos coeficientes\nPriors\nAtividade Prática\nAmbiente\n\n\nSaindo do universo dos modelos lineares, começamos a nos aventurar nos modelos linares generalizados (generalized linear models - GLM). O segundo deles é a regressão de Poisson.\nUma regressão de Poisson se comporta exatamente como um modelo linear: faz uma predição simplesmente computando uma soma ponderada das variáveis independentes, mais uma constante. Porém ao invés de retornar um valor contínuo, como a regressão linear, retorna o logarítmo natural desse valor.\n\\[\\log(y)= \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\dots + \\theta_n x_n\\] que é o mesmo que\n\\[y = e^{(\\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\dots + \\theta_n x_n)}\\] Regressão de Poisson é usada quando a nossa variável dependente só pode tomar valores positivos e discretos (número inteiros), geralmente em contextos de dados de contagem.\n\n\nx <- seq(-5, 5, length.out = 100)\nplot(x, exp(x), type = \"l\", lwd=2, ylab = \"Exponencial(x)\")\n\n\n\n\nRegressão de Poisson com o rstanarm\nO rstanarm pode tolerar qualquer modelo linear generalizado e regressão de Poisson não é uma exceção. Para rodar um modelo de Poisson no rstanarm é preciso simplesmente alterar o argumento family da função stan_glm.\nPara exemplo, usaremos um dataset chamado roaches do pacote rstanarm. É uma base de dados com 262 observações sobre a eficácia de um sistema de controle de pragas em reduzir o número de baratas (roaches) em apartamentos urbanos.\nPossui as seguintes variáveis:\ny: variável dependente - número de baratas mortas\nroach1: número de baratas antes da dedetização\ntreatment: dummy para indicar se o apartamento foi dedetizado ou não\nsenior: dummy para indicar se há apenas idosos no apartamento\nexposure2: número de dias que as armadilhas de baratas foram usadas\n\n\noptions(mc.cores = parallel::detectCores())\noptions(Ncpus = parallel::detectCores())\n\nlibrary(rstanarm)\ndata(roaches)\n\nmodel_poisson <- stan_glm(\n  y ~ roach1 + treatment + senior,\n  data = roaches,\n  family = poisson()\n    )\n\n\n\n\n\nsummary(model_poisson)\n\n\n\nModel Info:\n function:     stan_glm\n family:       poisson [log]\n formula:      y ~ roach1 + treatment + senior\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 262\n predictors:   4\n\nEstimates:\n              mean   sd   10%   50%   90%\n(Intercept)  3.1    0.0  3.1   3.1   3.2 \nroach1       0.0    0.0  0.0   0.0   0.0 \ntreatment   -0.5    0.0 -0.5  -0.5  -0.5 \nsenior      -0.4    0.0 -0.4  -0.4  -0.3 \n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 25.7    0.4 25.1  25.7  26.2 \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n              mcse Rhat n_eff\n(Intercept)   0.0  1.0  3635 \nroach1        0.0  1.0  3585 \ntreatment     0.0  1.0  3433 \nsenior        0.0  1.0  3300 \nmean_PPD      0.0  1.0  3554 \nlog-posterior 0.0  1.0  1697 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nInterpretação dos coeficientes\nAo vermos a fórmula de regressão de Poisson vemos que para analisarmos o efeito de um preditor na variável dependente temos que calcular o valor \\(e\\) elevado ao coeficiente do preditor\n\\[y = e^{(\\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\dots + \\theta_n x_n)}\\]\n\n\ncoeff <- exp(model_poisson$coefficients)\ncoeff\n\n\n(Intercept)      roach1   treatment      senior \n      23.01        1.01        0.60        0.69 \n\n(Intercept): a taxa basal de exterminação das baratas \\(y\\)\nroach1: a cada uma barata antes da exterminação há um aumento de 1.01 barata exterminada a mais\ntreatment: se o apartamento foi dedetizado há um aumento de 0.6 barata exterminada a mais\nsenior: se o apartamento possui somente idoso há um aumento de 0.69 barata exterminada a mais\nPriors\nrstanarm possui as seguintes configurações como padrão de priors para regressão de Poisson:\nConstante (Intercept): centralizada com média \\(\\mu = 0\\) e desvio padrão de \\(2.5 \\sigma_y\\) - prior_intercept = normal(0, 2.5 * sd_y)\nCoeficientes: para cada coeficiente média \\(\\mu = 0\\) and standard deviation of \\(2.5\\times\\frac{1}{\\sigma_{x_k}}\\) - prior = normal(0, 2.5 * 1/sd_xk)\nErro residual (prior_aux): uma distribuição exponencial com taxa \\(\\frac{1}{\\sigma_y}\\): prior_aux = exponential(1/sd_y)\nAtividade Prática\nUm datasets está disponível na pasta datasets/:\nNew York City - East River Bicycle Crossings: datasets/NYC_bicycle.csv\n\n\n###\n\n\n\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.3 (2020-10-10)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n[1] carData_3.0-4   gapminder_0.3.0 skimr_2.1.2     rstanarm_2.21.1\n[5] Rcpp_1.0.5      readxl_1.3.1   \n\nloaded via a namespace (and not attached):\n  [1] nlme_3.1-151         matrixStats_0.57.0   xts_0.12.1          \n  [4] lubridate_1.7.9.2    threejs_0.3.3        rprojroot_2.0.2     \n  [7] rstan_2.21.2         repr_1.1.0           tools_4.0.3         \n [10] utf8_1.1.4           R6_2.5.0             DT_0.16             \n [13] colorspace_2.0-0     withr_2.3.0          tidyselect_1.1.0    \n [16] gridExtra_2.3        prettyunits_1.1.1    processx_3.4.5      \n [19] downlit_0.2.1        curl_4.3             compiler_4.0.3      \n [22] cli_2.2.0            shinyjs_2.0.0        labeling_0.4.2      \n [25] colourpicker_1.1.0   bookdown_0.21        scales_1.1.1        \n [28] dygraphs_1.1.1.6     ggridges_0.5.2       callr_3.5.1         \n [31] stringr_1.4.0        digest_0.6.27        StanHeaders_2.21.0-7\n [34] minqa_1.2.4          rmarkdown_2.6        base64enc_0.1-3     \n [37] pkgconfig_2.0.3      htmltools_0.5.0      lme4_1.1-26         \n [40] fastmap_1.0.1        highr_0.8            htmlwidgets_1.5.3   \n [43] rlang_0.4.10         rstudioapi_0.13      shiny_1.5.0         \n [46] farver_2.0.3         generics_0.1.0       zoo_1.8-8           \n [49] jsonlite_1.7.2       crosstalk_1.1.0.1    gtools_3.8.2        \n [52] dplyr_1.0.2          distill_1.1          inline_0.3.17       \n [55] magrittr_2.0.1       loo_2.4.1            bayesplot_1.7.2     \n [58] Matrix_1.3-0         munsell_0.5.0        fansi_0.4.1         \n [61] lifecycle_0.2.0      stringi_1.5.3        yaml_2.2.1          \n [64] MASS_7.3-53          pkgbuild_1.2.0       plyr_1.8.6          \n [67] grid_4.0.3           parallel_4.0.3       promises_1.1.1      \n [70] crayon_1.3.4         miniUI_0.1.1.1       lattice_0.20-41     \n [73] splines_4.0.3        knitr_1.30           ps_1.5.0            \n [76] pillar_1.4.7         igraph_1.2.6         boot_1.3-25         \n [79] markdown_1.1         shinystan_2.5.0      reshape2_1.4.4      \n [82] codetools_0.2-18     stats4_4.0.3         rstantools_2.1.1    \n [85] glue_1.4.2           evaluate_0.14        V8_3.4.0            \n [88] RcppParallel_5.0.2   nloptr_1.2.2.2       vctrs_0.3.6         \n [91] httpuv_1.5.4         cellranger_1.1.0     tidyr_1.1.2         \n [94] gtable_0.3.0         purrr_0.3.4          assertthat_0.2.1    \n [97] ggplot2_3.3.3        xfun_0.19            mime_0.9            \n[100] xtable_1.8-4         later_1.1.0.1        survival_3.2-7      \n[103] rsconnect_0.8.16     tibble_3.0.4         shinythemes_1.1.2   \n[106] statmod_1.4.35       ellipsis_0.3.1      \n\n\n\n\n",
      "last_modified": "2021-01-03T04:51:35-03:00"
    },
    {
      "path": "8-Regressao_Robusta.html",
      "title": "Modelos Lineares Generalizados - Regressão Robusta",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "August 2, 2020",
      "contents": "\n\nContents\nComparativo Normal vs Student\nModelos Lineares Robustos com o pacote brms\nExemplo com os dados de Prestígio de Duncan (1961)\nPriors do brms\n\nAtividade Prática\nAmbiente\n\n\nLembrando da curva normal gaussiana que possui um formato de sino. Ela não é muito alongada nas “pontas”. Ou seja, as observações não fogem muito da média. Quando usamos essa distribuição como verossimilhança na inferência modelos Bayesianos, forçamos a que todas as estimativas sejam condicionadas à uma distribuição normal da variável dependente. Se nos dados houverem muitas observações com valores discrepantes (bem diferentes da média - outliers), isso faz com que as estimativas dos coeficientes das variáveis independentes fiquem instáveis. Isso ocorre porquê a distribuição normal não consegue contemplar observações muito divergentes da média sem mudar a média de local.\n\n\nx <- seq(-4, 4, length = 100)\nplot(x, dnorm(x),\n     type = \"l\",\n     col = \"red\",\n     lwd = 3,\n     xlab=\"valor de x\",\n     ylab=\"Densidade\",\n     main=\"Distribuição Normal\",\n     sub = \"Média 0 e Desvio Padrão 1\",\n     xlim = c(-4, 4),\n     ylim = c(0, 0.4))\n\n\n\n\nEntão precisamos de uma distribuição mais “maleável” como verossimilhança. Precisamos de uma distribuição que seja mais robusta à observações discrepantes (outliers). Precisamos de uma distribuição similar à Normal mas que possua caudas mais longas para justamente contemplar observações muito longe da média sem ter que mudar a média de local. Para isso temos a distribuição t de Student. Lembrando o formato dela:\n\n\nx <- seq(-4, 4, length = 100)\nplot(x, dt(x, 2),\n     type = \"l\",\n     col = \"blue\",\n     lwd = 3,\n     xlab=\"valor de x\",\n     ylab=\"Densidade\",\n     main=\"Distribuição t de Student\",\n     sub = \"Média 0 e Graus de Liberdade 2\",\n     xlim = c(-4, 4),\n     ylim = c(0, 0.4))\n\n\n\n\nComparativo Normal vs Student\nReparem nas caudas:\n\n\nplot(NA, xlab=\"valor de x\",\n  ylab = \"Densidade\",\n  main = \"Comparativo de Distribuições\",\n  sub = \"Normal vs t de Student\",\n  xlim = c(-4, 4),\n  ylim = c(0, 0.4))\nlines(x, dnorm(x), lwd = 2, col = \"red\")\nlines(x, dt(x, df = 2), lwd = 2, col = \"blue\")\nlegend(\"topright\", legend=c(\"Normal\", \"Student\"),\n       col=c(\"red\", \"blue\"), title=\"Distribuições\", lty=1)\n\n\n\n\nModelos Lineares Robustos com o pacote brms\nO rstanarm não possui a possibilidade de usar distribuições t de Student como verossimilhança do modelo Bayesiano. Para usarmos distribuições t de Student, precisamos do pacote brms. O brms usa a mesma síntaxe que o rstanarm e a única diferença é que o brms não possui os modelos pré-compilados então os modelos devem ser todos compilados antes de serem rodados. A diferença prática é que você irá esperar alguns instantes antes do R começar a simular MCMC e amostrar do modelo.\nA função que usa-se para designar modelos lineares no brms é a brm():\nbrm(y ~ x1 + x2 + x3,\n    data = df,\n    family = student)\nExemplo com os dados de Prestígio de Duncan (1961)\nPara exemplicar regressão robusta vamos usar um dataset que tem muitas observações discrepantes (outliers) chamado Duncan. Ele possui 45 observações sobre ocupações nos EUA e 4 variáveis:\ntype: Tipo de ocupação. Uma variável qualitativa:\nprof - profissional ou de gestão\nwc - white-collar (colarinho branco)\nbc - blue-collar (colarinho azul)\n\nincome: Porcentagem de pessoas da ocupação que ganham acima $ 3.500 por ano em 1950 (mais ou menos $36.000 em 2017);\neducation: Porcentagem de pessoas da ocupação que possuem diploma de ensino médio em 1949 (que, sendo cínicos, podemos dizer que é de certa maneira equivalente com diploma de Doutorado em 2017); e\nprestige:Porcentagem de respondentes na pesquisa que classificam a sua ocupação como no mínimo “boa” em respeito à prestígio.\n\n\nduncan <- read.csv2(\"datasets/Duncan.csv\", row.names = 1, stringsAsFactors = T)\n\nhist(duncan$prestige,\n     main = \"Histograma do Prestígio\",\n     xlab = \"Prestígio\",\n     ylab = \"Frequência\")\n\n\n\n\nPrimeiro modelo: Regressão Linear\nVamos estimar primeiramente uma regressão linear usando a distribuição Normal como verossimilhança:\n\n\nlibrary(rstanarm)\nmodel_1 <- stan_glm(\n  prestige ~ income + education,\n  data = duncan,\n  family = gaussian\n)\n\n\n\nE na sequência o sumário das estimativas do modelo, assim como os diagnósticos da MCMC:\n\n\nsummary(model_1)\n\n\n\nModel Info:\n function:     stan_glm\n family:       gaussian [identity]\n formula:      prestige ~ income + education\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 45\n predictors:   3\n\nEstimates:\n              mean   sd    10%   50%   90%\n(Intercept)  -6.2    4.4 -11.7  -6.1  -0.6\nincome        0.6    0.1   0.4   0.6   0.8\neducation     0.5    0.1   0.4   0.5   0.7\nsigma        13.7    1.5  11.9  13.5  15.7\n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 47.7    2.8 44.1  47.7  51.4 \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n              mcse Rhat n_eff\n(Intercept)   0.1  1.0  4275 \nincome        0.0  1.0  2079 \neducation     0.0  1.0  1945 \nsigma         0.0  1.0  3057 \nmean_PPD      0.0  1.0  3558 \nlog-posterior 0.0  1.0  1417 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nAparentemente parece que o modelo possui boas métricas mas quando olhamos o posterior predictive check, vemos uma bagunça:\n\n\npp_check(model_1, nsamples = 45)\n\n\n\n\nSegundo modelo: Regressão Robusta\nPara rodar um modelo Bayesiano que usa como verossimilhança a distribuição t de Student é somente usar a mesma síntaxe que o stan_glm mas colocando argumento family = student:\n\n\nlibrary(brms)\nmodel_2 <- brm(\n  prestige ~ income + education,\n  data = duncan,\n  family = student\n)\n\n\n\nE na sequência o sumário das estimativas do modelo, assim como os diagnósticos da MCMC. Vemos que as estimativas não alteraram muito. Além disso temos um novo parâmetro estimado pelo modelo que é o parâmetro nu (\\(\\nu\\)), que é os graus de liberdade da distribuição t de Student usada como verossimilhança:\n\n\nsummary(model_2, prob =  0.9)\n\n\n Family: student \n  Links: mu = identity; sigma = identity; nu = identity \nFormula: prestige ~ income + education \n   Data: duncan (Number of observations: 45) \nSamples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup samples = 4000\n\nPopulation-Level Effects: \n          Estimate Est.Error l-90% CI u-90% CI Rhat Bulk_ESS Tail_ESS\nIntercept    -6.76      4.03   -13.24    -0.26 1.00     4242     3052\nincome        0.66      0.13     0.44     0.87 1.00     1754     2650\neducation     0.51      0.11     0.34     0.69 1.00     1954     2599\n\nFamily Specific Parameters: \n      Estimate Est.Error l-90% CI u-90% CI Rhat Bulk_ESS Tail_ESS\nsigma    12.35      1.90     9.23    15.43 1.00     1812     1280\nnu       18.31     13.64     3.58    45.68 1.00     1842     1375\n\nSamples were drawn using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\nMas a posterior predictive check ficou com um aspecto muito melhor que o modelo linear:\n\n\npp_check(model_2, nsamples = 45)\n\n\n\n\nPriors do brms\nbrms possui as seguintes configurações como padrão de priors para regressão robusta usando t de Student:\nConstante (Intercept): t de Student com média \\(\\mu = \\text{median}_y\\), desvio padrão de \\(\\max(2.5, MAD(y)\\) e graus de liberdade \\(3\\) - prior = student_t(3, median_y, mad_y), class = intercept\nCoeficientes: para cada coeficiente média \\(\\mu = 0\\) e desvio padrão de \\(2.5\\times\\frac{1}{\\sigma_{x_k}}\\) - prior = normal(0, 2.5 * 1/sd_xk)\nErro residual (sigma): t de Student com média \\(\\mu = 0\\), desvio padrão de \\(\\max(2.5, MAD(y)\\) e graus de liberdade \\(3\\) - prior = student_t(3, 0, mad_y), class = sigma\nGraus de liberdade (nu): distribuição gamma com \\(\\alpha = 2\\) e \\(\\beta = 0.1\\) - prior = gamma(2, 0.1), class = nu\nAtividade Prática\nO dataset Boston Housing está disponível em datasets/Boston_Housing.csv. Possui 506 observações e possui 14 variáveis:\nCRIM - per capita crime rate by town\nZN - proportion of residential land zoned for lots over 25,000 sq.ft.\nINDUS - proportion of non-retail business acres per town.\nCHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\nNOX - nitric oxides concentration (parts per 10 million)\nRM - average number of rooms per dwelling\nAGE - proportion of owner-occupied units built prior to 1940\nDIS - weighted distances to five Boston employment centres\nRAD - index of accessibility to radial highways\nTAX - full-value property-tax rate per $10,000\nPTRATIO - pupil-teacher ratio by town\nB - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\nLSTAT - % lower status of the population\nMEDV - Median value of owner-occupied homes in $1000’s\n\n\n###\n\n\n\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.3 (2020-10-10)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n[1] brms_2.14.4     carData_3.0-4   gapminder_0.3.0 skimr_2.1.2    \n[5] rstanarm_2.21.1 Rcpp_1.0.5      readxl_1.3.1   \n\nloaded via a namespace (and not attached):\n  [1] TH.data_1.0-10       minqa_1.2.4          colorspace_2.0-0    \n  [4] ellipsis_0.3.1       ggridges_0.5.2       rsconnect_0.8.16    \n  [7] rprojroot_2.0.2      estimability_1.3     markdown_1.1        \n [10] base64enc_0.1-3      rstudioapi_0.13      farver_2.0.3        \n [13] rstan_2.21.2         DT_0.16              mvtnorm_1.1-1       \n [16] fansi_0.4.1          lubridate_1.7.9.2    bridgesampling_1.0-0\n [19] codetools_0.2-18     splines_4.0.3        downlit_0.2.1       \n [22] knitr_1.30           shinythemes_1.1.2    projpred_2.0.2      \n [25] bayesplot_1.7.2      jsonlite_1.7.2       nloptr_1.2.2.2      \n [28] shiny_1.5.0          compiler_4.0.3       emmeans_1.5.3       \n [31] backports_1.2.1      assertthat_0.2.1     Matrix_1.3-0        \n [34] fastmap_1.0.1        cli_2.2.0            later_1.1.0.1       \n [37] htmltools_0.5.0      prettyunits_1.1.1    tools_4.0.3         \n [40] igraph_1.2.6         coda_0.19-4          gtable_0.3.0        \n [43] glue_1.4.2           reshape2_1.4.4       dplyr_1.0.2         \n [46] V8_3.4.0             cellranger_1.1.0     vctrs_0.3.6         \n [49] nlme_3.1-151         crosstalk_1.1.0.1    xfun_0.19           \n [52] stringr_1.4.0        ps_1.5.0             lme4_1.1-26         \n [55] mime_0.9             miniUI_0.1.1.1       lifecycle_0.2.0     \n [58] gtools_3.8.2         statmod_1.4.35       MASS_7.3-53         \n [61] zoo_1.8-8            scales_1.1.1         colourpicker_1.1.0  \n [64] Brobdingnag_1.2-6    promises_1.1.1       sandwich_3.0-0      \n [67] parallel_4.0.3       inline_0.3.17        shinystan_2.5.0     \n [70] gamm4_0.2-6          yaml_2.2.1           curl_4.3            \n [73] gridExtra_2.3        ggplot2_3.3.3        loo_2.4.1           \n [76] StanHeaders_2.21.0-7 distill_1.1          stringi_1.5.3       \n [79] highr_0.8            dygraphs_1.1.1.6     boot_1.3-25         \n [82] pkgbuild_1.2.0       repr_1.1.0           rlang_0.4.10        \n [85] pkgconfig_2.0.3      matrixStats_0.57.0   evaluate_0.14       \n [88] lattice_0.20-41      purrr_0.3.4          rstantools_2.1.1    \n [91] htmlwidgets_1.5.3    labeling_0.4.2       processx_3.4.5      \n [94] tidyselect_1.1.0     plyr_1.8.6           magrittr_2.0.1      \n [97] bookdown_0.21        R6_2.5.0             generics_0.1.0      \n[100] multcomp_1.4-15      mgcv_1.8-33          pillar_1.4.7        \n[103] withr_2.3.0          xts_0.12.1           abind_1.4-5         \n[106] survival_3.2-7       tibble_3.0.4         crayon_1.3.4        \n[109] utf8_1.1.4           rmarkdown_2.6        grid_4.0.3          \n[112] callr_3.5.1          threejs_0.3.3        digest_0.6.27       \n[115] xtable_1.8-4         tidyr_1.1.2          httpuv_1.5.4        \n[118] RcppParallel_5.0.2   stats4_4.0.3         munsell_0.5.0       \n[121] shinyjs_2.0.0       \n\n\n\n\n",
      "last_modified": "2021-01-03T04:52:07-03:00"
    },
    {
      "path": "9-Regressao_Multinivel.html",
      "title": "Modelos Multiniveis ou Modelos Hierárquicos",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "August 2, 2020",
      "contents": "\n\nContents\nQuando usar Modelos Multiníveis?\nHyperprior\nTrês abordagens\nRandom Intercept Model\nRandom Slope Model\nRandom Intercept-Slope Model\nExemplo com o dataset cheese\n\nPriors de Modelos Multiníveis\nAtividade Prática\nAmbiente\n\n\nModelos hierárquicos Bayesianos (também chamados de modelos multiníveis) são um modelo estatístico escrito em níveis múltiplos (forma hierárquica) que estima os parâmetros da distribuição posterior usando o método Bayesiano. Os submodelos se combinam para formar o modelo hierárquico, e o teorema de Bayes é usado para integrá-los aos dados observados e contabilizar toda a incerteza que está presente. O resultado dessa integração é a distribuição posterior, também conhecida como estimativa de probabilidade atualizada, à medida que evidências adicionais sobre a distribuição anterior são adquiridas.\nA modelagem hierárquica é usada quando as informações estão disponíveis em vários níveis diferentes de unidades de observação. A forma hierárquica de análise e organização auxilia no entendimento de problemas multiparâmetros e também desempenha um papel importante no desenvolvimento de estratégias computacionais.\nOs modelos hierárquicos são descrições matemáticas que envolvem vários parâmetros, de modo que as estimativas de alguns parâmetros dependem significativamente dos valores de outros parâmetros.\nModelo HierarquicoQuando usar Modelos Multiníveis?\nModelos multiníveis são particularmente apropriados para projetos de pesquisa onde os dados dos participantes são organizados em mais de um nível (ou seja, dados aninhados - nested data). As unidades de análise geralmente são indivíduos (em um nível inferior) que estão aninhados em unidades contextuais/agregadas (em um nível superior).\nHá um pressuposto principal que não pode ser violado em modelos multiníveis que é o de permutabilidade. Esse pressuposto parte do princípio que os grupos são permutáveis. Se esse pressuposto é violado na sua inferência, então modelos multiníveis não são apropriados.\nHyperprior\nComo as priors dos parâmetros são amostradas de uma outra prior do hiperparâmetro (parâmetro do nível superior), as priors do nível superior são chamadas de hyperpriors. Isso faz com que estimativas de um grupo ajudem o modelo a estimar melhor os outros grupos e dando estimativas mais robustas e estáveis.\nTrês abordagens\nModelos multiníveis geralmente se dividem em três abordagens:\nRandom intercept model: Modelo no qual cada grupo recebe uma constante (intercept) diferente\nRandom slope model: Modelo no qual cada grupo recebe um coeficiente diferente para cada variável independente\nRandom intercept-slope model: Modelo no qual cada grupo recebe tanto uma constante (intercept) quanto um coeficiente diferente para cada variável independente\nRandom Intercept Model\nA primeira abordagem é o random intercept model na qual especificamos para cada grupo uma constante diferente. Essas constantes são amostrada de uma hyperprior.\nO pacote rstanarm tem as funcionalidades completas para rodar modelos multiníveis e a única coisa a se fazer é alterar a formula. Há uma segunda mudança também que não usamos mais a função stan_glm() mas sim a função stan_glmer().\nNo caso de random intercept model, a formula a ser usada segue este padrão:\ny ~ (1 | group) + x1 + x2\nRandom Slope Model\nA segunda abordagem é o random slope model na qual especificamos para cada grupo um coeficiente diferente para cada variável independente. Esses coeficientes são amostrada de uma hyperprior.\nNo caso de random slope model, a formula a ser usada segue este padrão:\ny ~ (0 + x1 | group) + (0 + x2 | group)\nRandom Intercept-Slope Model\nA terceira abordagem é o random intercept-slope model na qual especificamos para cada grupo uma constante diferente além de coeficientes diferentes para cada variável independente. Essas constantes e coeficientes são amostrados de duas ou mais hyperpriors.\nNo caso de random intercept-slope model, a formula a ser usada segue este padrão:\ny ~ (1 + x1 | group) + (1 + x2 | group)\nExemplo com o dataset cheese\nO dataset cheese possui 160 observações de avaliações de queijo. Um grupo de 10 avaliadores “rurais” e 10 “urbanos” avaliaram 4 queijos diferentes \\((A,B,C,D)\\) em duas amostras. Portanto \\(4 \\cdot 20 \\cdot 2 = 160\\). Possui 4 variáveis:\ncheese: tipo do queijo \\((A,B,C,D)\\)\nrater: avaliador \\((1,\\dots, 10)\\)\nbackground: origem do avaliador em “urbano” ou “rural”\ny: variável dependente - nota da avaliação\n\n\ncheese <- read.csv2(\"datasets/cheese.csv\", stringsAsFactors = T, row.names = 1)\n\n\n\nRandom Intercept Model\nNo primeiro exemplo vamos usar um modelo que cada grupo de cheese recebe uma constante diferente:\n\n\nlibrary(rstanarm)\nrandom_intercept <- stan_glmer(\n  y ~ (1 | cheese) + background,\n  data = cheese\n)\n\n\n\nNo sumário do modelo vemos que os avaliadores urbanos avaliam melhor os queijos que os avaliadores rurais, mas também observamos que cada queijo possui uma “taxa basal” de avaliação. Sendo \\(B\\) o pior queijo e \\(C\\) o melhor queijo:\n\n\nsummary(random_intercept)\n\n\n\nModel Info:\n function:     stan_glmer\n family:       gaussian [identity]\n formula:      y ~ (1 | cheese) + background\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 160\n groups:       cheese (4)\n\nEstimates:\n                                        mean   sd    10%   50%   90%\n(Intercept)                            67.4    5.9  60.5  67.3  74.3\nbackgroundurban                         7.4    1.1   6.0   7.4   8.8\nb[(Intercept) cheese:A]                 3.7    5.9  -3.3   3.8  10.7\nb[(Intercept) cheese:B]               -14.2    5.9 -21.2 -14.1  -7.2\nb[(Intercept) cheese:C]                 8.5    5.9   1.6   8.5  15.5\nb[(Intercept) cheese:D]                 1.3    5.9  -5.7   1.3   8.3\nsigma                                   7.1    0.4   6.6   7.1   7.6\nSigma[cheese:(Intercept),(Intercept)] 138.1  128.7  42.6  98.7 274.5\n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 70.8    0.8 69.8  70.8  71.9 \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n                                      mcse Rhat n_eff\n(Intercept)                           0.2  1.0  1191 \nbackgroundurban                       0.0  1.0  4045 \nb[(Intercept) cheese:A]               0.2  1.0  1170 \nb[(Intercept) cheese:B]               0.2  1.0  1169 \nb[(Intercept) cheese:C]               0.2  1.0  1196 \nb[(Intercept) cheese:D]               0.2  1.0  1156 \nsigma                                 0.0  1.0  3572 \nSigma[cheese:(Intercept),(Intercept)] 3.1  1.0  1677 \nmean_PPD                              0.0  1.0  3695 \nlog-posterior                         0.1  1.0  1298 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nRandom Slope Model\nNo segundo exemplo vamos usar um modelo que cada grupo de cheese recebe um coeficiente diferente para background:\n\n\nrandom_slope <- stan_glmer(\n  y ~ (0 + background | cheese),\n  data = cheese\n)\n\n\n\nAqui vemos que todos os queijos recebem a mesma constante mas cada queijo possui um coeficiente diferente para background do avaliador:\n\n\nsummary(random_slope)\n\n\n\nModel Info:\n function:     stan_glmer\n family:       gaussian [identity]\n formula:      y ~ (0 + background | cheese)\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 160\n groups:       cheese (4)\n\nEstimates:\n                                                mean   sd    10%\n(Intercept)                                    69.6    5.8  62.5\nb[backgroundrural cheese:A]                     1.1    5.9  -6.3\nb[backgroundurban cheese:A]                     9.1    6.0   1.7\nb[backgroundrural cheese:B]                   -15.4    6.2 -23.1\nb[backgroundurban cheese:B]                   -10.0    5.8 -17.1\nb[backgroundrural cheese:C]                     5.7    5.8  -1.5\nb[backgroundurban cheese:C]                    14.0    6.1   6.6\nb[backgroundrural cheese:D]                    -0.4    5.9  -7.7\nb[backgroundurban cheese:D]                     5.7    6.0  -1.5\nsigma                                           7.1    0.4   6.6\nSigma[cheese:backgroundrural,backgroundrural] 132.2  124.6  41.0\nSigma[cheese:backgroundurban,backgroundrural]  77.0   89.0   6.2\nSigma[cheese:backgroundurban,backgroundurban] 166.1  144.3  52.8\n                                                50%   90%\n(Intercept)                                    69.7  76.7\nb[backgroundrural cheese:A]                     1.1   8.4\nb[backgroundurban cheese:A]                     9.0  16.5\nb[backgroundrural cheese:B]                   -15.4  -7.8\nb[backgroundurban cheese:B]                   -10.1  -3.0\nb[backgroundrural cheese:C]                     5.6  12.8\nb[backgroundurban cheese:C]                    14.0  21.5\nb[backgroundrural cheese:D]                    -0.5   6.8\nb[backgroundurban cheese:D]                     5.6  13.0\nsigma                                           7.1   7.7\nSigma[cheese:backgroundrural,backgroundrural]  95.0 257.4\nSigma[cheese:backgroundurban,backgroundrural]  57.3 170.7\nSigma[cheese:backgroundurban,backgroundurban] 124.1 325.2\n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 70.8    0.8 69.8  70.8  71.8 \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n                                              mcse Rhat n_eff\n(Intercept)                                   0.2  1.0   705 \nb[backgroundrural cheese:A]                   0.2  1.0   740 \nb[backgroundurban cheese:A]                   0.2  1.0   733 \nb[backgroundrural cheese:B]                   0.2  1.0   729 \nb[backgroundurban cheese:B]                   0.2  1.0   771 \nb[backgroundrural cheese:C]                   0.2  1.0   744 \nb[backgroundurban cheese:C]                   0.2  1.0   713 \nb[backgroundrural cheese:D]                   0.2  1.0   739 \nb[backgroundurban cheese:D]                   0.2  1.0   725 \nsigma                                         0.0  1.0  4683 \nSigma[cheese:backgroundrural,backgroundrural] 2.9  1.0  1895 \nSigma[cheese:backgroundurban,backgroundrural] 2.5  1.0  1220 \nSigma[cheese:backgroundurban,backgroundurban] 4.5  1.0  1024 \nmean_PPD                                      0.0  1.0  3950 \nlog-posterior                                 0.1  1.0  1011 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nRandom Intercept-Slope Model\nNo terceiro exemplo vamos usar um modelo que cada grupo de cheese recebe uma constante diferente e um coeficiente diferente para background:\n\n\nrandom_intercept_slope <- stan_glmer(\n  y ~ (1 + background | cheese),\n  data = cheese\n)\n\n\n\nAqui vemos que os queijos recebem a constantes diferentes e que cada queijo possui um coeficiente diferente para background do avaliador:\n\n\nsummary(random_intercept_slope)\n\n\n\nModel Info:\n function:     stan_glmer\n family:       gaussian [identity]\n formula:      y ~ (1 + background | cheese)\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 160\n groups:       cheese (4)\n\nEstimates:\n                                                mean   sd    10%\n(Intercept)                                    65.5    7.6  56.3\nb[(Intercept) cheese:A]                         5.4    7.6  -3.8\nb[backgroundurban cheese:A]                     7.8    2.1   5.1\nb[(Intercept) cheese:B]                       -10.9    7.9 -20.7\nb[backgroundurban cheese:B]                     4.7    2.3   1.7\nb[(Intercept) cheese:C]                         9.8    7.5   0.7\nb[backgroundurban cheese:C]                     8.4    2.2   5.6\nb[(Intercept) cheese:D]                         3.8    7.6  -5.5\nb[backgroundurban cheese:D]                     6.1    2.1   3.4\nsigma                                           7.1    0.4   6.6\nSigma[cheese:(Intercept),(Intercept)]         148.7  143.0  45.2\nSigma[cheese:backgroundurban,(Intercept)]      18.9   73.4 -50.4\nSigma[cheese:backgroundurban,backgroundurban]  88.3   85.1  27.1\n                                                50%   90%\n(Intercept)                                    65.4  74.7\nb[(Intercept) cheese:A]                         5.6  14.4\nb[backgroundurban cheese:A]                     7.7  10.4\nb[(Intercept) cheese:B]                       -10.7  -1.2\nb[backgroundurban cheese:B]                     4.7   7.6\nb[(Intercept) cheese:C]                         9.8  18.9\nb[backgroundurban cheese:C]                     8.4  11.2\nb[(Intercept) cheese:D]                         3.9  12.9\nb[backgroundurban cheese:D]                     6.1   8.7\nsigma                                           7.1   7.7\nSigma[cheese:(Intercept),(Intercept)]         106.4 294.7\nSigma[cheese:backgroundurban,(Intercept)]      16.4  94.1\nSigma[cheese:backgroundurban,backgroundurban]  63.9 173.3\n\nFit Diagnostics:\n           mean   sd   10%   50%   90%\nmean_PPD 70.9    0.8 69.8  70.9  71.9 \n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n                                              mcse Rhat n_eff\n(Intercept)                                   0.3  1.0   751 \nb[(Intercept) cheese:A]                       0.3  1.0   756 \nb[backgroundurban cheese:A]                   0.0  1.0  5162 \nb[(Intercept) cheese:B]                       0.3  1.0   751 \nb[backgroundurban cheese:B]                   0.0  1.0  2935 \nb[(Intercept) cheese:C]                       0.3  1.0   776 \nb[backgroundurban cheese:C]                   0.0  1.0  3991 \nb[(Intercept) cheese:D]                       0.3  1.0   785 \nb[backgroundurban cheese:D]                   0.0  1.0  5120 \nsigma                                         0.0  1.0  3557 \nSigma[cheese:(Intercept),(Intercept)]         3.3  1.0  1836 \nSigma[cheese:backgroundurban,(Intercept)]     2.4  1.0   912 \nSigma[cheese:backgroundurban,backgroundurban] 2.0  1.0  1824 \nmean_PPD                                      0.0  1.0  4015 \nlog-posterior                                 0.1  1.0  1064 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n\nPriors de Modelos Multiníveis\nRelembrando a tabela de priors da Aula 4:\nArgumento\nUsado em\nAplica-se à\nprior_intercept\nTodas funções de modelagem exceto stan_polr and stan_nlmer\nConstante (intercept) do modelo, após centralização dos preditores\nprior\nTodas funções de modelagem\nCoeficientes de Regressão, não inclui coeficientes que variam por grupo em modelos multiníveis (veja prior_covariance)\nprior_aux\nstan_glm, stan_glmer, stan_gamm4, stan_nlmer\nParâmetro auxilizar (ex: desvio padrão (standard error - DP), interpretação depende do modelo\nprior_covariance\nstan_glmer, stan_gamm4, stan_nlmer\nMatrizes de covariância em modelos multiníveis\nConstante(Intercept): centralizada com média \\(\\mu_{y_{group}}\\) para cada grupo e desvio padrão de \\(2.5 \\sigma_{y_{group}}\\) para cada grupo - prior_intercept = normal(mean_y_group, 2.5 * sd_y_group)\nCoeficientes: aqui não especifica-se uma prior para cada coeficiente, mas sim uma prior para a matriz de correlação das variáveis independentes usando uma distribuição LKJ - prior_covariance = lkj(regularization = 1, concentration = 1, shape = 1, scale = 1)\nAtividade Prática\nPara atividade prática, temos o dataset rikz em datasets/rikz.csv.\nFor each of 9 intertidal areas (denoted ‘Beaches’), the researchers sampled five sites (denoted ‘Sites’) and at each site they measured abiotic variables and the diversity of macro-fauna (e.g. aquatic invertebrates). Here, species richness refers to the total number of species found at a given site while NAP ( i.e. Normal Amsterdams Peil) refers to the height of the sampling location relative to the mean sea level and represents a measure of the amount of food available for birds, etc. For our purpose, the main question is:\nWhat is the influence of NAP on species richness?\nRicz Dataset\n\nrikz <- read.csv2(\"datasets/rikz.csv\", row.names = 1)\nrikz$Beach <- as.factor(rikz$Beach)\nrikz$Site <- as.factor(rikz$Site)\n\n\n\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.3 (2020-10-10)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n[1] brms_2.14.4     carData_3.0-4   gapminder_0.3.0 skimr_2.1.2    \n[5] rstanarm_2.21.1 Rcpp_1.0.5      readxl_1.3.1   \n\nloaded via a namespace (and not attached):\n  [1] TH.data_1.0-10       minqa_1.2.4          colorspace_2.0-0    \n  [4] ellipsis_0.3.1       ggridges_0.5.2       rsconnect_0.8.16    \n  [7] rprojroot_2.0.2      estimability_1.3     markdown_1.1        \n [10] base64enc_0.1-3      rstudioapi_0.13      farver_2.0.3        \n [13] rstan_2.21.2         DT_0.16              mvtnorm_1.1-1       \n [16] fansi_0.4.1          lubridate_1.7.9.2    bridgesampling_1.0-0\n [19] codetools_0.2-18     splines_4.0.3        downlit_0.2.1       \n [22] knitr_1.30           shinythemes_1.1.2    projpred_2.0.2      \n [25] bayesplot_1.7.2      jsonlite_1.7.2       nloptr_1.2.2.2      \n [28] shiny_1.5.0          compiler_4.0.3       emmeans_1.5.3       \n [31] backports_1.2.1      assertthat_0.2.1     Matrix_1.3-0        \n [34] fastmap_1.0.1        cli_2.2.0            later_1.1.0.1       \n [37] htmltools_0.5.0      prettyunits_1.1.1    tools_4.0.3         \n [40] igraph_1.2.6         coda_0.19-4          gtable_0.3.0        \n [43] glue_1.4.2           reshape2_1.4.4       dplyr_1.0.2         \n [46] V8_3.4.0             cellranger_1.1.0     vctrs_0.3.6         \n [49] nlme_3.1-151         crosstalk_1.1.0.1    xfun_0.19           \n [52] stringr_1.4.0        ps_1.5.0             lme4_1.1-26         \n [55] mime_0.9             miniUI_0.1.1.1       lifecycle_0.2.0     \n [58] gtools_3.8.2         statmod_1.4.35       MASS_7.3-53         \n [61] zoo_1.8-8            scales_1.1.1         colourpicker_1.1.0  \n [64] Brobdingnag_1.2-6    promises_1.1.1       sandwich_3.0-0      \n [67] parallel_4.0.3       inline_0.3.17        shinystan_2.5.0     \n [70] gamm4_0.2-6          yaml_2.2.1           curl_4.3            \n [73] gridExtra_2.3        ggplot2_3.3.3        loo_2.4.1           \n [76] StanHeaders_2.21.0-7 distill_1.1          stringi_1.5.3       \n [79] highr_0.8            dygraphs_1.1.1.6     boot_1.3-25         \n [82] pkgbuild_1.2.0       repr_1.1.0           rlang_0.4.10        \n [85] pkgconfig_2.0.3      matrixStats_0.57.0   evaluate_0.14       \n [88] lattice_0.20-41      purrr_0.3.4          rstantools_2.1.1    \n [91] htmlwidgets_1.5.3    labeling_0.4.2       processx_3.4.5      \n [94] tidyselect_1.1.0     plyr_1.8.6           magrittr_2.0.1      \n [97] bookdown_0.21        R6_2.5.0             generics_0.1.0      \n[100] multcomp_1.4-15      mgcv_1.8-33          pillar_1.4.7        \n[103] withr_2.3.0          xts_0.12.1           abind_1.4-5         \n[106] survival_3.2-7       tibble_3.0.4         crayon_1.3.4        \n[109] utf8_1.1.4           rmarkdown_2.6        grid_4.0.3          \n[112] callr_3.5.1          threejs_0.3.3        digest_0.6.27       \n[115] xtable_1.8-4         tidyr_1.1.2          httpuv_1.5.4        \n[118] RcppParallel_5.0.2   stats4_4.0.3         munsell_0.5.0       \n[121] shinyjs_2.0.0       \n\n\n\n\n",
      "last_modified": "2021-01-03T04:52:27-03:00"
    },
    {
      "path": "aux-Dados_Faltantes.html",
      "title": "Dados Faltantes",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "August 2, 2020",
      "contents": "\n\nContents\nRemover dados faltantes\nImputar valores nos dados faltantes\nImputar a média\nImputar a mediana\nImputar o último valor ocorrido\n\nComparação dos resultados\nAmbiente\n\n\nDados faltantes são um problema comum em qualquer análise de dados. Tanto o rstan, quanto brms e rstanarm usam observações completas nas suas inferências. Então, toma observação que contiver qualquer dado faltante será removida por completa. Temos duas abordagens básicas para lidar com dados faltantes1:\nremover os dados faltantes\nimputar valores nos dados faltantes\nRemover dados faltantes\nA remoção de dados faltantes se divide em duas principais abordagens usando a função na.omit() do pacote base stats:\nremoção de observações com dados faltantes: aqui removemos as linhas com dados faltantes df <- na.omit(df)\nremoção de variáveis com dados faltantes: aqui removemos as colunas com dados faltantes df <- t(na.omit(t(df)))\nImputar valores nos dados faltantes\nDentre as diversas maneiras de imputar valores ao dados faltantes, as mais comuns são três:\nimputar a média\nimputar a mediana\nimputar o último valor ocorrido (muito usada em séries temporais)\nMas ainda há maneiras mais avançadas e que desempenham melhor em certas condições (não cobriremos essas técnicas nesse curso):\nk-nearest neighbors imputation\nrandom forest imputation\nHá um pacote de R chamado DescTools que é uma coleção de funções focadas especialmente na parte descritiva de análise de um dataset.\nPara mostrar as abordagens, geramos um dataset de uma série temporal de uma semana com dados faltantes:\n\n\nlibrary(DescTools)\nset.seed(123)\ndf <- data.frame(\n  dia = c(\"seg\", \"ter\", \"qua\", \"qui\", \"sex\", \"sab\", \"dom\"),\n  valor = runif(7))\nindices_aleatorios <- sample(1:nrow(df), 2)\ndf[indices_aleatorios[1], 2] <- NA\ndf[indices_aleatorios[2], 2] <- NA\n\n\n\nImputar a média\n\n\ndf$media <- Impute(df$valor, FUN = mean(df$valor, na.rm = T))\n\n\n\nImputar a mediana\n\n\ndf$mediana <- Impute(df$valor, FUN = median(df$valor, na.rm = T))\n\n\n\nImputar o último valor ocorrido\n\n\ndf$ultimo <- LOCF(df$valor)\n\n\n\nComparação dos resultados\n\n\ndf\n\n\n  dia valor media mediana ultimo\n1 seg  0.29  0.29    0.29   0.29\n2 ter  0.79  0.79    0.79   0.79\n3 qua    NA  0.69    0.79   0.79\n4 qui  0.88  0.88    0.88   0.88\n5 sex  0.94  0.94    0.94   0.94\n6 sab    NA  0.69    0.79   0.94\n7 dom  0.53  0.53    0.53   0.53\n\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.3 (2020-10-10)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n[1] DescTools_0.99.39 brms_2.14.4       carData_3.0-4    \n[4] gapminder_0.3.0   skimr_2.1.2       rstanarm_2.21.1  \n[7] Rcpp_1.0.5        readxl_1.3.1     \n\nloaded via a namespace (and not attached):\n  [1] backports_1.2.1      plyr_1.8.6           igraph_1.2.6        \n  [4] repr_1.1.0           splines_4.0.3        crosstalk_1.1.0.1   \n  [7] ggplot2_3.3.3        TH.data_1.0-10       rstantools_2.1.1    \n [10] inline_0.3.17        digest_0.6.27        htmltools_0.5.0     \n [13] rsconnect_0.8.16     fansi_0.4.1          magrittr_2.0.1      \n [16] RcppParallel_5.0.2   matrixStats_0.57.0   xts_0.12.1          \n [19] sandwich_3.0-0       prettyunits_1.1.1    colorspace_2.0-0    \n [22] xfun_0.19            dplyr_1.0.2          callr_3.5.1         \n [25] crayon_1.3.4         jsonlite_1.7.2       Exact_2.1           \n [28] lme4_1.1-26          survival_3.2-7       zoo_1.8-8           \n [31] glue_1.4.2           gtable_0.3.0         emmeans_1.5.3       \n [34] V8_3.4.0             pkgbuild_1.2.0       rstan_2.21.2        \n [37] abind_1.4-5          scales_1.1.1         mvtnorm_1.1-1       \n [40] miniUI_0.1.1.1       xtable_1.8-4         stats4_4.0.3        \n [43] StanHeaders_2.21.0-7 DT_0.16              htmlwidgets_1.5.3   \n [46] threejs_0.3.3        ellipsis_0.3.1       pkgconfig_2.0.3     \n [49] loo_2.4.1            farver_2.0.3         utf8_1.1.4          \n [52] tidyselect_1.1.0     labeling_0.4.2       rlang_0.4.10        \n [55] reshape2_1.4.4       later_1.1.0.1        munsell_0.5.0       \n [58] cellranger_1.1.0     tools_4.0.3          cli_2.2.0           \n [61] generics_0.1.0       ggridges_0.5.2       evaluate_0.14       \n [64] stringr_1.4.0        fastmap_1.0.1        yaml_2.2.1          \n [67] processx_3.4.5       knitr_1.30           purrr_0.3.4         \n [70] rootSolve_1.8.2.1    nlme_3.1-151         mime_0.9            \n [73] projpred_2.0.2       compiler_4.0.3       bayesplot_1.7.2     \n [76] shinythemes_1.1.2    rstudioapi_0.13      curl_4.3            \n [79] gamm4_0.2-6          e1071_1.7-4          tibble_3.0.4        \n [82] statmod_1.4.35       stringi_1.5.3        highr_0.8           \n [85] ps_1.5.0             Brobdingnag_1.2-6    lattice_0.20-41     \n [88] Matrix_1.3-0         nloptr_1.2.2.2       markdown_1.1        \n [91] shinyjs_2.0.0        vctrs_0.3.6          pillar_1.4.7        \n [94] lifecycle_0.2.0      bridgesampling_1.0-0 estimability_1.3    \n [97] lmom_2.8             httpuv_1.5.4         R6_2.5.0            \n[100] bookdown_0.21        promises_1.1.1       gridExtra_2.3       \n[103] gld_2.6.2            codetools_0.2-18     distill_1.1         \n[106] boot_1.3-25          colourpicker_1.1.0   MASS_7.3-53         \n[109] gtools_3.8.2         assertthat_0.2.1     rprojroot_2.0.2     \n[112] withr_2.3.0          shinystan_2.5.0      multcomp_1.4-15     \n[115] expm_0.999-5         mgcv_1.8-33          parallel_4.0.3      \n[118] grid_4.0.3           class_7.3-17         tidyr_1.1.2         \n[121] coda_0.19-4          minqa_1.2.4          rmarkdown_2.6       \n[124] downlit_0.2.1        shiny_1.5.0          lubridate_1.7.9.2   \n[127] base64enc_0.1-3      dygraphs_1.1.1.6    \n\n\nhá uma terceira que é modelar os dados faltantes, veja a vinheta do brms para mais detalhes↩︎\n",
      "last_modified": "2021-01-03T04:52:28-03:00"
    },
    {
      "path": "aux-Regressao_Coeficientes.html",
      "title": "Diferenças entre Coeficientes padronizados vs brutos",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "August 2, 2020",
      "contents": "\n\nContents\nSimulação\nMédia e Desvio Padrões\nCoeficientes Brutos vs Padronizados\n\nAmbiente\n\n\nEm tabelas de regressão temos geralmente temos duas opções de reportar os coeficientes:\nCoeficientes Brutos: não há transformações e as associações das variáveis independentes/controles (covariáveis) com a dependente são reportadas em suas medidas originais. Exemplo: A cada 1 unidades de aumento de \\(x\\), \\(y\\) aumenta 0.45.\nCoeficientes Padronizados: os coeficientes são transformados para expressarem as associações das variáveis independentes/controles (covariáveis) com a dependente em relação à variação dos seus desvios padrões. Exemplo: A cada 1 desvio padrão de variação positiva de \\(x\\), \\(y\\) possui variação de 0.1 desvio padrão.\nSimulação\nPara explicar melhor esses conceitos, simularemos alguns dados:\n\\(x\\): 1,000 observações amostradas de uma distribuição normal com média 1 e desvio padrão 0.1. \\(x \\sim \\mathcal{N} (1, 0.1)\\)\n\\(y\\): uma combinação linear de \\(100x\\) com uma constante e um erro pequeno normalmente distribuído. \\(y = 10 + 100x + \\epsilon\\) e \\(\\epsilon \\sim \\mathcal{N} (0, 1)\\).\n\n\nN <- 1000\nx <- rnorm(N, 1, 0.1)\nerror <- rnorm(N, 0, 1)\ny <- rep(10, N) + 100*x + error\n\ndf <- data.frame(x, y)\n\n\n\n\n\nlibrary(skimr)\nskim(df)\n\n\nTable 1: Data summary\nName\ndf\nNumber of rows\n1000\nNumber of columns\n2\n_______________________\n\nColumn type frequency:\n\nnumeric\n2\n________________________\n\nGroup variables\nNone\nVariable type: numeric\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\nx\n0\n1\n1\n0.1\n0.67\n0.93\n1\n1.1\n1.3\n▁▃▇▃▁\ny\n0\n1\n110\n10.1\n75.94\n103.01\n109\n116.5\n142.7\n▁▃▇▃▁\n\nMédia e Desvio Padrões\nPrestem atenção:\n\\(x\\): média 1, desvio padrão 0.1\n\\(y\\): média 109.6, desvio padrão 10.05\nCoeficientes Brutos vs Padronizados\nAgora vamos rodar uma regressão e mostrar coeficientes tanto os coeficientes brutos e os padronizados\n\n\nlibrary(lm.beta)\nmodel <- lm.beta(lm(y ~ x, df))\nsummary(model)\n\n\n\nCall:\nlm(formula = y ~ x, data = df)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-3.701 -0.727 -0.009  0.683  2.728 \n\nCoefficients:\n            Estimate Standardized Std. Error t value\n(Intercept)    9.460        0.000      0.324    29.2\nx            100.506        0.995      0.324   310.5\n                       Pr(>|t|)    \n(Intercept) <0.0000000000000002 ***\nx           <0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1 on 998 degrees of freedom\nMultiple R-squared:  0.99,  Adjusted R-squared:  0.99 \nF-statistic: 9.64e+04 on 1 and 998 DF,  p-value: <0.0000000000000002\n\nPor fim, ambas colunas mostram a mesma coisa\nColuna não padronizada Estimate: a cada 1 unidade que \\(x\\) aumenta, \\(y\\) aumenta 100.51\nColuna padronizada Standardized: a cada 1 desvio padrão de \\(x\\) de incremento (dp = 0.1), há um aumento de 0.99 desvio padrão de \\(y\\) (10). Um total de 100.51. \\(\\big( \\frac{0.955 * \\operatorname{sd}_y}{\\operatorname{sd}_x}\\big)\\)\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.3 (2020-10-10)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n[1] lm.beta_1.5-1     DescTools_0.99.39 brms_2.14.4      \n[4] carData_3.0-4     gapminder_0.3.0   skimr_2.1.2      \n[7] rstanarm_2.21.1   Rcpp_1.0.5        readxl_1.3.1     \n\nloaded via a namespace (and not attached):\n  [1] backports_1.2.1      plyr_1.8.6           igraph_1.2.6        \n  [4] repr_1.1.0           splines_4.0.3        crosstalk_1.1.0.1   \n  [7] ggplot2_3.3.3        TH.data_1.0-10       rstantools_2.1.1    \n [10] inline_0.3.17        digest_0.6.27        htmltools_0.5.0     \n [13] rsconnect_0.8.16     fansi_0.4.1          magrittr_2.0.1      \n [16] RcppParallel_5.0.2   matrixStats_0.57.0   xts_0.12.1          \n [19] sandwich_3.0-0       prettyunits_1.1.1    colorspace_2.0-0    \n [22] xfun_0.19            dplyr_1.0.2          callr_3.5.1         \n [25] crayon_1.3.4         jsonlite_1.7.2       Exact_2.1           \n [28] lme4_1.1-26          survival_3.2-7       zoo_1.8-8           \n [31] glue_1.4.2           gtable_0.3.0         emmeans_1.5.3       \n [34] V8_3.4.0             pkgbuild_1.2.0       rstan_2.21.2        \n [37] abind_1.4-5          scales_1.1.1         mvtnorm_1.1-1       \n [40] miniUI_0.1.1.1       xtable_1.8-4         stats4_4.0.3        \n [43] StanHeaders_2.21.0-7 DT_0.16              htmlwidgets_1.5.3   \n [46] threejs_0.3.3        ellipsis_0.3.1       pkgconfig_2.0.3     \n [49] loo_2.4.1            farver_2.0.3         utf8_1.1.4          \n [52] tidyselect_1.1.0     labeling_0.4.2       rlang_0.4.10        \n [55] reshape2_1.4.4       later_1.1.0.1        munsell_0.5.0       \n [58] cellranger_1.1.0     tools_4.0.3          cli_2.2.0           \n [61] generics_0.1.0       ggridges_0.5.2       evaluate_0.14       \n [64] stringr_1.4.0        fastmap_1.0.1        yaml_2.2.1          \n [67] processx_3.4.5       knitr_1.30           purrr_0.3.4         \n [70] rootSolve_1.8.2.1    nlme_3.1-151         mime_0.9            \n [73] projpred_2.0.2       compiler_4.0.3       bayesplot_1.7.2     \n [76] shinythemes_1.1.2    rstudioapi_0.13      curl_4.3            \n [79] gamm4_0.2-6          e1071_1.7-4          tibble_3.0.4        \n [82] statmod_1.4.35       stringi_1.5.3        highr_0.8           \n [85] ps_1.5.0             Brobdingnag_1.2-6    lattice_0.20-41     \n [88] Matrix_1.3-0         nloptr_1.2.2.2       markdown_1.1        \n [91] shinyjs_2.0.0        vctrs_0.3.6          pillar_1.4.7        \n [94] lifecycle_0.2.0      bridgesampling_1.0-0 estimability_1.3    \n [97] lmom_2.8             httpuv_1.5.4         R6_2.5.0            \n[100] bookdown_0.21        promises_1.1.1       gridExtra_2.3       \n[103] gld_2.6.2            codetools_0.2-18     distill_1.1         \n[106] boot_1.3-25          colourpicker_1.1.0   MASS_7.3-53         \n[109] gtools_3.8.2         assertthat_0.2.1     rprojroot_2.0.2     \n[112] withr_2.3.0          shinystan_2.5.0      multcomp_1.4-15     \n[115] expm_0.999-5         mgcv_1.8-33          parallel_4.0.3      \n[118] grid_4.0.3           class_7.3-17         tidyr_1.1.2         \n[121] coda_0.19-4          minqa_1.2.4          rmarkdown_2.6       \n[124] downlit_0.2.1        shiny_1.5.0          lubridate_1.7.9.2   \n[127] base64enc_0.1-3      dygraphs_1.1.1.6    \n\n\n\n\n",
      "last_modified": "2021-01-03T04:52:29-03:00"
    },
    {
      "path": "aux-Tabelas_para_Publicacao.html",
      "title": "Como montar tabelas de modelos Bayesianos prontas para publicação",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "August 2, 2020",
      "contents": "\n\nContents\nEstatísticas Descritivas\nTabela de Correlações\nRegressão Linear Bayesiana\nTabela de Regressão Linear\n\nModelo de Regressão Binomial/Logística\nTabela de Regressão Binomial/Logística\n\nAmbiente\n\n\n\n\n\nAo invés de ser obrigado a passar horas a fio formatando tabelas em Excel softwares pagos, você pode usar pacotes gratuitos do R para formatar automaticamente suas tabelas:\nEstatísticas Descritivas: gtsummary::tbl_summary()\nCorrelações: sjPlot::tab_corr()\nRegressões: sjPlot::tab_model()\nEstatísticas Descritivas\nO pacote gtsummary possui um conjunto de funções para sumarizar dados e tabelas. Eu particularmente gosto da função gtsummary::tbl_summary(). Ela formata uma tabela de Estatística Descritiva de maneira bem conveniente.\n\n\ngtsummary::tbl_summary(\n  kidiq,\n  by = mom_hs,\n  type = all_continuous() ~ \"continuous2\",\n  statistic = list(\n    all_continuous() ~ c(\"{N_nonmiss}\",\n                         \"{median} ({p25}, {p75})\", \n                         \"{min}, {max}\"),\n    all_categorical() ~ \"{n} ({p}%)\"),\n  missing = \"no\",\n  digits = all_continuous() ~ 2) %>%\n  # add p value and overall\n  add_p(pvalue_fun = ~style_pvalue(.x, digits = 2)) %>% \n  add_overall() %>%\n  # bold variable labels, italicize levels\n  bold_labels() %>%\n  italicize_levels() %>%\n  # change stuff\n  modify_header(label ~ \"**Variable**\") %>% \n  modify_spanning_header(c(\"stat_1\", \"stat_2\") ~ \"**Mom High School**\") %>% \n  add_n()\n\n\nhtml {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#wxywdabygn .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#wxywdabygn .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#wxywdabygn .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#wxywdabygn .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 4px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#wxywdabygn .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#wxywdabygn .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#wxywdabygn .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#wxywdabygn .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#wxywdabygn .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#wxywdabygn .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#wxywdabygn .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#wxywdabygn .gt_group_heading {\n  padding: 8px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#wxywdabygn .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#wxywdabygn .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#wxywdabygn .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#wxywdabygn .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#wxywdabygn .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 12px;\n}\n\n#wxywdabygn .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#wxywdabygn .gt_first_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n}\n\n#wxywdabygn .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#wxywdabygn .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#wxywdabygn .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#wxywdabygn .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#wxywdabygn .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#wxywdabygn .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding: 4px;\n}\n\n#wxywdabygn .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#wxywdabygn .gt_sourcenote {\n  font-size: 90%;\n  padding: 4px;\n}\n\n#wxywdabygn .gt_left {\n  text-align: left;\n}\n\n#wxywdabygn .gt_center {\n  text-align: center;\n}\n\n#wxywdabygn .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#wxywdabygn .gt_font_normal {\n  font-weight: normal;\n}\n\n#wxywdabygn .gt_font_bold {\n  font-weight: bold;\n}\n\n#wxywdabygn .gt_font_italic {\n  font-style: italic;\n}\n\n#wxywdabygn .gt_super {\n  font-size: 65%;\n}\n\n#wxywdabygn .gt_footnote_marks {\n  font-style: italic;\n  font-size: 65%;\n}\nVariable\n      N\n      Overall, N = 434\n      \n        Mom High School\n      \n      p-value1\n    no, N = 93\n      yes, N = 341\n    kid_score\n      434.00\n      \n      \n      \n      <0.001\n    N\n      \n      434.00\n      93.00\n      341.00\n      \n    Median (IQR)\n      \n      90.00 (74.00, 102.00)\n      80.00 (58.00, 95.00)\n      92.00 (77.00, 103.00)\n      \n    Range\n      \n      20.00, 144.00\n      20.00, 136.00\n      38.00, 144.00\n      \n    mom_iq\n      434.00\n      \n      \n      \n      <0.001\n    N\n      \n      434.00\n      93.00\n      341.00\n      \n    Median (IQR)\n      \n      97.92 (88.66, 110.27)\n      88.66 (81.83, 99.16)\n      100.24 (90.45, 113.17)\n      \n    Range\n      \n      71.04, 138.89\n      74.23, 127.54\n      71.04, 138.89\n      \n    mom_age\n      434.00\n      \n      \n      \n      <0.001\n    N\n      \n      434.00\n      93.00\n      341.00\n      \n    Median (IQR)\n      \n      23.00 (21.00, 25.00)\n      21.00 (20.00, 24.00)\n      23.00 (21.00, 25.00)\n      \n    Range\n      \n      17.00, 29.00\n      17.00, 28.00\n      17.00, 29.00\n      \n    \n        \n          1\n          \n           \n          Statistical tests performed: Wilcoxon rank-sum test\n          \n      \n    \n\nTabela de Correlações\nPara as tabelas de correlações, eu uso o pacote sjPlot com a função sjPlot::tab_cor()\nOs astericos significam:\n* - \\(p < 0.05\\)\n** - \\(p < 0.01\\)\n*** - \\(p < 0.001\\)\n\n\nsjPlot::tab_corr(\n  kidiq %>% mutate(mom_hs = as.integer(mom_hs)),\n  digits = 2,\n  triangle = \"lower\"\n)\n\n\n\n \n\n\nkid_score\n\n\nmom_hs\n\n\nmom_iq\n\n\nmom_age\n\n\nkid_score\n\n\n \n\n\n \n\n\n \n\n\n \n\n\nmom_hs\n\n\n0.24***\n\n\n \n\n\n \n\n\n \n\n\nmom_iq\n\n\n0.45***\n\n\n0.28***\n\n\n \n\n\n \n\n\nmom_age\n\n\n0.09\n\n\n0.21***\n\n\n0.09\n\n\n \n\n\nComputed correlation used pearson-method with listwise-deletion.\n\n\nRegressão Linear Bayesiana\nVamos começar com o caso simples da Aula 2 - Regressão Linear\n\n\nmodel <- stan_glm(\n  kid_score ~ mom_hs + mom_iq,\n  data = kidiq\n  )\n\n\n\nTabela de Regressão Linear\nPara as tabelas de regressões eu geralmente uso o mesmo pacote sjPlot, mas agora com a função sjPlot::tab_model() que aceita um modelo bayesiano.\n\n\ntab_model(model, show.reflvl = TRUE)\n\n\n\n \n\n\nkid_score\n\n\nPredictors\n\n\nEstimates\n\n\nCI (95%)\n\n\n(Intercept)\n\n\n25.71\n\n\n13.81 – 37.02\n\n\nno\n\n\nReference\n\n\n\n\nyes\n\n\n5.92\n\n\n1.57 – 10.26\n\n\nmom_iq\n\n\n0.56\n\n\n0.45 – 0.69\n\n\nObservations\n\n\n434\n\n\nR2 Bayes\n\n\n0.215\n\n\nModelo de Regressão Binomial/Logística\nVamos utilizar o caso da Aula 6 - Regressão Binomial\n\n\nmodel_binomial <- stan_glm(\n  switch ~ dist + arsenic + assoc + educ,\n  data = wells,\n  family = binomial()\n)\n\n\n\nTabela de Regressão Binomial/Logística\nA função sjPlot::tab_model() quando aplicada à um modelo bayesiano linear generalizado (binomial, Poisson etc.) já faz a transformação necessária para uma melhor interpretação dos coeficientes.\nNo caso de modelos binomiais/logísticos geralmente é aplicada uma exponenciação (exp()) dos coeficientes para transformá-los em razões de probabilidades (odds ratio)\nCaso queira deixar os coeficientes brutos (raw coefficients) use transform = NULL\n\n\ntab_model(model_binomial, show.reflvl = TRUE)\n\n\n\n \n\n\nswitch\n\n\nPredictors\n\n\nOdds Ratios\n\n\nCI (95%)\n\n\n(Intercept)\n\n\n0.86\n\n\n0.70 – 1.04\n\n\narsenic\n\n\n1.60\n\n\n1.47 – 1.73\n\n\nassoc\n\n\n0.88\n\n\n0.76 – 1.03\n\n\ndist\n\n\n0.99\n\n\n0.99 – 0.99\n\n\neduc\n\n\n1.04\n\n\n1.02 – 1.06\n\n\nObservations\n\n\n3020\n\n\nR2 Bayes\n\n\n0.067\n\n\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.3 (2020-10-10)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n[1] sjPlot_2.8.6    gtsummary_1.3.5 rstanarm_2.21.1 Rcpp_1.0.5     \n[5] dplyr_1.0.2    \n\nloaded via a namespace (and not attached):\n  [1] TH.data_1.0-10       minqa_1.2.4          colorspace_2.0-0    \n  [4] ellipsis_0.3.1       ggridges_0.5.2       rsconnect_0.8.16    \n  [7] sjlabelled_1.1.7     snakecase_0.11.0     estimability_1.3    \n [10] markdown_1.1         parameters_0.10.1    base64enc_0.1-3     \n [13] rstan_2.21.2         DT_0.16              mvtnorm_1.1-1       \n [16] fansi_0.4.1          codetools_0.2-18     splines_4.0.3       \n [19] downlit_0.2.1        knitr_1.30           shinythemes_1.1.2   \n [22] sjmisc_2.8.5         bayesplot_1.7.2      jsonlite_1.7.2      \n [25] nloptr_1.2.2.2       ggeffects_1.0.1      gt_0.2.2            \n [28] broom_0.7.3          effectsize_0.4.1     shiny_1.5.0         \n [31] compiler_4.0.3       emmeans_1.5.3        backports_1.2.1     \n [34] sjstats_0.18.0       assertthat_0.2.1     Matrix_1.3-0        \n [37] fastmap_1.0.1        survey_4.0           cli_2.2.0           \n [40] later_1.1.0.1        htmltools_0.5.0      prettyunits_1.1.1   \n [43] tools_4.0.3          igraph_1.2.6         coda_0.19-4         \n [46] gtable_0.3.0         glue_1.4.2           reshape2_1.4.4      \n [49] V8_3.4.0             vctrs_0.3.6          nlme_3.1-151        \n [52] crosstalk_1.1.0.1    insight_0.11.1       xfun_0.19           \n [55] stringr_1.4.0        ps_1.5.0             lme4_1.1-26         \n [58] mime_0.9             miniUI_0.1.1.1       lifecycle_0.2.0     \n [61] gtools_3.8.2         statmod_1.4.35       MASS_7.3-53         \n [64] zoo_1.8-8            scales_1.1.1         colourpicker_1.1.0  \n [67] promises_1.1.1       sandwich_3.0-0       parallel_4.0.3      \n [70] inline_0.3.17        shinystan_2.5.0      yaml_2.2.1          \n [73] curl_4.3             gridExtra_2.3        ggplot2_3.3.3       \n [76] sass_0.2.0           loo_2.4.1            StanHeaders_2.21.0-7\n [79] distill_1.1          stringi_1.5.3        bayestestR_0.8.0    \n [82] dygraphs_1.1.1.6     checkmate_2.0.0      boot_1.3-25         \n [85] pkgbuild_1.2.0       commonmark_1.7       rlang_0.4.10        \n [88] pkgconfig_2.0.3      matrixStats_0.57.0   evaluate_0.14       \n [91] lattice_0.20-41      purrr_0.3.4          rstantools_2.1.1    \n [94] htmlwidgets_1.5.3    processx_3.4.5       tidyselect_1.1.0    \n [97] plyr_1.8.6           magrittr_2.0.1       R6_2.5.0            \n[100] generics_0.1.0       multcomp_1.4-15      DBI_1.1.0           \n[103] pillar_1.4.7         withr_2.3.0          xts_0.12.1          \n[106] survival_3.2-7       tibble_3.0.4         performance_0.6.1   \n[109] modelr_0.1.8         crayon_1.3.4         rmarkdown_2.6       \n[112] grid_4.0.3           callr_3.5.1          forcats_0.5.0       \n[115] threejs_0.3.3        digest_0.6.27        xtable_1.8-4        \n[118] tidyr_1.1.2          httpuv_1.5.4         RcppParallel_5.0.2  \n[121] stats4_4.0.3         munsell_0.5.0        mitools_2.4         \n[124] shinyjs_2.0.0       \n\n\n\n\n",
      "last_modified": "2021-01-03T04:53:16-03:00"
    },
    {
      "path": "index.html",
      "title": "Estatística Bayesiana com R e RStan",
      "description": "Companion para a disciplina de Estatística Bayesiana para alunos de Mestrado e Doutorado da UNINOVE\n",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "August 2, 2020",
      "contents": "\n\nContents\nAulas\nO que esta disciplina não é\nRStudio na Núvem Gratuito\nProfessor\nComo usar esse conteúdo?\nReferências\nLivros\nArtigos\n\nLicença\n\n\n\nA Estatística Bayesiana é uma abordagem de Estatística inferencial que não usa hipóteses nulas (\\(H_0\\)) e \\(p\\)-valores. Se você não sabe o que é um \\(p\\)-valor, recomendo olhar o tutorial sobre o que são \\(p\\)-valores. Muitos cientistas e pesquisadores acreditam que sabe o que é um \\(p\\)-valor, mas sua compreensão é falha e imperfeita, por isso, mesmo que você acredite que saiba o que é um \\(p\\)-valor, eu ainda recomendo que veja o tutorial sobre o que são \\(p\\)-valores.\nAulas\nConteúdos Primários:\nComandos Básicos de R\nRegressão Linear Bayesiana\nDistribuições Estatísticas\nPriors\nMarkov Chain Montecarlo (MCMC)\nRegressão Binomial Bayesiana\nRegressão de Poisson Bayesiana\nRegressão Robusta Bayesiana\nModelos Multiníveis\nConteúdos Auxiliares:\nDados Faltantes\nCoeficientes de uma Regressão\nTabelas para Publicação\nO que esta disciplina não é\nNão será coberto conteúdos sobre leitura, manipulação e exportação de dados com R. Para isso recomendo fortemente o livro R para Data Science que pode ser encontrado gratuitamente aqui e possui uma versão impressa em português.\n\nRStudio na Núvem Gratuito\nClique no ícone abaixo para abrir uma sessão do RStudio no Projeto Binder.\n\nProfessor\nProf. Dr. José Eduardo Storopoli    \njosees@uni9.pro.br\nComo usar esse conteúdo?\nEste conteúdo possui licença livre para uso (CC BY-SA). Caso queira utilizar o conteúdo para um curso ou estudos, por favor colabore nesse repositório quaisquer aprimorações que foram realizadas.\nPara configurar um ambiente local:\nClone o repositório do GitHub: git clone https://github.com/storopoli/Estatistica-Bayesiana.git\nAcesse o diretório: cd Estatistica-Bayesiana\nInstale os pacotes necessários: Rscript install.R\nReferências\nLivros\nGelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian data analysis. Chapman and Hall/CRC.\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan. CRC press.\nGelman, A., Hill, J., & Vehtari, A. (2020). Regression and other stories. Cambridge University Press.\nArtigos\nBenjamin, D. J., Berger, J. O., Johannesson, M., Nosek, B. A., Wagenmakers, E.-J., Berk, R., … Johnson, V. E. (2018). Redefine statistical significance. Nature Human Behaviour, 2(1), 6–10. https://doi.org/10.1038/s41562-017-0189-z\nCarpenter, B., Gelman, A., Hoffman, M. D., Lee, D., Goodrich, B., Betancourt, M., … Riddell, A. (2017). Stan : A Probabilistic Programming Language. Journal of Statistical Software, 76(1). https://doi.org/10.18637/jss.v076.i01\nEtz, A. (2018). Introduction to the Concept of Likelihood and Its Applications. Advances in Methods and Practices in Psychological Science, 1(1), 60–69. https://doi.org/10.1177/2515245917744314\nEtz, A., Gronau, Q. F., Dablander, F., Edelsbrunner, P. A., & Baribault, B. (2018). How to become a Bayesian in eight easy steps: An annotated reading list. Psychonomic Bulletin and Review, 25(1), 219–234. https://doi.org/10.3758/s13423-017-1317-5\nGeyer, C. J. (2011). Introduction to markov chain monte carlo. In S. Brooks, A. Gelman, G. L. Jones, & X.-L. Meng (Eds.), Handbook of markov chain monte carlo.\nMcShane, B. B., Gal, D., Gelman, A., Robert, C., & Tackett, J. L. (2019). Abandon Statistical Significance. American Statistician, 73(sup1), 235–245. https://doi.org/10.1080/00031305.2018.1527253\nvan Ravenzwaaij, D., Cassey, P., & Brown, S. D. (2018). A simple introduction to Markov Chain Monte–Carlo sampling. Psychonomic Bulletin and Review, 25(1), 143–154. https://doi.org/10.3758/s13423-016-1015-8\nVandekerckhove, J., Matzke, D., Wagenmakers, E.-J., & others. (2015). Model comparison and the principle of parsimony. In J. R. Busemeyer, Z. Wang, J. T. Townsend, & A. Eidels (Eds.), Oxford handbook of computational and mathematical psychology (pp. 300–319). Oxford University Press Oxford.\nVan de Schoot, R., Kaplan, D., Denissen, J., Asendorpf, J. B., Neyer, F. J., & van Aken, M. A. G. (2014). A Gentle Introduction to Bayesian Analysis: Applications to Developmental Research. Child Development, 85(3), 842–860. https://doi.org/10.1111/cdev.12169\nWagenmakers, E.-J. (2007). A practical solution to the pervasive problems of p values. Psychonomic Bulletin & Review, 14(5), 779–804. https://doi.org/10.3758/BF03194105\nLicença\nEste obra está licenciado com uma Licença Creative Commons Atribuição-CompartilhaIgual 4.0 Internacional.\n\n\n\n\n",
      "last_modified": "2021-01-03T04:52:40-03:00"
    },
    {
      "path": "pvalores.html",
      "title": "p-Valores, Hipótese Nula e Pressupostos",
      "description": "Porque $p$-valor, hipótese nula e pressupostos são importantes.\n",
      "author": [
        {
          "name": "Jose Storopoli",
          "url": "https://scholar.google.com/citations?user=xGU7H1QAAAAJ&hl=en"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nEstatística Inferencial\n\\(p\\)-valor e Hipótese Nula \\(H_0\\)\nAlgumas questões históricas\nO que o \\(p\\)-valor não é\nIntervalos de Confiança\nSignificância Estatística vs Significância Prática\n\nErro Tipo I e Erro Tipo II\nTamanho da Amostra\nE aonde entra a Estatística Bayesiana?\nComentários Finais\nAmbiente\n\n\nEsse conteúdo foi criado com o intuito de despertar o leitor para a importância da Estatística para a ciência e geração de conhecimento. Nossa ideia é apresentar conceitos da maneira que gostaríamos de ter sido apresentados quando alunos prestes a serem iniciados na ciência. Nossa abordagem é simplificar os conceitos o máximo possível sem perder a sua essência. E, quando necessário, aliando-os com sua trajetória histórica para compreensão do “porque as coisas são como são.” Não estamos atrás de formalismo matemático, mas sim de conseguir desenvolver uma intuição clara do que é cada conceito, quando se deve usá-lo e quais são os principais cuidados que se deve ter.\nA estatística é dividida em duas partes:\nEstatística Descritiva: Sumariza e quantifica as características de uma amostra de dados observados. Métricas comuns são: média, mediana, moda, desvio padrão, variância, correlação, percentis.\nEstatística Inferencial: Permite gerar inferências (afirmações) a partir de um conjunto de uma amostra de dados observados sobre real processo de geração de dados (população). Há diversas maneiras de se gerar tais inferências, mas os principais são os testes de hipóteses clássicos que usam uma hipótese nula \\(H_0\\) pré-especificada. A figura 1 mostra a relação entre dados observados e o processo de geração de dados sob a ótica da probabilidade e da estatística.\n\n\n\n{\"x\":{\"diagram\":\"\\n digraph estatistica_inferencial {\\n  forcelabels = true;\\n  graph [overlap = false,\\n         fontsize = 12,\\n         rankdir = TD]\\n  node [shape = oval,\\n        fontname = Helvetica]\\n  A [label = \\\"Processo de\\nGeração de Dados\\\"]\\n  B [label = \\\"Dados\\nObservados\\\"]\\n  A -> B [dir = forward,\\n          xlabel = \\\"  Probabilidade  \\\",\\n          tailport = \\\"e\\\",\\n          headport = \\\"e\\\"]\\n  B -> A [dir = backward,\\n          label = \\\"  Inferência  \\\",\\n          tailport = \\\"w\\\",\\n          headport = \\\"w\\\"]\\n} \\n\",\"config\":{\"engine\":\"dot\",\"options\":null}},\"evals\":[],\"jsHooks\":[]}\nFigure 1: Estatística Inferencial\n\n\n\nEstatística Inferencial\nO nosso intuito nesse conjunto de tutoriais é focar na Estatística inferencial, porque, ao contrário da Estatística descritiva, a Estatística inferencial é raramente compreendida ao ponto do usuário e consumidor estarem aptos à realizar e consumir análises, respectivamente.\nA Estatística inferencial têm suas origens no final do século XIX, especialmente no trabalho de Karl Pearson1 e se baseia em um conjunto de técnicas e procedimentos para testar hipóteses sobre uma amostra generalizando para uma população-alvo.\n\n\n\nFigure 2: Karl Pearson. Figura de https://www.wikipedia.org\n\n\n\nA chave para compreesão da Estatística inferencial se baseia em entender os testes de hipóteses, também chamado de testes estatísticos. Todos testes estatísticos2 segue o mesmo padrão universal (Downey, 2016):\nCalculamos uma estatística da amostra. Aqui estatística (em letras minúsculas) significa uma medida dos dados. Para fins de exemplo vamos chamar essa medida de \\(\\delta\\) (letra gregra delta). Essa é a medida que mais nos importamos: uma diferença de média, mediana ou proporções, entre outras…\nContrastamos essa estatística observada com uma estatística computada se o efeito fosse nulo. Em outras palavras, o que observamos é comparado com o resultado que esperaríamos caso estívessemos vivendo em um mundo no qual essa medida (diferença de média, mediana ou proporções, …) fosse nula (zero). Geralmente esse universo paralelo no qual o efeito observado é zero ou nulo é chamado de Hipótese Nula e é representada com o seguinte símbolo \\(H_0\\). A estatística \\(\\delta\\) no mundo da \\(H_0\\) não é calculada, mas sim dada por um valor que fora matematicamente provado como o valor de \\(\\delta\\) no mundo da \\(H_0\\). Vamos chamar esse valor de \\(\\delta_0\\)\nCalculamos a probabidalide de obtermos algo como \\(\\delta\\) no mundo da \\(H_0\\): chamamos isso de \\(p\\)-valor. O \\(p\\)-valor é a probabilidade de observarmos um \\(\\delta\\) no mínimo tão grande quanto o observado num mundo no qual não há o efeito \\(\\delta\\). Ou seja \\(\\delta = 0\\), e consequentemente \\(\\delta = \\delta_0\\). Como sabemos do valor \\(\\delta_0\\) de antemão, basta compararmos o nosso \\(\\delta\\) com \\(\\delta_0\\) para gerar o \\(p\\)-valor. Por isso que muitos livros de Estatística possuem um vasto arsenal de tabelas. O leitor pode facilmente ver o seu \\(\\delta\\) e com alguns dados sobre a amostra, em especial o número da amostra, obter o \\(\\delta_0\\) e \\(p\\)-valor respectivos.\nDecidimos se \\(\\delta\\) possui significância estatística. Escolhemos um limiar de rejeição da \\(H_0\\), muitas vezes chamado de \\(\\alpha\\) (letra gregra alpha). Esse limiar será o nosso critério de decisão se há evidências suficientes para rejeitarmos o mundo da \\(H_0\\).\nEste paradigma descrito nos quatro passos acima é chamado de Null Hypothesis Significance Testing – NHST (tradução: teste de significância de hipótese nula) e é o que predomina em grande parte da ciência do passado e atual.\nUma segunda chave para a compreensão da Estatística inferencial possui razões históricas. As técnicas de Estatística inferencial clássicas são em grande parte um mecanismo técnico de aproximações numéricas baseadas na distribuição Normal e suas muitas engrenagens subsidiárias. Essa máquina já foi necessária, porque a alternativa conceitualmente mais simples baseada em permutações estava computacionalmente além de nosso alcance3. Antes dos computadores, os estatísticos não tinham escolha (Cobb, 2007).\n\nQuem ficou curioso com a história da Estatística. Recomendo um livro de Stephen Stigler intitulado Statistics on the Table: The History of Statistical Concepts and Methods. O primeiro autor comprou uma cópia em um sebo online.\n\\(p\\)-valor e Hipótese Nula \\(H_0\\)\n\n\\(p\\)-valores são de difícil entendimento, \\(p < 0.05\\).\n\n\n\n\nSem dúvida, esta parte da Estatística inferencial é a mais complicada e menos intuitiva. Parafraseando Andrew Gelman, estatístico da Columbia University, “Para definir \\(p\\)-valores, escolha uma das duas características: intuitiva ou precisa. Ou sua definição é intuitiva mas imprecisa, ou sua definição é precisa mas não intuitiva.” A grande maioria dos pesquisadores4 possui uma definição incorreta do que é um \\(p\\)-valor (Cumming, 2009). E quando vemos evidências do campo da medicina, que talvez seja o campo com maior quantidade de recursos disponíveis para pesquisa e avanço do conhecimento, também encontramos muitos problemas no uso dos \\(p\\)-valores (Ioannidis, 2019). Antes de entrarmos nas definições de \\(p\\)-valores, vale a pena tranquilizá-los: \\(p\\)-valores são uma coisa complicada e se você não entender na primeira vez que ler as definições abaixo, não se preocupe, você não estará em má companhia; respire fundo e tente ler mais uma vez.\nPrimeiramente a definição estatística:\n\n\\(p\\)-valor é a probabilidade de obter resultados no mínimo tão extremos quanto os que foram observados, dado que a hipótese nula \\(H_0\\) é verdadeira.\n\nSe você escrever essa definição em qualquer prova, livro ou artigo científico, você estará 100% preciso e correto na definição do que é um \\(p\\)-valor. Agora, a compreensão dessa definição é algo complicado. Para isso, vamos quebrar essa definição em algumas partes para melhor compreensão:\n“probabilidade de obter resultados…”: vejam que \\(p\\)-valores são uma característica dos seus dados e não da sua teoria ou hipótese.\n“…no mínimo tão extremos quanto os que foram observados…”: “no minimo tão” implica em definir um limiar para a caracterização de algum achado relevante, que é comumente chamado de \\(\\alpha\\). Geralmente estipulamos alpha em 5% (\\(\\alpha = 0.05\\)) e qualquer coisa mais extrema que alpha (ou seja menor que 5%) caracterizamos como significante5.\n“..dado que a hipótese nula é verdadeira…”: Todo teste estatístico que possui um \\(p\\)-valor possui uma Hipótese Nula (geralmente escrita como \\(H_0\\)). Hipótese nula, sempre tem a ver com algum efeito nulo. Por exemplo, a hipótese nula do teste Shapiro-Wilk e Komolgorov-Smirnov é “os dados são distribuídos conforme uma distribuição Normal” e a do teste de Levene é “as variâncias dos dados são iguais.” Sempre que ver um \\(p\\)-valor, se pergunte: “Qual a hipótese nula que este teste presupõe correta?6”\nPara entender o \\(p\\)-valor qualquer teste estatístico primeiro descubra qual é a hipótese nula por trás daquele teste. A definição do \\(p\\)-valor não mudará. Em todo teste ela é sempre a mesma. O que muda com o teste é a hipótese nula. Cada teste possui sua \\(H_0\\).\n\n\n\n\\(p\\)-valor é a probabilidade dos dados que você obteve dado que a hipótese nula é verdadeira. Para os que gostam do formalismo matemático: \\(p = P(D|H_0)\\). Em português, essa expressão significa “a probabilidade de \\(D\\) condicionado à \\(H_0\\).” Antes de avançarmos para alguns exemplos e tentativas de formalizar uma intuição sobre os \\(p\\)-valores, é importante ressaltar que \\(p\\)-valores dizem algo à respeito dos dados e não de hipóteses. Para o \\(p\\)-valor, a hipótese nula é verdadeira, e estamos apenas avaliando se os dados se conformam à essa hipótese nula ou não. Se vocês saírem desse tutorial munidos com essa intuição, o mundo será agraciado com pesquisadores mais preparados para qualificar e interpretar evidências (\\(p < 0.05\\)).\nExemplo intuitivo:\n\nImagine que você tem uma moeda que suspeita ser enviesada para uma probabilidade maior de dar cara. (Sua hipótese nula é então que a moeda é justa.) Você joga a moeda 100 vezes e obtém mais cara do que coroa. O \\(p\\)-valor não dirá se a moeda é justa, mas dirá a probabilidade de você obter pelo menos tantas caras quanto se a moeda fosse justa. É isso - nada mais.\n\n\nApesar de termos falado anterior que definições intuitivas não são precisas, elas sem dúvida facilitam o entendimento do \\(p\\)-valor.\nAlgumas questões históricas\nNão tem como entendermos \\(p\\)-valores se não compreendermos as suas origens e trajetória histórica. A primeira menção do termo foi feita pelo estatístico Ronald Fisher7 em 1925 (Fisher, 1925) que define o \\(p\\)-valor como um “índice que mede a força da evidência contra a hipótese nula.” Para quantificar a força da evidência contra a hipótese nula, Fisher defendeu “\\(p<0.05\\) (5% de significância) como um nível padrão para concluir que há evidência contra a hipótese testada, embora não como uma regra absoluta.” Fisher não parou por aí mas classificou a força da evidência contra a hipótese nula. Ele propôs “se \\(p\\) está entre 0.1 e 0.9, certamente não há razão para suspeitar da hipótese testada. Se estiver abaixo de 0.02, é fortemente indicado que a hipótese falha em explicar o conjunto dos fatos. Não seremos frequentemente perdidos se traçarmos uma linha convencional de 0.05” Desde que Fisher fez esta declaração há quase 100 anos, o limiar de 0.05 foi usado por pesquisadores e cientistas em todo o mundo e tornou-se ritualístico usar 0.05 como limiar como se outros limiares não pudessem ser usados.\n\n\n\nFigure 3: Ronald Fisher. Figura de https://www.wikipedia.org\n\n\n\nApós isso, o limiar de 0.05 agora instaurado como inquestionável influenciou fortemente a estatística e a ciência. Mas não há nenhuma razão contra a adoção de outros limiares (\\(\\alpha\\)) como 0.1 ou 0.01. Se bem argumentados, a escolha de limiares diferentes de 0.05 pode ser bem-vista por editores, revisores e orientadores. Como o \\(p\\)-valor é uma probabilidade, ele não é um quantidade contínua. Não há razão para diferenciarmos um \\(p\\) de 0.049 contra um \\(p\\) de 0.051. Robert Rosenthal, um psicólogo já dizia “Deus ama \\(p\\) de 0.06 tanto quanto um \\(p\\) de 0.05” (Rosnow & Rosenthal, 1989).\n\n\n\nO que o \\(p\\)-valor não é\nCom a definição e intuição do que é um \\(p\\)-valor bem ancoradas, podemos avançar para o que o \\(p\\)-valor não é!\n\n\n\n\\(p\\)-valor não é a probabilidade da Hipótese nula - Famosa confusão entre \\(P(D|H_0)\\) e \\(P(H_0|D)\\). \\(p\\)-valor não é a probabilidade da hipótese nula, mas sim a probabilidade dos dados que você obteve. Por exemplo: a probabilidade de você tossir dado que você está com COVID é diferente da probabilidade de você estar com COVID dado que você tossiu: \\(P(\\text{tosse} | \\text{COVID}) \\neq P(\\text{COVID} | \\text{tosse})\\). Acredito que a primeira, \\(P(\\text{tosse} | \\text{COVID})\\) é bem alta, enquanto a segunda, \\(P(\\text{COVID} | \\text{tosse})\\) deve ser bem baixa (afinal tossimos a todo momento).\n\nO primeiro autor tentou explicar essa diferença para uma senhora que o viu tossir na fila do mercado, mas os seus esforços foram em vão…\n\\(p\\)-valor não é a probabilidade dos dados serem produzidos pelo acaso - Não! Ninguém falou nada de acaso. Mais uma vez: \\(p\\)-valor é probabilidade de obter resultados no mínimo tão extremos quanto os que foram observados, dado que a hipótese nula é verdadeira.\n\\(p\\)-valor mensura o tamanho do efeito de um teste estatístico - Também não… \\(p\\)-valor não diz nada sobre o tamanho do efeito. Apenas sobre se o quanto os dados observados divergem do esperado sob a hipótese nula. É claro que efeitos grandes são mais prováveis de serem estatisticamente significantes que efeitos pequenos. Mas isto não é via de regra e nunca julguem um achado pelo seu \\(p\\)-valor, mas sim pelo seu tamanho de efeito. Além disso, \\(p\\)-valores podem ser “hackeados” de diversas maneiras (Head, Holman, Lanfear, Kahn, & Jennions, 2015) e muitas vezes seu valor é uma consequência direta do tamanho da amostra. Mais sobre isso no conteúdo auxiliar sobre tamanho de amostra.\nIntervalos de Confiança\nIntervalos de confiança foram criados como uma solução para os problemas de má-interpretação dos \\(p\\)-valores e sua aplicação se destina ao tamanho do efeito. Se você achou \\(p\\)-valor confuso, se prepare! Intervalos de confiança são ainda mais confusos e muitos pesquisadores e cientistas também não possuem a compreensão correta (Hoekstra, Morey, Rouder, & Wagenmakers, 2014)8…Vamos para a definição estatística do idealizador dos intervalos de confiança, Jerzy Neyman, em 1937 (Neyman, 1937):\n\n“Um intervalo de confiança de X% para um parâmetro é um intervalo (a, b) gerado por um procedimento que em amostragem repetida tem uma probabilidade de X% de conter o valor verdadeiro do parâmetro, para todos os valores possíveis do parâmetro.”9 (Neyman, 1937)\n\nMais uma vez vamos quebrar essa definição em em algumas partes para melhor compreensão:\n“… intervalo (a,b) …”: intervalo de confiança sempre serão expressados como um intervalo \\(a\\) - \\(b\\), onde \\(a\\) é menor que \\(b\\) (\\(a < b\\)).\n“… gerado por um procedimento que em amostragem repetida…”: aqui estamos falando de população. E o que você geralmente tem nas suas mãos quando está fazendo uma análise estatística é uma amostra. Uma população é um conjunto de pessoas, itens ou eventos sobre os quais você quer fazer inferências. Uma amostra é um é um subconjunto de pessoas, itens ou eventos de uma população maior que você coleta e analisa para fazer inferências. Geralmente o tamanho da amostra é bem menor que o tamanho da população. Então, intervalos de confiança expressam a frequência de longo-prazo que vocês esperaria obter de um tamanho de efeito caso replicasse o teste estatístico para diversas amostras da MESMA população.\n“… tem uma probabilidade de X% de conter o valor verdadeiro do parâmetro, para todos os valores possíveis do parâmetro.”: os intervalos de confiança sempre serão expressados acompanhados de uma probabilidade (algo entre 0.001% e 99.999%) que quantifica a certeza de encontrar o intervalo em uma replicações do teste estatístico para diversas amostras da MESMA população.\nPor exemplo: digamos que você executou uma análise estatística para comparar eficácia de uma política pública em dois grupos e você obteve a diferença entre a média desses grupos. Você pode expressar essa diferença como um intervalo de confiança. Geralmente escolhemos a confiança de 95% (sim, está relacionado com o 0.05 do \\(p\\)-valor). Você então escreve no seu artigo que a “diferença entre grupos observada é de 10.5 - 23.5 (95% IC).” Isso quer dizer que 95 estudos de 100, que usem o mesmo tamanho de amostra e população-alvo, aplicando o mesmo teste estatístico, esperarão encontrar um resultado de diferenças de média entre grupos entre 10.5 e 23.5. Aqui as unidades são arbitrárias, mas para continuar o exemplo vamos supor que sejam espectativa de vida.\nFalácias\nEm um artigo bem controverso, Morey, Hoekstra, Rouder, Lee, & Wagenmakers (2016) mostram as três grandes falácias (qualquer enunciado ou raciocínio falso que entretanto simula a veracidade) dos intervalos de confiança (a tradução é livre e feita por nós):\nA falácia fundamental dos intervalos de confiança: Um intervalo de confiança de X% para um parâmetro é um intervalo (a, b) gerado por um procedimento que na amostragem repetida tem uma probabilidade de X% de conter o valor verdadeiro do parâmetro, para todos os valores possíveis do parâmetro. probabilidade de que um intervalo aleatório contém o valor verdadeiro é X%, então a plausibilidade ou probabilidade de que um determinado intervalo observado contém o valor verdadeiro também é X%; ou, alternativamente, podemos ter X% de confiança de que o intervalo observado contém o valor real10.\nA falácia da precisão: A largura de um intervalo de confiança indica a precisão de nosso conhecimento sobre o parâmetro. Intervalos de confiança estreitos correspondem a conhecimentos precisos, enquanto erros de confiança amplos correspondem a conhecimentos imprecisos11.\nA falácia da probabilidade: Um intervalo de confiança contém os valores prováveis para o parâmetro. Os valores dentro do intervalo de confiança são mais prováveis do que os externos. Essa falácia existe em várias variedades, às vezes envolvendo plausibilidade, credibilidade ou razoabilidade de crenças sobre o parâmetro12.\nNote que todas essas três falácias estão erradas e são uma compreensão errônea ou incompleta de intervalos de confiança.\nRelação entre intervalos de confiança e \\(p\\)-valores\nIntervalos de confiança estão profundamente relacionados com \\(p\\)-valores. Primeiro, para que uma estimativa tenha um \\(p\\)-valor menor que 0.05, seu intervalo de confiança 95% não pode capturar o zero. Ou seja, o intervalo não pode compreender o efeito nulo (Hipótese Nula - \\(H_0\\)). Isso segue para outros valores de \\(p\\) correspondentes com outros níveis de confiança dos intervalos. Por exemplo, para uma estimativa com \\(p\\)-valor menor que 0.01, seu intervalo de confiança 99% não pode capturar o 0. Além disso, intervalos de confiança (assim como \\(p\\)-valores) estão intrinsicamente conectados com o tamanho da amostra. Quanto maior o tamanho de amostra, mais estreito será o intervalo de confiança. A intuição por trás disso é que conforme a sua amostra aumenta, também aumentarão a sua confiança e precisão em inferências sobre a população-alvo. Por fim, intervalos de confiança (assim como \\(p\\)-valores) não falam nada sobre a sua teoria ou hipótese, mas sobre a relação dos seus dados (amostra) com a população-alvo. Eles não são a probabilidade do parâmetro estimado (\\(P(\\text{parâmetro} | D)\\), no nosso exemplo diferença entre médias de grupos), mas sim a probabilidade de amostras com o mesmo parâmetro estimado (\\(P(D | \\text{parâmetro})\\)).\nUma boa maneira de resumir \\(p\\)-valores e intervalos de confiança é a seguinte:\n\nConsidere \\(p\\)-valores algo que mensura a possibilidade de existir um efeito ou não e intervalos de confiança quantificam o tamanho desse efeito.\n\n\nMas sempre se atente nas definições. Lembre-se que se tentarmos ser intuitivos com \\(p\\)-valores e intervalos de confiança não seremos precisos nas definições.\nSignificância Estatística vs Significância Prática\n\nConsidere isso uma introdução rápida à \\(p\\)-hacking.\nPara encerrar esse tour de \\(p\\)-valores e intervalos de confiança, temos que nos atentar que significância estatística não é a mesma coisa que significância prática. Significância estatística é se algum achado de um teste/modelo estatístico diverge o suficiente da hipótese nula e, sendo que hipótese nula sempre são sobre efeitos ou diferenças nulas, podemos afirmar que significância estatística quer dizer um achado é diferente de um efeito nulo. Diversos testes da Estatística inferencial clássica quando submetidos à amostras grandes13 vão detectar uma diferença significante, mesmo que praticamente insignificante. Com uma amostra suficientemente grande nós conseguimos gerar \\(p\\)-valores significantes para diferenças minúsculas, como por exemplo uma diferença de 0.01cm altura entre dois grupos de uma amostra.\nPor isso que defendemos que nunca se interprete análises estatísticas somente com \\(p\\)-valores, mas sempre em conjunto com os intervalos de confiança que quantificam o tamanho do efeito. Nunca gere argumentos sobre evidências somente a partir de significância estatística, sempre inclua tamanho do efeito.\nErro Tipo I e Erro Tipo II\nNa Estatística inferencial temos dois erros possíveis quando estamos realizando um teste estatístico contra uma hipótese nula.\nErro tipo I, também chamado de “falso positivo”, é a chance de rejeitarmos a hipótese nula quando ela é verdadeira. Esse erro é o alpha \\(\\alpha\\) que é usado como limiar de significância do \\(p\\)-valor.\nErro tipo II, também chamado de “falso negativo”, é a chance de não rejeitarmos a hipótese nula quando ela é falsa. Esse erro é identificado como a letra grega beta \\(\\beta\\). Além disso, o poder de um teste estatístico é mensurado como \\(1 - \\beta\\). O poder de um teste estatístico aumenta proporcionalmente ao tamanho amostral. Quanto maior a amostra, maior o poder do teste.\n\nEsses conceitos foram criados por matemáticos, então a nomenclatura erro tipo I e erro tipo II é perfeita matematicamente, pois no contexto de testes estatísticos contra uma hipótese nula só existem dois tipos de erros. Mas para o ensino da Estatística e comunicação de incertezas é péssima. Sempre que possível optamos por usar termos como “falso positivo” e “falso negativo” ao invés de erro tipo I e erro tipo II.\n\n\n\nPor questões históricas, o erro tipo I14 foi considerado mais importante de ser controlado do que o erro tipo II. Portanto, quase todos os testes de hipótese nula focam no controle dos “falsos positivos” enquanto o controle dos “falsos negativos” são colocados em segundo plano. No mundo ideal, tanto \\(\\alpha\\) quando \\(\\beta\\) devem ser reduzidos o máximo possível. Isto requer um tamanho amostral frequentemente maior do que os recursos disponíveis para o pesquisador, portanto é comum pesquisadores usarem um \\(\\alpha\\) de 5% e um \\(\\beta\\) de 20% (poder de 80%).\nTamanho da Amostra\nA maioria dos testes estatísticos que computam um \\(p\\)-valor são extremamente sensíveis a tamanho da amostra. A hipótese nula sempre representa a ausência de qualquer efeito e nunca a diferença observada na amostra é igual a zero. Sempre há algum digito, menor que seja, que faz com que a diferença seja diferente de zero, ex: 0.00001. Quanto maior o tamanho da amostra maior a probabilidade de obtermos um \\(p\\)-valor significante, pois ele indica que o efeito é diferente de zero, mesmo que essa diferença seja insignificante do ponto de vista prático. Em certos contextos, defendemos que o \\(p\\)-valor é uma aproximação (proxy) de tamanho da amostra.\n\n\n\nE aonde entra a Estatística Bayesiana?\nA Estatística Frequentista15 se baseia em realizarmos testes de hipóteses sempre comparando os dados disponíveis com um cenário hipótetico de efeito nulo – \\(H_0\\):\n\\[P(D | H_0)\\]\nO resultado dessa probabilidade é o \\(p\\)-valor: a probabilidade dos dados obtidos condicionado à hipótese nula ser verdadeira. E se quisermos a probabilidade da hipótese nula16 e não dos dados obtidos?\nPara isso temos que “inverter” a probabilidade. Estamos interessados em:\n\\[P(H_0 | D)\\] Isso somente pode ser feito com o teorema de Bayes. Generalizando de \\(H_0\\) para qualquer \\(H\\), o teorema de Bayes nos permite “inverter” a probabilidade condicional:\n\\[P(H | D)=\\frac{P(H) \\cdot P(D | H)}{P(D)}\\] Aqui temos as seguintes probabilidades (note que podemos trocar \\(H\\) aqui para qualquer parâmetro \\(\\theta\\)):\n\\(P(H|D)\\) – probabilidade posterior de \\(H\\) depois de observamos os dados \\(D\\).\n\\(P(H)\\) – probabilidade prévia de \\(H\\) antes de observarmos os dados \\(D\\).\n\\(P(D|H)\\) – probabilidade dos dados obtidos sob a hipótese \\(H\\), também chamada de verossimilhança (do inglês likelihood).\n\\(P(D)\\) – chamada de evidência ou verossimilhança marginal (do inglês marginal likelihood), é a probabilidade geral dos dados de acordo com o modelo, determinada pela média de todos os valores de hipóteses ou paramêtros possíveis ponderados pela força da crença nesses valores de hipóteses ou parâmetros. Para hipóteses valores discretos de parâmetros: \\(P(D) = \\sum_\\theta P(D|H_0) P(H_0)\\). Já para valores contínuos de parâmetros: \\(P(D) = \\int_\\theta P(D|\\theta) P(\\theta) d \\theta\\). Em outras palavras, tome a probabilidade média \\(P(D|\\theta)\\) em todos os valores de \\(\\theta\\), ponderada pela probabilidade anterior de \\(\\theta\\) - \\(P(\\theta)\\). A única função de \\(P(D)\\) é garantir que a probabilidade posterior \\(P(H|D)\\) seja válida (algo entre 0 e 1).\nPortanto, a Estatística Bayesiana é qualquer técnica inferencial caracterizada pelo uso de informação prévia embutida como probabilidade prévia \\(P(H)\\). Nós não usamos \\(p\\)-valores nem intervalo de confiança, pois o conceito de hipótese nula é inexistente. Você pode especificar qualquer hipótese que queria, não necessariamente uma hipótese nula. Aqui temos o conceitos de probabilidade posterior de uma hipótese ou parâmetro ao invés de \\(p\\)-valores e também o conceito de intervalos de credibilidade que, ao invés de intervalos de confiança, nos dão a probabilidade de um parâmetro estar entre um intervalo de valores (muito mais intuitivo e simples de usar que um intervalo de confiança).\nComentários Finais\nSim, \\(p\\)-valores, intervalos de confiança, hipóteses nulas são conceitos complexos e muitos pesquisadores e cientistas não possuem a compreensão mínima necessária para a prática de Estatística inferencial. Acreditamos que a ciência (e a sociedade como um todo) se beneficiará de um maior número de cidadãos e pesquisadores que consigam avaliar, quantificar e qualificar evidências científicas. O paradigma da evidência científica atual (e, acreditamos que perdurará assim por bastante tempo) é o NHST e, apesar de termos algumas alternativas – como a Estatística Bayesiana – NHST irá predominar em boa parte da ciência pelas próximas décadas. Por isso, caro leitor, saiba que com “grandes poderes, vêm grandes responsabilidades.” Não deixe alguém torturar dados em práticas anti-éticas de \\(p\\)-hacking ou fundamentarem seus argumentos em compreensões incorretas de \\(p\\)-valor e \\(H_0\\).\n\n\n\nAmbiente\n\n\nsessionInfo()\n\n\nR version 4.0.3 (2020-10-10)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods  \n[7] base     \n\nother attached packages:\n [1] DiagrammeR_1.0.6.1 sjPlot_2.8.6       gtsummary_1.3.5   \n [4] dplyr_1.0.2        lm.beta_1.5-1      DescTools_0.99.39 \n [7] brms_2.14.4        carData_3.0-4      gapminder_0.3.0   \n[10] skimr_2.1.2        rstanarm_2.21.1    Rcpp_1.0.5        \n[13] readxl_1.3.1      \n\nloaded via a namespace (and not attached):\n  [1] utf8_1.1.4           tidyselect_1.1.0     lme4_1.1-26         \n  [4] htmlwidgets_1.5.3    grid_4.0.3           munsell_0.5.0       \n  [7] codetools_0.2-18     effectsize_0.4.1     distill_1.1         \n [10] statmod_1.4.35       DT_0.16              miniUI_0.1.1.1      \n [13] withr_2.3.0          Brobdingnag_1.2-6    colorspace_2.0-0    \n [16] highr_0.8            knitr_1.30           rstudioapi_0.13     \n [19] stats4_4.0.3         bayesplot_1.7.2      labeling_0.4.2      \n [22] emmeans_1.5.3        rstan_2.21.2         repr_1.1.0          \n [25] farver_2.0.3         bridgesampling_1.0-0 rprojroot_2.0.2     \n [28] coda_0.19-4          vctrs_0.3.6          generics_0.1.0      \n [31] TH.data_1.0-10       xfun_0.19            R6_2.5.0            \n [34] markdown_1.1         gamm4_0.2-6          projpred_2.0.2      \n [37] assertthat_0.2.1     promises_1.1.1       scales_1.1.1        \n [40] multcomp_1.4-15      rootSolve_1.8.2.1    gtable_0.3.0        \n [43] downlit_0.2.1        processx_3.4.5       lmom_2.8            \n [46] sandwich_3.0-0       rlang_0.4.10         splines_4.0.3       \n [49] broom_0.7.3          checkmate_2.0.0      inline_0.3.17       \n [52] yaml_2.2.1           reshape2_1.4.4       abind_1.4-5         \n [55] modelr_0.1.8         threejs_0.3.3        crosstalk_1.1.0.1   \n [58] backports_1.2.1      httpuv_1.5.4         rsconnect_0.8.16    \n [61] tools_4.0.3          bookdown_0.21        ggplot2_3.3.3       \n [64] ellipsis_0.3.1       RColorBrewer_1.1-2   ggridges_0.5.2      \n [67] plyr_1.8.6           base64enc_0.1-3      visNetwork_2.0.9    \n [70] purrr_0.3.4          ps_1.5.0             prettyunits_1.1.1   \n [73] zoo_1.8-8            survey_4.0           magrittr_2.0.1      \n [76] colourpicker_1.1.0   mvtnorm_1.1-1        sjmisc_2.8.5        \n [79] matrixStats_0.57.0   shinyjs_2.0.0        mime_0.9            \n [82] evaluate_0.14        xtable_1.8-4         shinystan_2.5.0     \n [85] sjstats_0.18.0       gridExtra_2.3        ggeffects_1.0.1     \n [88] rstantools_2.1.1     compiler_4.0.3       tibble_3.0.4        \n [91] gt_0.2.2             V8_3.4.0             crayon_1.3.4        \n [94] minqa_1.2.4          StanHeaders_2.21.0-7 htmltools_0.5.0     \n [97] mgcv_1.8-33          later_1.1.0.1        tidyr_1.1.2         \n[100] expm_0.999-5         Exact_2.1            RcppParallel_5.0.2  \n[103] lubridate_1.7.9.2    DBI_1.1.0            sjlabelled_1.1.7    \n[106] MASS_7.3-53          boot_1.3-25          Matrix_1.3-0        \n[109] cli_2.2.0            mitools_2.4          parallel_4.0.3      \n[112] insight_0.11.1       igraph_1.2.6         forcats_0.5.0       \n[115] pkgconfig_2.0.3      dygraphs_1.1.1.6     estimability_1.3    \n[118] snakecase_0.11.0     stringr_1.4.0        callr_3.5.1         \n[121] digest_0.6.27        parameters_0.10.1    rmarkdown_2.6       \n[124] cellranger_1.1.0     gld_2.6.2            curl_4.3            \n[127] shiny_1.5.0          gtools_3.8.2         commonmark_1.7      \n[130] nloptr_1.2.2.2       lifecycle_0.2.0      nlme_3.1-151        \n[133] jsonlite_1.7.2       fansi_0.4.1          pillar_1.4.7        \n[136] lattice_0.20-41      loo_2.4.1            fastmap_1.0.1       \n[139] pkgbuild_1.2.0       survival_3.2-7       glue_1.4.2          \n[142] xts_0.12.1           bayestestR_0.8.0     shinythemes_1.1.2   \n[145] class_7.3-17         stringi_1.5.3        sass_0.2.0          \n[148] performance_0.6.1    e1071_1.7-4         \n\n\n\n\nBaird, D. (1983). The fisher/pearson chi-squared controversy: A turning point for inductive inference. The British Journal for the Philosophy of Science, 34(2), 105–118. Retrieved from http://www.jstor.org/stable/687444\n\n\nCobb, G. W. (2007). The introductory statistics course: A ptolemaic curriculum? Technology Innovations in Statistics Education, 1(1).\n\n\nCumming, G. (2009). Inference by eye: Reading the overlap of independent confidence intervals. Statistics in Medicine, 28(2), 205–220.\n\n\nDowney, A. (2016). Probably overthinking it: There is still only one test. Retrieved from http://allendowney.blogspot.com/2016/06/there-is-still-only-one-test.html\n\n\nFisher, R. A. (1925). Statistical methods for research workers. Oliver; Boyd.\n\n\nHead, M. L., Holman, L., Lanfear, R., Kahn, A. T., & Jennions, M. D. (2015). The extent and consequences of p-hacking in science. PLoS Biol, 13(3), e1002106.\n\n\nHoekstra, R., Morey, R. D., Rouder, J. N., & Wagenmakers, E.-J. (2014). Robust misinterpretation of confidence intervals. Psychonomic Bulletin & Review, 21(5), 1157–1164. https://doi.org/10.3758/s13423-013-0572-3\n\n\nIoannidis, J. P. A. (2019). What Have We (Not) Learnt from Millions of Scientific Papers with <i>P<\/i> Values? The American Statistician, 73(sup1), 20–25. https://doi.org/10.1080/00031305.2018.1447512\n\n\nMorey, R. D., Hoekstra, R., Rouder, J. N., Lee, M. D., & Wagenmakers, E.-J. (2016). The fallacy of placing confidence in confidence intervals. Psychonomic Bulletin & Review, 23(1), 103–123. https://doi.org/10.3758/s13423-015-0947-8\n\n\nNeyman, J. (1937). Outline of a theory of statistical estimation based on the classical theory of probability. Philosophical Transactions of the Royal Society of London. Series A, Mathematical and Physical Sciences, 236(767), 333–380.\n\n\nNeyman, J., & Pearson, E. S. (1933). On the problem of the most efficient tests of statistical hypotheses. Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character, 231(694-706), 289–337.\n\n\nRosnow, R. L., & Rosenthal, R. (1989). Statistical procedures and the justification of knowledge in psychological science. American Psychologist, 44, 1276–1284.\n\n\nStigler, S. M., & others. (2007). The epic story of maximum likelihood. Statistical Science, 22(4), 598–620.\n\n\nMatemático inglês que viveu entre 1857-1936. Considerado o fundador do campo da Estatística.↩︎\nem especial as técnicas clássicas/frequentistas de Estatística inferencial.↩︎\nTeoricamente não precisamos da hipótese nula se, no passo 2, simulássemos e permutássemos valores da amostra para calcular um \\(\\delta_0\\) (é provado matematicamente que se gerarmos amostras e permutações simuladas o suficiente, conseguiremos ter um \\(\\delta_0\\) no mínimo tão verídico que a abordagem clássica) ao invés de nos embasarmos em uma aproximação numérica pré-estabelecida de \\(\\delta_0\\). É claro que todas essas permutações e simulações são computacionalmente intensas.↩︎\nInclusive muitos renomados e citados em abundância em suas áreas.↩︎\nCuidado com essa palavra. Ela é precisa e somente deve ser usada em contextos estatísticos. Significância estatística quer dizer que os dados observados são mais extremos que um alpha prédefinido de que a hipótese nula é verdadeira.↩︎\nEsse conselho é extremamente útil. Por diversas vezes temos alunos que nos procuram com uma pergunta mais ou menos assim: “Professor, o que é o teste de Sobrenome que nunca ouvi falar na minha vida hífen outro sobrenome ainda mais estranho?” Graças a Wikipedia e Google, nós simplesmente vamos atrás da \\(H_0\\) desse teste (busca Google: “sobrenome1-sobrenome2 null hypothesis”) e com isso conseguimos responder ao aluno.↩︎\nA controvérsia da personalidade e vida de Ronald Fisher merece uma nota de rodapé. Suas contribuições, sem dúvida, foram cruciais para o avanço da ciência e da estatística. Seu intelecto era brilhante e seu talento já floresceu jovem: antes de completar 33 anos de idade ele tinha proposto o método de estimação por máxima verossimilhança (maximum likelihood estimation) (Stigler & others, 2007) e também criou o conceito de graus de liberdade (degrees of freedom) ao propor uma correção no teste de chi-quadrado de Pearson (Baird, 1983). Também inventou a Análise de Variância (ANOVA) e foi o primeiro a propor randomização como uma maneira de realizar experimentos, sendo considerado o “pai” dos ensaios clínicos randomizados. Nem tudo é florido na vida de Fisher, ele foi um eugenista e possuía uma visão muito forte sobre etnia e raça preconizando a superioridade de certas etnias. Além disso, era extremamente invariante, perseguindo, prejudicando e debochando qualquer crítico à suas teorias e publicações. O que vemos hoje no monopólio do paradigma Neyman-Pearson (Neyman & Pearson, 1933) com \\(p\\)-valores e hipóteses nulas é resultado desse esforço Fisheriano em calar os críticos e deixar apenas sua voz ecoar.↩︎\ninclusive muitos professores de estatística, veja a referência↩︎\nOriginal em ingles: “An X% confidence interval for a parameter is an interval (a, b) generated by a procedure that in repeated sampling has an X% probability of containing the true value of the parameter, for all possible values of the parameter.”↩︎\nOriginal em inglês: If the probability that a random interval contains the true value is X%, then the plausibility or probability that a particular observed interval contains the true value is also X%;or, alternatively, we can have X% confidence that the observed interval contains the true value.↩︎\nOriginal em inglês: The width of a confidence interval indicates the precision ofour knowledge about the parameter. Narrow confidence intervals correspond to precise knowledge, while wide confidence errors correspond to imprecise knowledge.↩︎\nOriginal em inglês: A confidence interval contains the likely values for the parameter. Values inside the confidence interval are more likely than those outside. This fallacy exists in several varieties, sometimes involving plausibility, credibility, or reasonableness of beliefs about the parameter.↩︎\nO que é muito comum em 2020s com o advento de Big Data e facilidade de obtenção de dados.↩︎\nJerzy Newman, fundador do paradigma NHST, e criador dos erros tipo I e tipo II defendia a ideia de que é melhor absolver um culpado (erro tipo II) do que culpar um inocente (erro tipo I).↩︎\ntambém chamada de Estatística Clássica↩︎\nou de maneira geral qualquer hipótese ou paramêtro estimado↩︎\n",
      "last_modified": "2021-01-03T04:52:41-03:00"
    },
    {
      "path": "README.html",
      "author": [],
      "contents": "\n\nContents\nEstatística Bayesiana\nProfessor\nComo usar esse conteúdo?\nAulas\nReferências\nLivros\nArtigos\n\n\n\nEstatística Bayesiana\nDisciplina de Estatística Bayesiana da UNINOVE\nDisciplina do Mestrado e Doutorado em Administração da UNINOVE\nSegundo Semestre de 2020\nRStudio: \nProfessor\nProf. Dr. José Eduardo Storopoli - Currículo Lattes - ORCID - CV\njosees@uni9.pro.br\nComo usar esse conteúdo?\nEste conteúdo possui licença livre para uso. Caso queira utilizar o conteúdo para um curso ou estudos, por favor colabore nesse repositório quaisquer aprimorações que foram realizadas.\nPara configurar um ambiente local:\nClone o repositório do GitHub: git clone https://github.com/storopoli/Estatistica-Bayesiana.git\nAcesse o diretório: cd Estatistica-Bayesiana\nInstale os pacotes necessários: Rscript install.R\nAulas\nComandos Básicos de R\nRegressão Linear Bayesiana\nDistribuições Estatísticas\nPriors\nMarkov Chain Montecarlo (MCMC)\nRegressão Binomial Bayesiana\nRegressão de Poisson Bayesiana\nRegressão Robusta Bayesiana\nModelos Multiníveis\nDados Faltantes\nCoeficientes de uma Regressão\nTabelas para Publicação\nReferências\nLivros\nGelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., & Rubin, D. B. (2013). Bayesian data analysis. Chapman and Hall/CRC.\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan. CRC press.\nGelman, A., Hill, J., & Vehtari, A. (2020). Regression and other stories. Cambridge University Press.\nArtigos\nBásicos\nBenjamin, D. J., Berger, J. O., Johannesson, M., Nosek, B. A., Wagenmakers, E.-J., Berk, R., … Johnson, V. E. (2018). Redefine statistical significance. Nature Human Behaviour, 2(1), 6–10. https://doi.org/10.1038/s41562-017-0189-z\nCarpenter, B., Gelman, A., Hoffman, M. D., Lee, D., Goodrich, B., Betancourt, M., … Riddell, A. (2017). Stan : A Probabilistic Programming Language. Journal of Statistical Software, 76(1). https://doi.org/10.18637/jss.v076.i01\nEtz, A. (2018). Introduction to the Concept of Likelihood and Its Applications. Advances in Methods and Practices in Psychological Science, 1(1), 60–69. https://doi.org/10.1177/2515245917744314\nEtz, A., Gronau, Q. F., Dablander, F., Edelsbrunner, P. A., & Baribault, B. (2018). How to become a Bayesian in eight easy steps: An annotated reading list. Psychonomic Bulletin and Review, 25(1), 219–234. https://doi.org/10.3758/s13423-017-1317-5\nGeyer, C. J. (2011). Introduction to markov chain monte carlo. In S. Brooks, A. Gelman, G. L. Jones, & X.-L. Meng (Eds.), Handbook of markov chain monte carlo.\nMcShane, B. B., Gal, D., Gelman, A., Robert, C., & Tackett, J. L. (2019). Abandon Statistical Significance. American Statistician, 73(sup1), 235–245. https://doi.org/10.1080/00031305.2018.1527253\nvan Ravenzwaaij, D., Cassey, P., & Brown, S. D. (2018). A simple introduction to Markov Chain Monte–Carlo sampling. Psychonomic Bulletin and Review, 25(1), 143–154. https://doi.org/10.3758/s13423-016-1015-8\nVandekerckhove, J., Matzke, D., Wagenmakers, E.-J., & others. (2015). Model comparison and the principle of parsimony. In J. R. Busemeyer, Z. Wang, J. T. Townsend, & A. Eidels (Eds.), Oxford handbook of computational and mathematical psychology (pp. 300–319). Oxford University Press Oxford.\nVan de Schoot, R., Kaplan, D., Denissen, J., Asendorpf, J. B., Neyer, F. J., & van Aken, M. A. G. (2014). A Gentle Introduction to Bayesian Analysis: Applications to Developmental Research. Child Development, 85(3), 842–860. https://doi.org/10.1111/cdev.12169\nWagenmakers, E.-J. (2007). A practical solution to the pervasive problems of p values. Psychonomic Bulletin & Review, 14(5), 779–804. https://doi.org/10.3758/BF03194105\nComplementares\nCohen, J. (1994). The earth is round (p < .05). American Psychologist, 49(12), 997–1003. https://doi.org/10.1037/0003-066X.49.12.997\nDienes, Z. (2011). Bayesian versus orthodox statistics: Which side are you on? Perspectives on Psychological Science, 6(3), 274–290. https://doi.org/10.1177/1745691611406920\nEtz, A., & Vandekerckhove, J. (2018). Introduction to Bayesian Inference for Psychology. Psychonomic Bulletin & Review, 25(1), 5–34. https://doi.org/10.3758/s13423-017-1262-3\nKerr, N. L. (1998). HARKing: Hypothesizing after the results are known. Personality and Social Psychology Review, 2(3), 196–217. https://doi.org/10.1207/s15327957pspr0203_4\nKruschke, J. K., & Vanpaemel, W. (2015). Bayesian estimation in hierarchical models. In J. R. Busemeyer, Z. Wang, J. T. Townsend, & A. Eidels (Eds.), The Oxford handbook of computational and mathematical psychology (pp. 279–299). Oxford University Press Oxford, UK.\nKruschke, J. K., & Liddell, T. M. (2018a). Bayesian data analysis for newcomers. Psychonomic Bulletin and Review, 25(1), 155–177. https://doi.org/10.3758/s13423-017-1272-1\nKruschke, J. K., & Liddell, T. M. (2018b). The Bayesian New Statistics: Hypothesis testing, estimation, meta-analysis, and power analysis from a Bayesian perspective. Psychonomic Bulletin and Review, 25(1), 178–206. https://doi.org/10.3758/s13423-016-1221-4\nLakens, D., Adolfi, F. G., Albers, C. J., Anvari, F., Apps, M. A. J., Argamon, S. E., … Zwaan, R. A. (2018, March 1). Justify your alpha. Nature Human Behaviour, Vol. 2, pp. 168–171. https://doi.org/10.1038/s41562-018-0311-x\nMorey, R. D., Hoekstra, R., Rouder, J. N., Lee, M. D., & Wagenmakers, E.-J. (2016). The fallacy of placing confidence in confidence intervals. Psychonomic Bulletin & Review, 23(1), 103–123. https://doi.org/10.3758/s13423-015-0947-8\nMourão Júnior, C. A. (2019). Quanto vale o valor-p? Arquivos de Ciências Do Esporte, 7(2), 72–74. http://seer.uftm.edu.br/revistaeletronica/index.php/aces\nMurphy, K. R., & Aguinis, H. (2019). HARKing: How Badly Can Cherry-Picking and Question Trolling Produce Bias in Published Results? Journal of Business and Psychology, 34(1). https://doi.org/10.1007/s10869-017-9524-7\nStark, P. B., & Saltelli, A. (2018). Cargo-cult statistics and scientific crisis. Significance, 15(4), 40–43. https://doi.org/10.1111/j.1740-9713.2018.01174.x\n",
      "last_modified": "2021-01-03T04:53:16-03:00"
    }
  ],
  "collections": []
}
